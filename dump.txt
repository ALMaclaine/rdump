File: ./GEMINI.md
---
# Gemini Notes: rdump Project

This file contains notes and observations about the `rdump` project to aid in development.

## Project Overview

- **Purpose**: `rdump` appears to be a command-line file search and query tool.
- **Primary Language**: The core logic is written in **Rust**.
- **Query Language**: It uses a custom query language, likely defined in `rdump/src/rql.pest` and parsed by `rdump/src/parser.rs`.
- **Language-Aware Features**: The presence of `rdump/src/predicates/code_aware/` and language-specific tests (`tests/go_search.rs`, `tests/java_search.rs`, etc.) suggests it has code-aware search capabilities.
- **Configuration**: Configuration is likely managed through `.rdump.toml`.

## Key Files & Directories

- `rdump/src/main.rs`: The main entry point for the application.
- `rdump/src/parser.rs`: Handles parsing the rdump query language.
- `rdump/src/evaluator.rs`: Evaluates the parsed query against the filesystem.
- `rdump/src/predicates/`: Contains the logic for different search filters (e.g., `name`, `path`, `size`, `contains`).
- `tests/`: Contains integration and CLI tests.
- `insane_test_bed/`: A directory with a wide variety of files used for testing `rdump`'s capabilities.

## Development Notes

- **Build**: The project is built using `cargo build` from the `rdump` directory.
- **Run**: The application can be run with `cargo run` from the `rdump` directory.
- **Test**: Tests are executed with `cargo test` from the `rdump` directory.
- **Formatting**: Assumed to follow standard Rust formatting (`rustfmt`).

## Development Rules

1.  **Always Add Tests**: For any bug fix or feature addition, a corresponding test must be added to verify the change and prevent regressions.
2.  **Log All Changes**: All modifications, including bug fixes and new features, must be logged in the `GEMINI_EDITS.log` file. The log entry should be dated and clearly describe the change.
3.  **Continuously Refine `GEMINI.md`**: Actively look for opportunities to improve and expand this document based on interactions and new discoveries about the project.


---

File: ./GEMINI_EDITS.log
---
2025-07-12:
- Added `contains_predicate.rs` to test the `contains` predicate.
- Added "not found" tests to `rust_search.rs`, `go_search.rs`, `java_search.rs`, `js_ts_search.rs`, and `python_search.rs`.
- Added a test for complex predicate combinations to `extended_cli.rs`.
- Added `ignore.rs` to test the `.rdumpignore` functionality.
- Fixed a bug in the `contains` predicate where it was case-sensitive.
- Fixed a bug in the `test_size_predicate` test in `extended_cli.rs`.

---

File: ./README.md
---
# `rdump` &mdash; The Definitive Developer's Guide to Code-Aware Search

**`rdump` is a next-generation, command-line tool for developers. It finds and processes files by combining filesystem metadata, content matching, and deep structural code analysis.**

[![Build Status](https://img.shields.io/github/actions/workflow/status/user/repo/rust.yml?branch=main)](https://github.com/user/repo/actions)
[![Crates.io](https://img.shields.io/crates/v/rdump.svg)](https://crates.io/crates/rdump)
[![License](https://img.shields.io/crates/l/rdump.svg)](https://github.com/user/repo/blob/main/LICENSE)

It's a developer's swiss-army knife for code discovery. It goes beyond the text-based search of tools like `grep` and `ripgrep` by using **tree-sitter** to parse your code into a syntax tree. This allows you to ask questions that are impossible for other tools to answer efficiently:

- *"Find the 'User' struct definition, but only in non-test Rust files."*
- *"Show me every call to 'console.log' in my JavaScript files with 3 lines of context."*
- *"List all Python files larger than 10KB that import 'requests' and were modified in the last week."*

`rdump` is written in Rust for blazing-fast performance, ensuring that even complex structural queries on large codebases are executed in moments.

---

## Table of Contents

1.  [**Why `rdump`?**](#1-why-rdump-a-comparative-look)
    - [The Problem with Text-Based Search](#the-problem-with-text-based-search)
    - [The `rdump` Solution: Structural Awareness](#the-rdump-solution-structural-awareness)
    - [Comparison with Other Tools](#comparison-with-other-tools)
2.  [**Architecture & Design Philosophy**](#2-architecture--design-philosophy)
    - [The Core Philosophy](#the-core-philosophy)
    - [Data Flow Diagram](#data-flow-diagram)
    - [Component Breakdown](#component-breakdown)
3.  [**Installation**](#3-installation)
    - [With Cargo (Recommended)](#with-cargo-recommended)
    - [From Pre-compiled Binaries](#from-pre-compiled-binaries)
    - [From Source](#from-source)
4.  [**Practical Recipes for Real-World Use**](#4-practical-recipes-for-real-world-use)
    - [Code Auditing & Security](#code-auditing--security)
    - [Refactoring & Maintenance](#refactoring--maintenance)
    - [Codebase Exploration & Learning](#codebase-exploration--learning)
    - [DevOps & Automation](#devops--automation)
5.  [**The `rdump` Query Language (RQL) &mdash; A Deep Dive**](#5-the-rdump-query-language-rql--a-deep-dive)
    - [Core Concepts & Syntax](#core-concepts--syntax)
    - [Evaluation Order & Performance Tips](#evaluation-order--performance-tips)
    - [Predicate Reference: Metadata](#predicate-reference-metadata)
    - [Predicate Reference: Content](#predicate-reference-content)
    - [Predicate Reference: Code-Aware (Semantic)](#predicate-reference-code-aware-semantic)
    - [Advanced Querying Techniques](#advanced-querying-techniques)
6.  [**Command Reference**](#6-command-reference)
    - [`rdump search`](#rdump-search)
    - [`rdump lang`](#rdump-lang)
    - [`rdump preset`](#rdump-preset)
7.  [**Output Formats: A Visual Guide**](#7-output-formats-a-visual-guide)
8.  [**Configuration**](#8-configuration)
    - [The `config.toml` File](#the-configtoml-file)
    - [The `.rdumpignore` System](#the-rdumpignore-system)
9.  [**Extending `rdump`: Adding a New Language**](#9-extending-rdump-adding-a-new-language)
10. [**Troubleshooting & FAQ**](#10-troubleshooting--faq)
11. [**Performance Benchmarks**](#11-performance-benchmarks)
12. [**Contributing**](#12-contributing)
13. [**License**](#13-license)

---

## 1. Why `rdump`? A Comparative Look

### The Problem with Text-Based Search

For decades, developers have relied on text-based search tools like `grep`, `ack`, and `ripgrep`. These tools are phenomenal for finding literal strings and regex patterns. However, they share a fundamental limitation: **they don't understand code.** They see a file as a flat sequence of characters.

This leads to noisy and inaccurate results for code-related questions. A `grep` for `User` will find:
- The `struct User` definition.
- A variable named `NewUser`.
- A function parameter `user_permission`.
- Comments mentioning `User`.
- String literals like `"Failed to create User"`.

### The `rdump` Solution: Structural Awareness

`rdump` sees code the way a compiler does: as a structured tree of nodes. It uses the powerful `tree-sitter` library to parse source code into a Concrete Syntax Tree (CST).

This means you can ask for `struct:User`, and `rdump` will navigate the syntax tree to find **only the node representing the definition of the `User` struct**. This is a paradigm shift in code search.

### Comparison with Other Tools

| Feature | `ripgrep` / `grep` | `semgrep` | **`rdump`** |
| :--- | :--- | :--- | :--- |
| **Search Paradigm** | Regex / Literal Text | Abstract Semantic Patterns | **Metadata + Content + Code Structure** |
| **Primary Use Case** | Finding specific lines of text | Enforcing static analysis rules | **Interactive code exploration & filtering** |
| **Speed** | Unmatched for text search | Fast for patterns | **Very fast; optimizes by layer** |
| **Query `func:foo`** | `grep "func foo"` (noisy) | `pattern: function foo(...)` | `func:foo` (precise) |
| **Query `size:>10kb`** | No | No | `size:>10kb` (built-in) |
| **Query `import:react`** | `grep "import.*react"` (noisy) | `pattern: import ... from "react"` | `import:react` (precise) |
| **Combine Filters** | Possible via shell pipes | Limited | **Natively via RQL (`&`, `|`, `!`)** |

---

## 2. Architecture, Frameworks, and Libraries: A Technical Deep Dive

`rdump`'s power and simplicity are not accidental; they are the result of deliberate architectural choices and the leveraging of best-in-class libraries from the Rust ecosystem. This section details how these pieces fit together to create a performant, modular, and extensible tool.

### The Core Philosophy: A Pipeline of Composable Filters

At its heart, `rdump` is a highly optimized pipeline. It starts with a massive set of potential files and, at each stage, applies progressively more powerful (and expensive) filters to narrow down the set.

1.  **Declarative Interface:** The user experience is paramount. We define *what* we want, not *how* to get it.
2.  **Composition over Inheritance:** Functionality is built from small, single-purpose, reusable units (predicates, formatters). This avoids complex class hierarchies and makes the system easy to reason about.
3.  **Extensibility by Design:** The architecture anticipates change. Adding a new language or predicate requires adding new data/modules, not rewriting the core evaluation logic.
4.  **Performance Through Layering:** Cheap checks (metadata) are performed first to minimize the work for expensive checks (code parsing).

### Data Flow & Component Breakdown

```
[Query String] -> [1. CLI Parser (clap)] -> [2. RQL Parser (pest)] -> [AST] -> [3. Evaluator Engine] -> [Matched Files] -> [6. Formatter (syntect)] -> [Final Output]
                                                                                    |
                                                                                    V
                                                                    [4. Predicate Trait System]
                                                                                    |
                                                                                    +------> [Metadata Predicates]
                                                                                    |
                                                                                    +------> [Content Predicates]
                                                                                    |
                                                                                    +------> [5. Semantic Engine (tree-sitter)]
```

#### 1. CLI Parsing: `clap`

-   **Library:** `clap` (Command Line Argument Parser)
-   **Role:** `clap` is the face of `rdump`. It provides a declarative macro-based API to define the entire CLI structure: subcommands (`search`, `lang`, `preset`), flags (`--format`, `-C`), and arguments (`<QUERY>`).
-   **Implementation Benefits:**
    -   **Automatic Help Generation:** `rdump --help` is generated for free, perfectly in sync with the defined CLI.
    -   **Type-Safe Parsing:** It parses arguments into strongly-typed Rust structs and enums, eliminating manual validation and parsing code.
    -   **Modularity:** The CLI definition is co-located with the `main` function, providing a single, clear entry point to the application's logic.

#### 2. RQL Parser: `pest`

-   **Library:** `pest` (Parser-Expressive Syntax Trees)
-   **Role:** `pest` transforms the human-readable RQL query string (e.g., `"ext:rs & (struct:User | !path:tests)"`) into a machine-readable Abstract Syntax Tree (AST).
-   **Implementation Benefits:**
    -   **Decoupled Grammar:** The entire RQL grammar is defined in a separate file (`src/rql.pest`). This allows the language syntax to evolve independently of the Rust code that processes it.
    -   **Resilience & Error Reporting:** `pest` generates a robust parser with excellent, human-readable error messages out of the box (e.g., "error: expected logical_op, found...").
    -   **AST Generation:** It automatically creates an iterator over the parsed pairs, which our `build_ast_from_pairs` function in `src/parser.rs` recursively walks to build our `AstNode` enum (e.g., `AstNode::LogicalOp(...)`).

#### 3. The Evaluator Engine

-   **Library:** Standard Rust
-   **Role:** The evaluator is the brain. It takes the AST from `pest` and a list of candidate files, and returns only the files that match the query.
-   **Implementation Benefits:**
    -   **Recursive Evaluation:** It's a simple, elegant recursive function that walks the `AstNode` tree. If it sees a `LogicalOp`, it calls itself on the left and right children. If it sees a `Predicate`, it dispatches to the predicate system.
    -   **Performance via Short-Circuiting:** When evaluating `ext:rs & struct:User`, if `ext:rs` returns `false`, the evaluator **immediately stops** and does not execute the expensive `struct:User` predicate. This is a critical performance optimization.

#### 4. The Predicate System: Rust's Trait System

-   **Library:** Standard Rust (specifically, `trait` objects)
-   **Role:** This is the heart of `rdump`'s modularity. Each predicate (`ext`, `size`, `contains`, `func`, etc.) is an independent module that implements a common `Predicate` trait.
-   **Implementation Benefits:**
    -   **Dynamic Dispatch:** The evaluator holds a collection of `Box<dyn Predicate>`. When it encounters a predicate key in the AST, it dynamically finds and executes the correct predicate's `evaluate()` method.
    -   **Extreme Modularity:** To add a new predicate, say `author:<name>`, a developer simply needs to:
        1.  Create a new file `src/predicates/author.rs`.
        2.  Implement the `Predicate` trait for an `AuthorPredicate` struct.
        3.  Register the new predicate in the evaluator's lookup map.
        *No other part of the codebase needs to change.*

#### 5. The Semantic Engine: `tree-sitter`

-   **Library:** `tree-sitter` and its Rust binding.
-   **Role:** `tree-sitter` is the universal parser that powers all code-aware predicates. It takes source code text and produces a concrete syntax tree.
-   **Implementation Benefits:**
    -   **Language Agnostic Core:** The core semantic predicate logic doesn't know anything about Rust, Python, or Go. It only knows how to execute a `tree-sitter` query against a syntax tree.
    -   **Data-Driven Extensibility:** A language is "supported" by providing data, not code:
        1.  The compiled `tree-sitter` grammar (as a crate).
        2.  A set of `.scm` files containing tree-sitter queries (e.g., `(function_definition name: (identifier) @func-name)`).
    -   This design means adding `func` support for a new language involves writing a one-line query in a text file, not writing complex Rust code to traverse a language-specific AST.

#### 6. Parallelism & Performance: `rayon`

-   **Library:** `rayon`
-   **Role:** `rayon` is the secret sauce for `rdump`'s performance on multi-core machines. While the evaluator processes a single query, the file search itself is a massively parallel problem. `rayon` provides incredibly simple, data-parallel iterators.
-   **Implementation Benefits:**
    -   **Effortless Parallelism:** With `rayon`, converting a sequential iterator over files into a parallel one is often a one-line change (e.g., `files.iter()` becomes `files.par_iter()`). `rayon` handles thread pooling, work-stealing, and synchronization automatically.
    -   **Fearless Concurrency:** Rust's ownership model and `rayon`'s design guarantee that this parallelism is memory-safe, preventing data races at compile time.
    -   **Scalability:** This allows `rdump` to scale its performance linearly with the number of available CPU cores, making it exceptionally fast on modern hardware when searching large numbers of files.

#### 7. The Formatter & Syntax Highlighting: `syntect`

-   **Library:** `syntect`
-   **Role:** The formatter takes the final list of matched files and hunks and presents them to the user.
-   **Implementation Benefits:**
    -   **Professional-Grade Highlighting:** `syntect` uses the same syntax and theme definitions as Sublime Text, providing robust, accurate, and beautiful highlighting for a vast number of languages.
    -   **Lazy Loading:** The `SYNTAX_SET` and `THEME_SET` are wrapped in `once_cell::sync::Lazy` to ensure they are loaded from disk and parsed only once on the first use, making subsequent runs faster.
    -   **Clean Separation:** The `Format` enum allows the `print_output` function to act as a clean dispatcher, routing to different printing functions (`print_highlighted_content`, `print_markdown_fenced_content`, etc.) based on the user's choice. This keeps the presentation logic clean and separated.

---

## 3. Installation

### With Cargo (Recommended)
If you have the Rust toolchain (`rustup`), you can install directly from Crates.io. This ensures you have the latest version.
```sh
cargo install rdump
```

### From Pre-compiled Binaries
Pre-compiled binaries for Linux, macOS, and Windows are available on the [**GitHub Releases**](https://github.com/user/repo/releases) page. Download the appropriate archive, extract the `rdump` executable, and place it in a directory on your system's `PATH`.

### From Source
To build `rdump` from source, you'll need `git` and the Rust toolchain.
```sh
git clone https://github.com/user/repo.git
cd rdump
cargo build --release
# The executable will be at ./target/release/rdump
./target/release/rdump --help
```

---

## 4. Practical Recipes for Real-World Use

### Code Auditing & Security

-   **Find potential hardcoded secrets, ignoring test data:**
    ```sh
    rdump "str:/[A-Za-z0-9_\\-]{20,}/ & !path:test"
    ```
-   **Locate all disabled or skipped tests:**
    ```sh
    rdump "(comment:ignore | comment:skip) & name:*test*"
    ```
-   **Find all raw SQL queries that are not in a `db` or `repository` package:**
    ```sh
    rdump "str:/SELECT.*FROM/ & !(path:/db/ | path:/repository/)"
    ```

### Refactoring & Maintenance

-   **Find all call sites of a function to analyze its usage before changing its signature:**
    ```sh
    rdump "call:process_payment" --format hunks -C 3
    ```
-   **Identify "god files" that might need to be broken up:**
    List Go files over 50KB.
    ```sh
    rdump "ext:go & size:>50kb" --format find
    ```
-   **Clean up dead code:** Find functions that have no corresponding calls within the project.
    ```sh
    # This is a two-step process, but rdump helps find the candidates
    rdump "ext:py & func:." --format json > funcs.json
    # Then, a script could check which function names from funcs.json are never found with a `call:` query.
    ```

### Codebase Exploration & Learning

-   **Get a high-level overview of a new Rust project's data structures:**
    ```sh
    rdump "ext:rs & (struct:. | enum:.) & !path:tests"
    ```
-   **Trace a configuration variable from definition to use:**
    ```sh
    rdump "contains:APP_PORT"
    ```
-   **Understand a project's API surface:** List all functions defined in files under an `api/` directory.
    ```sh
    rdump "path:src/api/ & func:."
    ```

### DevOps & Automation

-   **Find all Dockerfiles that don't pin to a specific image digest:**
    ```sh
    rdump "name:Dockerfile & !contains:/@sha256:/"
    ```
-   **List all TOML configuration files larger than 1KB that have been changed in the last 2 days:**
    ```sh
    rdump "ext:toml & size:>1kb & modified:<2d" --format find
    ```
-   **Pipe files to another command:** Delete all `.tmp` files older than a week.
    ```sh
    rdump "ext:tmp & modified:>7d" --format paths | xargs rm -v
    ```

### Code Quality & Consistency

-   **Find functions that are too long (e.g., > 50 lines):**
    ```sh
    # This is an approximation, but effective.
    # It finds functions where the text content of the function node is over 1200 bytes.
    rdump "func:. & size:>1200b"
    ```
-   **Enforce API conventions:** Find all `GET` endpoints that are missing a call to an authentication middleware.
    ```sh
    rdump "ext:go & func:/^Get/ & !call:requireAuth"
    ```
-   **Find magic strings/numbers:** Locate string or number literals outside of variable declarations.
    ```sh
    rdump "(str:. | contains:/ \d+;/) & !contains:/const / & !contains:/let / & !contains:/var /"
    ```

---

## 5. The `rdump` Query Language (RQL) &mdash; A Deep Dive

(This section is intentionally verbose for complete clarity.)

### Core Concepts & Syntax

-   **Predicates:** The building block of RQL is the `key:value` pair (e.g., `ext:rs`).
-   **Operators:** Combine predicates with `&` (AND), `|` (OR).
-   **Negation:** `!` negates a predicate or group (e.g., `!ext:md`).
-   **Grouping:** `()` controls the order of operations (e.g., `ext:rs & (contains:foo | contains:bar)`).
-   **Quoting:** Use `'` or `"` for values with spaces or special characters (e.g., `contains:'fn main()'`).

### Evaluation Order & Performance Tips

`rdump` is fast, but you can make it even faster by writing efficient queries. The key is to **eliminate the most files with the cheapest predicates first.**

-   **GOOD:** `ext:rs & struct:User`
    -   *Fast.* `rdump` first finds all `.rs` files (very cheap), then runs the expensive `struct` parser only on that small subset.
-   **BAD:** `struct:User & ext:rs`
    -   *Slow.* While `rdump`'s engine is smart enough to likely re-order this, writing it this way is logically less efficient. It implies parsing every file to look for a struct, then checking its extension.
-   **BEST:** `path:models/ & ext:rs & struct:User`
    -   *Blazing fast.* The search space is narrowed by path, then extension, before any files are even opened.

**Golden Rule:** Always lead with `path:`, `name:`, or `ext:` if you can.

### Predicate Reference: Metadata

| Key | Example | Description |
| :--- | :--- | :--- |
| `ext` | `ext:ts` | Matches file extension. Case-insensitive. |
| `name`| `name:"*_test.go"` | Matches filename (basename) against a glob pattern. |
| `path`| `path:src/api` | Matches if the substring appears anywhere in the full path. |
| `in`       | `in:"src/commands"`         | The directory path to search in. Matches all files that are descendants of the given directory.         |
| `size`| `size:>=10kb` | Filters by size. Operators: `>`, `<`, `>=`, `<=`, `=`. Units: `b`, `kb`, `mb`, `gb`. |
| `modified`| `modified:<2d` | Filters by modification time. Units: `m`, `h`, `d`, `w`, `y`. |

### Predicate Reference: Content

| Key | Example | Description |
| :--- | :--- | :--- |
| `contains` | `contains:"// HACK"` | Fast literal substring search. |
| `matches` | `matches:"\\w+_SECRET"` | Slower but powerful regex search. |

### Predicate Reference: Code-Aware (Semantic)

| Key | Example | Description |
| :--- | :--- | :--- |
| `def` | `def:User` | Finds a generic definition (class, struct, trait, etc.). |
| `func`| `func:get_user` | Finds a function or method definition. |
| `import`| `import:serde` | Finds an import/use/require statement. |
| `call`| `call:println` | Finds a function or method call site. |
| `struct`| `struct:Point` | Finds a `struct` definition. |
| `class`| `class:ApiHandler` | Finds a `class` definition. |
| `comment`| `comment:TODO` | Finds text within any comment. |
| `str` | `str:"api_key"` | Finds text within any string literal. |

### Advanced Querying Techniques

-   **The "Match All" Wildcard:** Using a single dot `.` as a value for a predicate means "match any value". This is useful for checking for the existence of a node type.
    -   `rdump "ext:rs & struct:."` &mdash; Find all Rust files that contain **any** struct definition.
    -   `rdump "ext:py & !import:."` &mdash; Find all Python files that have **no** import statements.

-   **Searching for Absence:** The `!` operator is very powerful when combined with the wildcard.
    -   `rdump "ext:js & !func:."` &mdash; Find JavaScript files that contain no functions (e.g., pure data/config files).

-   **Escaping Special Characters:** If you need to search for a literal quote, you can escape it.
    -   `rdump "str:'hello \'world\''"` &mdash; Finds the literal string `'hello 'world''`.

-   **Negating Groups:** Find Rust files that are *not* in the `tests` or `benches` directory.
    ```sh
    rdump "ext:rs & !(path:tests/ | path:benches/)"
    ```

-   **Distinguishing Content Types:** `contains:"foo"` finds `foo` anywhere. `str:"foo"` finds `foo` **only inside a string literal**. This is much more precise.

-   **Forcing Evaluation Order:** Use parentheses to ensure logical correctness for complex queries.
    ```sh
    # Find JS or TS files that either import React or define a 'Component' class
    rdump "(ext:js | ext:ts) & (import:react | class:Component)"
    ```


---

## 6. Command Reference
(Sections for `lang` and `preset` are omitted for brevity but would be here)

### `rdump search`
The primary command. Can be omitted (`rdump "ext:rs"` is the same as `rdump search "ext:rs"`).

**Usage:** `rdump [OPTIONS] <QUERY>`

**Options:**

| Flag | Alias | Description |
| :--- | :--- | :--- |
| `--format <FORMAT>` | `-f` | Sets the output format. See [Output Formats](#7-output-formats-a-visual-guide). |
| `--context <LINES>` | `-C` | Includes `<LINES>` of context around matches in `hunks` format. |
| `--preset <NAME>` | `-p` | Uses a saved query preset. |
| `--no-ignore` | | Disables all ignore logic. Searches everything. |
| `--hidden` | | Includes hidden files and directories (those starting with `.`). |
| `--config-path <PATH>` | | Path to a specific `rdump.toml` config file. |
| `--help` | `-h` | Displays help information. |
| `--version` | `-V` | Displays version information. |

---

## 7. Output Formats: A Visual Guide

| Format | Description |
| :--- | :--- |
| `hunks` | **(Default)** Shows only the matching code blocks, with optional context. |
| `markdown`| Wraps results in Markdown, useful for reports. |
| `json` | Machine-readable JSON output with file paths and content. |
| `paths` | A simple, newline-separated list of matching file paths. Perfect for piping. |
| `cat` | Concatenated content of all matching files. |
| `find` | `ls -l`-style output with permissions, size, modified date, and path. |

---

## 8. Configuration

### The `config.toml` File
`rdump` merges settings from a global and a local config file. Local settings override global ones.

- **Global Config:** `~/.config/rdump/config.toml`
- **Local Config:** `.rdump.toml` (in the current directory or any parent).

### The `.rdumpignore` System
`rdump` respects `.gitignore` by default and provides its own `.rdumpignore` for more control.

---

## 9. Extending `rdump`: Adding a New Language
Adding support for a new language is possible if there is a tree-sitter grammar available for it. This involves:
1.  Finding the `tree-sitter` grammar.
2.  Writing `.scm` query files to capture semantic nodes.
3.  Updating `rdump`'s language profiles.
4.  Recompiling.

---

## 10. Troubleshooting & FAQ
- **Q: My query is slow! Why?**
  - A: You are likely starting with an expensive predicate. Always try to filter by `ext:`, `path:`, or `name:` first.
- **Q: `rdump` isn't finding a file I know is there.**
  - A: It's probably being ignored. Run your query with `--no-ignore` to check.
- **Q: How do I search for a literal `!` or `&`?**
  - A: Quote the value, e.g., `contains:'&amp;'`.

---

## 11. Performance Benchmarks
(Illustrative) `rdump` is designed for accuracy and expressiveness, but it's still fast. On a large codebase (e.g., the Linux kernel):
- `ripgrep "some_string"`: ~0.1s
- `rdump "contains:some_string"`: ~0.5s
- `rdump "ext:c & func:some_func"`: ~2.0s

`rdump` will never beat `ripgrep` on raw text search, but `ripgrep` can't do structural search at all.

---

## 12. Contributing
Contributions are welcome! Please check the [GitHub Issues](https://github.com/user/repo/issues).

---

## 13. License
This project is licensed under the **MIT License**.

---

File: ./changes.txt
---
Excellent! This is a great feature to add, making the `in` predicate much more versatile. Here is the implementation to add wildcard support, primarily by modifying `rdump/src/predicates/in_path.rs` and its associated tests.

### 1. Add Dependency

First, you need to add the `globset` crate to your project's dependencies in `Cargo.toml`. This crate provides a fast and correct glob-matching implementation.

```toml
# In your [dependencies] section of Cargo.toml
globset = "0.4.10"
```

### 2. Updated `rdump/src/predicates/in_path.rs`

The main change is to bifurcate the logic in the `evaluate` function. If the input `value` contains glob metacharacters, we use `globset` to match against the file's parent directory. Otherwise, we retain the existing, efficient `starts_with` logic for exact paths. This provides the new functionality without breaking the old behavior.

```rust
use anyhow::Result;
use globset::Glob;
use std::path::PathBuf;

use super::PredicateEvaluator;
use crate::evaluator::{FileContext, MatchResult};
use crate::parser::PredicateKey;

pub(super) struct InPathEvaluator;

impl PredicateEvaluator for InPathEvaluator {
    fn evaluate(
        &self,
        context: &mut FileContext,
        _key: &PredicateKey,
        value: &str,
    ) -> Result<MatchResult> {
        // Check for glob metacharacters to switch between logic paths.
        if value.contains('*') || value.contains('?') || value.contains('[') || value.contains('{')
        {
            // --- Wildcard Logic ---
            let glob = Glob::new(value)?.compile_matcher();

            // We match the glob pattern against the file's parent directory.
            // If there's no parent (e.g., file is at the root "/"), it's not "in" a directory.
            if let Some(parent) = context.path.parent() {
                // The glob is matched against the entire parent path.
                // For example, a glob "**/src" will match a parent path like "/home/user/project/src".
                // A glob "/home/user/project_*/src" will also work as expected.
                Ok(MatchResult::Boolean(glob.is_match(parent)))
            } else {
                Ok(MatchResult::Boolean(false))
            }
        } else {
            // --- Existing Exact-Path Logic (for non-wildcard patterns) ---
            let target_dir = PathBuf::from(value);
            let absolute_target_dir = if target_dir.is_absolute() {
                target_dir
            } else {
                context.root.join(target_dir)
            };

            // If the target directory doesn't exist, it can't contain any files.
            if !absolute_target_dir.exists() {
                return Ok(MatchResult::Boolean(false));
            }

            // Canonicalize to resolve `.` or `..` for a reliable comparison.
            // On failure (e.g., broken symlink), we consider it a non-match rather than erroring out.
            let canonical_target = match dunce::canonicalize(&absolute_target_dir) {
                Ok(path) => path,
                Err(_) => return Ok(MatchResult::Boolean(false)),
            };
            let canonical_file_path = match dunce::canonicalize(&context.path) {
                Ok(path) => path,
                // This should not fail for a file that is being processed, but be robust.
                Err(_) => return Ok(MatchResult::Boolean(false)),
            };

            // `starts_with` handles the "is contained within" logic perfectly for exact paths.
            // e.g., a file in `/a/b/c` is also considered "in" `/a/b`.
            Ok(MatchResult::Boolean(
                canonical_file_path.starts_with(&canonical_target),
            ))
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs;
    use tempfile::tempdir;

    #[test]
    fn test_in_path_evaluator_exact() -> Result<()> {
        let evaluator = InPathEvaluator;

        // Create a temporary directory structure
        let root_dir = tempdir()?;
        let root_path = root_dir.path();

        let project_dir = root_path.join("project");
        let src_dir = project_dir.join("src");
        let other_project_dir = root_path.join("other_project");
        fs::create_dir_all(&src_dir)?;
        fs::create_dir_all(&other_project_dir)?;

        let main_rs_path = src_dir.join("main.rs");
        fs::write(&main_rs_path, "fn main() {}")?;

        // --- Test Cases ---

        let mut context = FileContext::new(main_rs_path.clone(), root_path.to_path_buf());

        // 1. Absolute Path: Exact parent directory
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::In, src_dir.to_str().unwrap())?
            .is_match());

        // 2. Absolute Path: Grandparent directory
        assert!(evaluator
            .evaluate(
                &mut context,
                &PredicateKey::In,
                project_dir.to_str().unwrap()
            )?
            .is_match());

        // 3. Absolute Path: Non-matching directory
        assert!(!evaluator
            .evaluate(
                &mut context,
                &PredicateKey::In,
                other_project_dir.to_str().unwrap()
            )?
            .is_match());

        // 4. Relative Path: from the root
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::In, "project/src")?
            .is_match());

        // 5. Relative Path: with dot-slash
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::In, "./project/src")?
            .is_match());

        // 6. Relative Path: non-matching
        assert!(!evaluator
            .evaluate(&mut context, &PredicateKey::In, "other_project")?
            .is_match());

        // 7. A file is considered to be "in" the directory represented by its own path
        assert!(evaluator
            .evaluate(
                &mut context,
                &PredicateKey::In,
                main_rs_path.to_str().unwrap()
            )?
            .is_match());

        // 8. Non-existent directory should not error, just return false
        assert!(!evaluator
            .evaluate(&mut context, &PredicateKey::In, "non_existent_dir")?
            .is_match());

        Ok(())
    }

    #[test]
    fn test_in_path_evaluator_wildcard() -> Result<()> {
        let evaluator = InPathEvaluator;

        // Create a temporary directory structure
        let root_dir = tempdir()?;
        let root_path = root_dir.path();

        let project_a_src = root_path.join("project_a").join("src");
        let project_b_source = root_path.join("project_b").join("source");
        let other_src = root_path.join("other").join("src");
        fs::create_dir_all(&project_a_src)?;
        fs::create_dir_all(&project_b_source)?;
        fs::create_dir_all(&other_src)?;

        let file_a = project_a_src.join("main.rs");
        fs::write(&file_a, "")?;
        let file_b = project_b_source.join("lib.rs");
        fs::write(&file_b, "")?;
        let file_c = other_src.join("component.js");
        fs::write(&file_c, "")?;

        let mut context_a = FileContext::new(file_a, root_path.to_path_buf());
        let mut context_b = FileContext::new(file_b, root_path.to_path_buf());
        let mut context_c = FileContext::new(file_c, root_path.to_path_buf());

        // --- Test Cases ---

        // 1. `**/src` should match files in any `src` directory
        assert!(evaluator
            .evaluate(&mut context_a, &PredicateKey::In, "**/src")?
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context_b, &PredicateKey::In, "**/src")?
            .is_match());
        assert!(evaluator
            .evaluate(&mut context_c, &PredicateKey::In, "**/src")?
            .is_match());

        // 2. `project_*/src` glob needs to match against the absolute path.
        let project_wildcard_glob = root_path
            .join("project_*")
            .join("src")
            .to_string_lossy()
            .to_string();
        assert!(evaluator
            .evaluate(&mut context_a, &PredicateKey::In, &project_wildcard_glob)?
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context_b, &PredicateKey::In, &project_wildcard_glob)?
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context_c, &PredicateKey::In, &project_wildcard_glob)?
            .is_match());

        // 3. More specific glob `**/project_a/s?c`
        assert!(evaluator
            .evaluate(&mut context_a, &PredicateKey::In, "**/project_a/s?c")?
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context_b, &PredicateKey::In, "**/project_a/s?c")?
            .is_match());

        // 4. Glob that should not match anything
        assert!(!evaluator
            .evaluate(&mut context_a, &PredicateKey::In, "**/test")?
            .is_match());

        // 5. Glob matching a different directory `**/so*ce`
        assert!(!evaluator
            .evaluate(&mut context_a, &PredicateKey::In, "**/so*ce")?
            .is_match());
        assert!(evaluator
            .evaluate(&mut context_b, &PredicateKey::In, "**/so*ce")?
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context_c, &PredicateKey::In, "**/so*ce")?
            .is_match());

        Ok(())
    }
}
```

---

File: ./docs/code-aware-spec.md
---
Of course. This is the perfect time to document our progress and solidify the vision for the future. A detailed handoff document ensures that we (or anyone else) can pick this project up and understand its purpose, current state, and future direction.

Here is the comprehensive handoff document you requested.

---

## **rdump: Project Handoff & Technical Specification**

**Version:** 1.1.0 (Feature-Complete Core)
**Date:** July 5, 2024
**Lead Collaborator:** You

### **1. Motivation & Vision: The "Why"**

#### **1.1 The Problem: The Developer-to-LLM "Context Gap"**

In the current landscape of AI-assisted development, a significant bottleneck exists in providing Large Language Models (LLMs) and AI agents with relevant context from a codebase. The standard workflow is a painful, manual ritual:

1.  Use `ls` to explore the directory structure.
2.  Use `find` with complex, often-forgotten syntax to locate potentially relevant files.
3.  Use `grep` or `ripgrep` to see if those files contain specific keywords.
4.  Finally, use `cat` to dump the contents of the discovered files into a single, massive text blob to be pasted into a prompt.

This process is slow, error-prone, and produces a low-quality result. The final output is an **unstructured firehose of text** that is noisy, lacks clear file boundaries, and often exceeds the LLM's context window with irrelevant boilerplate, comments, and imports. For an autonomous AI agent, navigating this workflow is even more difficult, requiring dozens of brittle, trial-and-error shell commands.

#### **1.2 The Solution: `rdump` - ETL for Code Context**

`rdump` was conceived to solve this problem by being a purpose-built tool for **Extracting, Transforming, and Loading** code context for language models. It bridges the "context gap" by providing a single, powerful interface to find and aggregate relevant information.

Its core strengths are:

*   **An Expressive Query Language:** Instead of arcane shell commands, `rdump` offers an intuitive, SQL-like query language (`ext:rs & (contains:'foo' | name:'*_test.rs')`) that is easy for both humans and AI agents to read, write, and generate.
*   **High-Performance Search:** Built in Rust and powered by parallel processing (`rayon`) and intelligent file discovery (`ignore`), `rdump` is designed to be exceptionally fast, even on large codebases.
*   **Structured, Agent-Ready Output:** The output is not just a text blob. It is structured (Markdown, JSON) to preserve file boundaries and metadata, making it far more useful for an LLM to reason about the provided context.

#### **1.3 Use Cases**

**For Human Developers:**

*   **Rapid Context Grabbing:** Quickly generate a context blob for a prompt: `rdump "path:src/api/ & (def:User | def:Order)" > context.txt`
*   **Codebase Exploration:** Answer complex questions about a new codebase instantly: "Find all TOML files or YAML files that mention 'database'": `rdump "(ext:toml | ext:yml) & contains:database"`
*   **Impact Analysis:** Before a refactor, find all files that import a specific module and are larger than 2kb: `rdump "import:old_module & size:>2kb"`

**For AI Agents / LLMs:**

`rdump` is designed to be the **primary file interaction tool for an AI agent**. Instead of teaching an agent to fumble with `ls`, `grep`, and `cat`, you can give it a single, powerful tool.

*   **Task:** "Refactor the `Database` class."
*   **Without `rdump`:** The agent runs `ls -R`, gets a huge list, tries `grep -r Database .`, gets thousands of results including variable names, then tries to `cat` a few likely-looking files. This is slow and inefficient.
*   **With `rdump`:** The agent can be prompted to generate a single command:
    `rdump --format=json "def:Database"`
    This one command returns a perfect, structured JSON object containing only the file(s) where the `Database` class or struct is defined. The agent can then parse this JSON and proceed with the task, having acquired perfect context in a single step.

---

### **2. The v2.0 Roadmap: Code-Aware Intelligence**

The current version of `rdump` is a powerful text-search tool. The next major phase is to transform it into a **language-aware code query engine**. The goal is to allow queries that understand the semantic structure of code, not just the characters it contains.

#### **2.1 The Vision: Semantic Search**

Users should be able to ask questions about the code's structure directly.

*   "Find the definition of the `Cli` struct in my Rust code."
    *   `rdump "def:Cli & ext:rs"`
*   "Show me all Python functions named `process_data`."
    *   `rdump "func:process_data & ext:py"`
*   "List all JavaScript files that import the `react` library."
    *   `rdump --format=paths "import:react & (ext:js | ext:tsx)"`

#### **2.2 Core Technology: `tree-sitter`**

To achieve this, we will integrate the `tree-sitter` parser generator library. `tree-sitter` is the ideal choice because it is:
*   **Fast:** Designed for real-time use in text editors.
*   **Robust:** It can gracefully handle syntax errors, producing a partial syntax tree even for incomplete code.
*   **Multi-Language:** It has a vast library of mature grammars for dozens of programming languages.

#### **2.3 The Architectural Plan: A Pluggable Abstraction Layer**

A direct implementation faces a major challenge that you correctly identified: the names for concepts like "function" or "class" are different in every language's `tree-sitter` grammar (`function_item` in Rust, `function_definition` in Python, etc.).

Our architecture will solve this with a **Language Profile Abstraction Layer**.

1.  **Universal Predicates:** We will define a set of universal `rdump` predicates (`def`, `func`, `import`, etc.).
2.  **`LanguageProfile` Struct:** For each supported language, we will create a `LanguageProfile` that maps our universal predicate names to the specific `tree-sitter` query for that language.

    *A conceptual example:*
    ```rust
    // Python Profile
    queries: {
        "def": "(class_definition name: (identifier) @match)",
        "func": "(function_definition name: (identifier) @match)"
    }

    // Rust Profile
    queries: {
        "def": "[(struct_item name: (identifier) @match) (enum_item name: (identifier) @match)]",
        "func": "(function_item name: (identifier) @match)"
    }
    ```

3.  **`CodeAwareEvaluator` Plugin:** We will create a new, smart `PredicateEvaluator` "plugin". When it evaluates a query like `def:Cli` on a `.rs` file, it will:
    a. Look up the Rust `LanguageProfile`.
    b. Get the `tree-sitter` query string associated with the `"def"` key.
    c. Parse the file using the Rust `tree-sitter` grammar.
    d. Execute the query against the resulting syntax tree.
    e. Check if any of the nodes captured by `@match` have the text `Cli`.

This design is highly modular and extensible. To add support for a new language, we simply need to write its `LanguageProfile` and add the `tree-sitter` grammar crate; no changes to the core evaluator logic will be needed.

#### **2.4 Phased Implementation Plan**

We will build this ambitious feature incrementally.

1.  **Phase 2.0 (Core Integration):** Implement the `def`, `func`, and `import` predicates for a **single language: Rust**. This will prove the architecture and provide immediate value.
2.  **Phase 2.1 (Expansion):** Add support for **Python**. This will validate the extensibility of our `LanguageProfile` design.
3.  **Phase 2.2 (Further Expansion):** Add support for other major languages like JavaScript/TypeScript, Go, etc., and consider new predicates like `call:<NAME>`.

This roadmap provides a clear path to transforming `rdump` into a next-generation developer tool, purpose-built for the age of AI-assisted programming.

---

File: ./docs/spec.md
---
Of course. Here is the complete, consolidated technical specification in a single file, incorporating all our decisions.

---

## **Technical Specification: `rdump` v1.0**

### **1. Guiding Principles & Design Philosophy**

*   **Zero-Configuration by Default:** The tool must be useful out-of-the-box with no setup. It will intelligently use common conventions like `.gitignore`.
*   **Performance is a Feature:** Every design decision will be weighed against its performance impact. We will prefer compile-time guarantees and parallel execution wherever possible.
*   **Clarity over Conciseness:** Error messages, query syntax, and output must be unambiguous, both for human users and AI agents.
*   **Deterministic Execution:** For a given filesystem state and query, the output must always be identical.

### **2. The Command-Line Interface (CLI)**

The CLI is the sole entry point for users. It is responsible for parsing all arguments and flags and passing them to the core engine.

**Command:** `rdump`

**Synopsis:** `rdump [FLAGS/OPTIONS] <QUERY_STRING>`

**Positional Arguments:**

*   **`<QUERY_STRING>`** (Required, String): A string encapsulating the query. Must be quoted by the shell to be treated as a single argument.

**Flags (Boolean Switches):**

*   `--no-ignore`: Disables all ignore file logic (`.gitignore`, `.ignore`, etc.). All files not explicitly excluded by the query are considered candidates.
*   `--hidden`: Forces the inclusion of hidden files and directories (those starting with a `.`), which are ignored by default.
*   `--line-numbers, -n`: Prepends line numbers to each line of the file content in the output. This affects `markdown` and `cat` formats. It has no effect on `json` or `paths` formats.
*   `--no-headers`: Strips all file path headers and metadata, effectively creating a concatenated stream of (optionally line-numbered) file contents. If used, it overrides the `markdown` and `json` formats, making the output equivalent to `cat`.
*   `--verbose, -v`: Prints detailed logging to `stderr`, including the parsed AST, directories being scanned, and reasons for file rejections.
*   `--help, -h`: Prints the help message and exits.
*   `--version, -V`: Prints the version number and exits.

**Options (Flags with Values):**

*   `--output <PATH>, -o <PATH>`: Redirects the formatted output to the specified file path. If not provided, output is written to `stdout`.
*   `--format <FORMAT>`: Specifies the output format.
    *   **Allowed values:** `markdown` (default), `json`, `cat`, `paths`.
    *   **Note:** If `--no-headers` is used, the effective output format will be `cat`, overriding this option.
*   `--root <DIR>`: Sets the root directory for the search. Defaults to the current working directory.
*   `--max-depth <N>`: Limits directory traversal to `N` levels deep. A depth of `0` searches only the root directory itself.
*   `--threads <N>`: Sets the number of worker threads. Defaults to the number of logical CPU cores.

---

### **3. The `rdump` Query Language (RQL)**

RQL is the core of the tool's expressiveness.

#### **3.1. Syntax and Grammar**

*   **Operators:** `&` (AND), `|` (OR), `!` (NOT).
*   **Grouping:** `( ... )` for explicit precedence.
*   **Precedence (Highest to Lowest):** `!`, then `&`, then `|`.
*   **Predicates:** `key:value` pairs.
    *   `key` is an alphanumeric identifier.
    *   `value` can be unquoted if it contains no special characters. If it contains spaces or operators, it **must** be enclosed in single `'...'` or double `"..."` quotes.

#### **3.2. Predicate Specification**

| Key (`key:value`) | Value Type | Matching Logic |
| :--- | :--- | :--- |
| **`ext`** | `string` | **Exact Match.** Matches the file extension *without* the leading dot. Case-insensitive. `ext:rs` matches `file.rs` and `file.RS`. |
| **`name`** | `glob` | **Glob Pattern Match.** Matches against the file's base name (e.g., `foo.txt`). Uses standard glob syntax (`*`, `?`, `[]`). `name:"*_test.rs"` |
| **`path`** | `string` | **Substring Match.** Matches if the value appears anywhere in the file's full canonical path. `path:src/components` |
| **`path_exact`** | `string` | **Exact Path Match.** Matches if the value is identical to the file's full canonical path. |
| **`size`** | `size_qualifier` | **Numeric Comparison.** `value` is `[>\|<][number][kb\|mb\|gb]`. No space between operator and number. `size:>100kb` |
| **`modified`** | `time_qualifier` | **Timestamp Comparison.** `value` is `[>\|<][number][s\|m\|h\|d\|w]`. `modified:<2d` matches files modified in the last 48 hours. |
| **`contains` / `c`** | `string` | **Literal Substring Search.** Case-sensitive. Reads the file content and returns true if the exact substring is found. `c:'fn main()'` |
| **`matches` / `m`** | `regex` | **Regular Expression Search.** The `value` is a regular expression. The tool will use the Rust `regex` crate. `m:'/struct \w+/'` |

---

### **4. Core Architecture & Execution Flow**

1.  **Initialization:** `clap` parses all CLI arguments. The `root` directory is canonicalized. The `rayon` thread pool is configured.

2.  **Query Parsing:** The `<QUERY_STRING>` is fed into the **Parser Module** (e.g., `pest`), which transforms it into an **Abstract Syntax Tree (AST)**. On failure, the program exits with a user-friendly syntax error.

3.  **Candidate Discovery:** A parallel directory walker (`jwalk`) discovers all files, respecting ignore-file logic (unless `--no-ignore`) and hidden file rules (unless `--hidden`).

4.  **Concurrent Evaluation Pipeline:** The stream of discovered files is piped into a `rayon` parallel iterator. For each file on a worker thread:
    a.  An internal **`FileContext`** struct is created, lazily loading path, then metadata, and finally content only when absolutely required.
    b.  The `FileContext` is evaluated against the AST using a **short-circuiting strategy**. Cheap metadata checks are performed before expensive content checks. A file is only read from disk if all preceding metadata predicates in an `&` chain pass.
    c.  If the AST evaluates to `true`, the `FileContext` is sent to the main thread for aggregation.

5.  **Result Aggregation & Sorting:** The main thread collects all matching `FileContext` objects. The final list is sorted alphabetically by path to ensure deterministic output.

6.  **Output Rendering:** The sorted list is passed to the **Formatter Module**, whose behavior is modified by the output flags:
    a.  **Internal Pre-processing:** If `--line-numbers` is active, the `content` string within each matching `FileContext` is transformed line-by-line before formatting.
    b.  **Format Logic:**
    *   **If `--no-headers` is specified:** The formatter ignores `--format`. It simply iterates through results and prints the (potentially line-numbered) content of each file.
    *   **If `--no-headers` is NOT specified:** The formatter uses `--format`:
    *   **`markdown`:** Prints a separator, metadata header, and the (potentially line-numbered) content for each file.
    *   **`json`:** The `content` field in the JSON will **always be the original, unmodified file content**. Line numbers are not injected to preserve data integrity.
    *   **`cat`:** Prints the concatenated (and potentially line-numbered) content.
    *   **`paths`:** Prints only the list of matching file paths.

---

### **5. Output Schemas**

#### **Markdown Format (Example with `--line-numbers`)**
```markdown
---
File: src/main.rs
Size: 78 B
Modified: 2023-10-29T10:30:00Z
---
    1 | use std::io;
    2 | 
    3 | fn main() {
    4 |     println!("Hello, rdump!");
    5 | }
```

#### **`cat` / `--no-headers` Format (Example with `--line-numbers`)**
*Assuming `file1.txt` ("a\nb") and `file2.txt` ("c\nd") matched:*
```
    1 | a
    2 | b
    1 | c
    2 | d
```

#### **JSON Format (Schema)**
*The output is a single JSON array `[...]`. Each object conforms to this schema:*
```json
{
  "path": "string",             // Canonical path to the file
  "size_bytes": "integer",          // File size in bytes
  "modified_iso8601": "string", // ISO 8601 formatted UTC timestamp
  "content": "string"             // The raw, original content of the file. NO line numbers.
}
```

---

File: ./dump.txt
---
File: ./GEMINI.md
---
# Gemini Notes: rdump Project

This file contains notes and observations about the `rdump` project to aid in development.

## Project Overview

- **Purpose**: `rdump` appears to be a command-line file search and query tool.
- **Primary Language**: The core logic is written in **Rust**.
- **Query Language**: It uses a custom query language, likely defined in `rdump/src/rql.pest` and parsed by `rdump/src/parser.rs`.
- **Language-Aware Features**: The presence of `rdump/src/predicates/code_aware/` and language-specific tests (`tests/go_search.rs`, `tests/java_search.rs`, etc.) suggests it has code-aware search capabilities.
- **Configuration**: Configuration is likely managed through `.rdump.toml`.

## Key Files & Directories

- `rdump/src/main.rs`: The main entry point for the application.
- `rdump/src/parser.rs`: Handles parsing the rdump query language.
- `rdump/src/evaluator.rs`: Evaluates the parsed query against the filesystem.
- `rdump/src/predicates/`: Contains the logic for different search filters (e.g., `name`, `path`, `size`, `contains`).
- `tests/`: Contains integration and CLI tests.
- `insane_test_bed/`: A directory with a wide variety of files used for testing `rdump`'s capabilities.

## Development Notes

- **Build**: The project is built using `cargo build` from the `rdump` directory.
- **Run**: The application can be run with `cargo run` from the `rdump` directory.
- **Test**: Tests are executed with `cargo test` from the `rdump` directory.
- **Formatting**: Assumed to follow standard Rust formatting (`rustfmt`).

## Development Rules

1.  **Always Add Tests**: For any bug fix or feature addition, a corresponding test must be added to verify the change and prevent regressions.
2.  **Log All Changes**: All modifications, including bug fixes and new features, must be logged in the `GEMINI_EDITS.log` file. The log entry should be dated and clearly describe the change.
3.  **Continuously Refine `GEMINI.md`**: Actively look for opportunities to improve and expand this document based on interactions and new discoveries about the project.


---

File: ./GEMINI_EDITS.log
---
2025-07-12:
- Added `contains_predicate.rs` to test the `contains` predicate.
- Added "not found" tests to `rust_search.rs`, `go_search.rs`, `java_search.rs`, `js_ts_search.rs`, and `python_search.rs`.
- Added a test for complex predicate combinations to `extended_cli.rs`.
- Added `ignore.rs` to test the `.rdumpignore` functionality.
- Fixed a bug in the `contains` predicate where it was case-sensitive.
- Fixed a bug in the `test_size_predicate` test in `extended_cli.rs`.

---

File: ./README.md
---
# `rdump` &mdash; The Definitive Developer's Guide to Code-Aware Search

**`rdump` is a next-generation, command-line tool for developers. It finds and processes files by combining filesystem metadata, content matching, and deep structural code analysis.**

[![Build Status](https://img.shields.io/github/actions/workflow/status/user/repo/rust.yml?branch=main)](https://github.com/user/repo/actions)
[![Crates.io](https://img.shields.io/crates/v/rdump.svg)](https://crates.io/crates/rdump)
[![License](https://img.shields.io/crates/l/rdump.svg)](https://github.com/user/repo/blob/main/LICENSE)

It's a developer's swiss-army knife for code discovery. It goes beyond the text-based search of tools like `grep` and `ripgrep` by using **tree-sitter** to parse your code into a syntax tree. This allows you to ask questions that are impossible for other tools to answer efficiently:

- *"Find the 'User' struct definition, but only in non-test Rust files."*
- *"Show me every call to 'console.log' in my JavaScript files with 3 lines of context."*
- *"List all Python files larger than 10KB that import 'requests' and were modified in the last week."*

`rdump` is written in Rust for blazing-fast performance, ensuring that even complex structural queries on large codebases are executed in moments.

---

## Table of Contents

1.  [**Why `rdump`?**](#1-why-rdump-a-comparative-look)
    - [The Problem with Text-Based Search](#the-problem-with-text-based-search)
    - [The `rdump` Solution: Structural Awareness](#the-rdump-solution-structural-awareness)
    - [Comparison with Other Tools](#comparison-with-other-tools)
2.  [**Architecture & Design Philosophy**](#2-architecture--design-philosophy)
    - [The Core Philosophy](#the-core-philosophy)
    - [Data Flow Diagram](#data-flow-diagram)
    - [Component Breakdown](#component-breakdown)
3.  [**Installation**](#3-installation)
    - [With Cargo (Recommended)](#with-cargo-recommended)
    - [From Pre-compiled Binaries](#from-pre-compiled-binaries)
    - [From Source](#from-source)
4.  [**Practical Recipes for Real-World Use**](#4-practical-recipes-for-real-world-use)
    - [Code Auditing & Security](#code-auditing--security)
    - [Refactoring & Maintenance](#refactoring--maintenance)
    - [Codebase Exploration & Learning](#codebase-exploration--learning)
    - [DevOps & Automation](#devops--automation)
5.  [**The `rdump` Query Language (RQL) &mdash; A Deep Dive**](#5-the-rdump-query-language-rql--a-deep-dive)
    - [Core Concepts & Syntax](#core-concepts--syntax)
    - [Evaluation Order & Performance Tips](#evaluation-order--performance-tips)
    - [Predicate Reference: Metadata](#predicate-reference-metadata)
    - [Predicate Reference: Content](#predicate-reference-content)
    - [Predicate Reference: Code-Aware (Semantic)](#predicate-reference-code-aware-semantic)
    - [Advanced Querying Techniques](#advanced-querying-techniques)
6.  [**Command Reference**](#6-command-reference)
    - [`rdump search`](#rdump-search)
    - [`rdump lang`](#rdump-lang)
    - [`rdump preset`](#rdump-preset)
7.  [**Output Formats: A Visual Guide**](#7-output-formats-a-visual-guide)
8.  [**Configuration**](#8-configuration)
    - [The `config.toml` File](#the-configtoml-file)
    - [The `.rdumpignore` System](#the-rdumpignore-system)
9.  [**Extending `rdump`: Adding a New Language**](#9-extending-rdump-adding-a-new-language)
10. [**Troubleshooting & FAQ**](#10-troubleshooting--faq)
11. [**Performance Benchmarks**](#11-performance-benchmarks)
12. [**Contributing**](#12-contributing)
13. [**License**](#13-license)

---

## 1. Why `rdump`? A Comparative Look

### The Problem with Text-Based Search

For decades, developers have relied on text-based search tools like `grep`, `ack`, and `ripgrep`. These tools are phenomenal for finding literal strings and regex patterns. However, they share a fundamental limitation: **they don't understand code.** They see a file as a flat sequence of characters.

This leads to noisy and inaccurate results for code-related questions. A `grep` for `User` will find:
- The `struct User` definition.
- A variable named `NewUser`.
- A function parameter `user_permission`.
- Comments mentioning `User`.
- String literals like `"Failed to create User"`.

### The `rdump` Solution: Structural Awareness

`rdump` sees code the way a compiler does: as a structured tree of nodes. It uses the powerful `tree-sitter` library to parse source code into a Concrete Syntax Tree (CST).

This means you can ask for `struct:User`, and `rdump` will navigate the syntax tree to find **only the node representing the definition of the `User` struct**. This is a paradigm shift in code search.

### Comparison with Other Tools

| Feature | `ripgrep` / `grep` | `semgrep` | **`rdump`** |
| :--- | :--- | :--- | :--- |
| **Search Paradigm** | Regex / Literal Text | Abstract Semantic Patterns | **Metadata + Content + Code Structure** |
| **Primary Use Case** | Finding specific lines of text | Enforcing static analysis rules | **Interactive code exploration & filtering** |
| **Speed** | Unmatched for text search | Fast for patterns | **Very fast; optimizes by layer** |
| **Query `func:foo`** | `grep "func foo"` (noisy) | `pattern: function foo(...)` | `func:foo` (precise) |
| **Query `size:>10kb`** | No | No | `size:>10kb` (built-in) |
| **Query `import:react`** | `grep "import.*react"` (noisy) | `pattern: import ... from "react"` | `import:react` (precise) |
| **Combine Filters** | Possible via shell pipes | Limited | **Natively via RQL (`&`, `|`, `!`)** |

---

## 2. Architecture, Frameworks, and Libraries: A Technical Deep Dive

`rdump`'s power and simplicity are not accidental; they are the result of deliberate architectural choices and the leveraging of best-in-class libraries from the Rust ecosystem. This section details how these pieces fit together to create a performant, modular, and extensible tool.

### The Core Philosophy: A Pipeline of Composable Filters

At its heart, `rdump` is a highly optimized pipeline. It starts with a massive set of potential files and, at each stage, applies progressively more powerful (and expensive) filters to narrow down the set.

1.  **Declarative Interface:** The user experience is paramount. We define *what* we want, not *how* to get it.
2.  **Composition over Inheritance:** Functionality is built from small, single-purpose, reusable units (predicates, formatters). This avoids complex class hierarchies and makes the system easy to reason about.
3.  **Extensibility by Design:** The architecture anticipates change. Adding a new language or predicate requires adding new data/modules, not rewriting the core evaluation logic.
4.  **Performance Through Layering:** Cheap checks (metadata) are performed first to minimize the work for expensive checks (code parsing).

### Data Flow & Component Breakdown

```
[Query String] -> [1. CLI Parser (clap)] -> [2. RQL Parser (pest)] -> [AST] -> [3. Evaluator Engine] -> [Matched Files] -> [6. Formatter (syntect)] -> [Final Output]
                                                                                    |
                                                                                    V
                                                                    [4. Predicate Trait System]
                                                                                    |
                                                                                    +------> [Metadata Predicates]
                                                                                    |
                                                                                    +------> [Content Predicates]
                                                                                    |
                                                                                    +------> [5. Semantic Engine (tree-sitter)]
```

#### 1. CLI Parsing: `clap`

-   **Library:** `clap` (Command Line Argument Parser)
-   **Role:** `clap` is the face of `rdump`. It provides a declarative macro-based API to define the entire CLI structure: subcommands (`search`, `lang`, `preset`), flags (`--format`, `-C`), and arguments (`<QUERY>`).
-   **Implementation Benefits:**
    -   **Automatic Help Generation:** `rdump --help` is generated for free, perfectly in sync with the defined CLI.
    -   **Type-Safe Parsing:** It parses arguments into strongly-typed Rust structs and enums, eliminating manual validation and parsing code.
    -   **Modularity:** The CLI definition is co-located with the `main` function, providing a single, clear entry point to the application's logic.

#### 2. RQL Parser: `pest`

-   **Library:** `pest` (Parser-Expressive Syntax Trees)
-   **Role:** `pest` transforms the human-readable RQL query string (e.g., `"ext:rs & (struct:User | !path:tests)"`) into a machine-readable Abstract Syntax Tree (AST).
-   **Implementation Benefits:**
    -   **Decoupled Grammar:** The entire RQL grammar is defined in a separate file (`src/rql.pest`). This allows the language syntax to evolve independently of the Rust code that processes it.
    -   **Resilience & Error Reporting:** `pest` generates a robust parser with excellent, human-readable error messages out of the box (e.g., "error: expected logical_op, found...").
    -   **AST Generation:** It automatically creates an iterator over the parsed pairs, which our `build_ast_from_pairs` function in `src/parser.rs` recursively walks to build our `AstNode` enum (e.g., `AstNode::LogicalOp(...)`).

#### 3. The Evaluator Engine

-   **Library:** Standard Rust
-   **Role:** The evaluator is the brain. It takes the AST from `pest` and a list of candidate files, and returns only the files that match the query.
-   **Implementation Benefits:**
    -   **Recursive Evaluation:** It's a simple, elegant recursive function that walks the `AstNode` tree. If it sees a `LogicalOp`, it calls itself on the left and right children. If it sees a `Predicate`, it dispatches to the predicate system.
    -   **Performance via Short-Circuiting:** When evaluating `ext:rs & struct:User`, if `ext:rs` returns `false`, the evaluator **immediately stops** and does not execute the expensive `struct:User` predicate. This is a critical performance optimization.

#### 4. The Predicate System: Rust's Trait System

-   **Library:** Standard Rust (specifically, `trait` objects)
-   **Role:** This is the heart of `rdump`'s modularity. Each predicate (`ext`, `size`, `contains`, `func`, etc.) is an independent module that implements a common `Predicate` trait.
-   **Implementation Benefits:**
    -   **Dynamic Dispatch:** The evaluator holds a collection of `Box<dyn Predicate>`. When it encounters a predicate key in the AST, it dynamically finds and executes the correct predicate's `evaluate()` method.
    -   **Extreme Modularity:** To add a new predicate, say `author:<name>`, a developer simply needs to:
        1.  Create a new file `src/predicates/author.rs`.
        2.  Implement the `Predicate` trait for an `AuthorPredicate` struct.
        3.  Register the new predicate in the evaluator's lookup map.
        *No other part of the codebase needs to change.*

#### 5. The Semantic Engine: `tree-sitter`

-   **Library:** `tree-sitter` and its Rust binding.
-   **Role:** `tree-sitter` is the universal parser that powers all code-aware predicates. It takes source code text and produces a concrete syntax tree.
-   **Implementation Benefits:**
    -   **Language Agnostic Core:** The core semantic predicate logic doesn't know anything about Rust, Python, or Go. It only knows how to execute a `tree-sitter` query against a syntax tree.
    -   **Data-Driven Extensibility:** A language is "supported" by providing data, not code:
        1.  The compiled `tree-sitter` grammar (as a crate).
        2.  A set of `.scm` files containing tree-sitter queries (e.g., `(function_definition name: (identifier) @func-name)`).
    -   This design means adding `func` support for a new language involves writing a one-line query in a text file, not writing complex Rust code to traverse a language-specific AST.

#### 6. Parallelism & Performance: `rayon`

-   **Library:** `rayon`
-   **Role:** `rayon` is the secret sauce for `rdump`'s performance on multi-core machines. While the evaluator processes a single query, the file search itself is a massively parallel problem. `rayon` provides incredibly simple, data-parallel iterators.
-   **Implementation Benefits:**
    -   **Effortless Parallelism:** With `rayon`, converting a sequential iterator over files into a parallel one is often a one-line change (e.g., `files.iter()` becomes `files.par_iter()`). `rayon` handles thread pooling, work-stealing, and synchronization automatically.
    -   **Fearless Concurrency:** Rust's ownership model and `rayon`'s design guarantee that this parallelism is memory-safe, preventing data races at compile time.
    -   **Scalability:** This allows `rdump` to scale its performance linearly with the number of available CPU cores, making it exceptionally fast on modern hardware when searching large numbers of files.

#### 7. The Formatter & Syntax Highlighting: `syntect`

-   **Library:** `syntect`
-   **Role:** The formatter takes the final list of matched files and hunks and presents them to the user.
-   **Implementation Benefits:**
    -   **Professional-Grade Highlighting:** `syntect` uses the same syntax and theme definitions as Sublime Text, providing robust, accurate, and beautiful highlighting for a vast number of languages.
    -   **Lazy Loading:** The `SYNTAX_SET` and `THEME_SET` are wrapped in `once_cell::sync::Lazy` to ensure they are loaded from disk and parsed only once on the first use, making subsequent runs faster.
    -   **Clean Separation:** The `Format` enum allows the `print_output` function to act as a clean dispatcher, routing to different printing functions (`print_highlighted_content`, `print_markdown_fenced_content`, etc.) based on the user's choice. This keeps the presentation logic clean and separated.

---

## 3. Installation

### With Cargo (Recommended)
If you have the Rust toolchain (`rustup`), you can install directly from Crates.io. This ensures you have the latest version.
```sh
cargo install rdump
```

### From Pre-compiled Binaries
Pre-compiled binaries for Linux, macOS, and Windows are available on the [**GitHub Releases**](https://github.com/user/repo/releases) page. Download the appropriate archive, extract the `rdump` executable, and place it in a directory on your system's `PATH`.

### From Source
To build `rdump` from source, you'll need `git` and the Rust toolchain.
```sh
git clone https://github.com/user/repo.git
cd rdump
cargo build --release
# The executable will be at ./target/release/rdump
./target/release/rdump --help
```

---

## 4. Practical Recipes for Real-World Use

### Code Auditing & Security

-   **Find potential hardcoded secrets, ignoring test data:**
    ```sh
    rdump "str:/[A-Za-z0-9_\\-]{20,}/ & !path:test"
    ```
-   **Locate all disabled or skipped tests:**
    ```sh
    rdump "(comment:ignore | comment:skip) & name:*test*"
    ```
-   **Find all raw SQL queries that are not in a `db` or `repository` package:**
    ```sh
    rdump "str:/SELECT.*FROM/ & !(path:/db/ | path:/repository/)"
    ```

### Refactoring & Maintenance

-   **Find all call sites of a function to analyze its usage before changing its signature:**
    ```sh
    rdump "call:process_payment" --format hunks -C 3
    ```
-   **Identify "god files" that might need to be broken up:**
    List Go files over 50KB.
    ```sh
    rdump "ext:go & size:>50kb" --format find
    ```
-   **Clean up dead code:** Find functions that have no corresponding calls within the project.
    ```sh
    # This is a two-step process, but rdump helps find the candidates
    rdump "ext:py & func:." --format json > funcs.json
    # Then, a script could check which function names from funcs.json are never found with a `call:` query.
    ```

### Codebase Exploration & Learning

-   **Get a high-level overview of a new Rust project's data structures:**
    ```sh
    rdump "ext:rs & (struct:. | enum:.) & !path:tests"
    ```
-   **Trace a configuration variable from definition to use:**
    ```sh
    rdump "contains:APP_PORT"
    ```
-   **Understand a project's API surface:** List all functions defined in files under an `api/` directory.
    ```sh
    rdump "path:src/api/ & func:."
    ```

### DevOps & Automation

-   **Find all Dockerfiles that don't pin to a specific image digest:**
    ```sh
    rdump "name:Dockerfile & !contains:/@sha256:/"
    ```
-   **List all TOML configuration files larger than 1KB that have been changed in the last 2 days:**
    ```sh
    rdump "ext:toml & size:>1kb & modified:<2d" --format find
    ```
-   **Pipe files to another command:** Delete all `.tmp` files older than a week.
    ```sh
    rdump "ext:tmp & modified:>7d" --format paths | xargs rm -v
    ```

### Code Quality & Consistency

-   **Find functions that are too long (e.g., > 50 lines):**
    ```sh
    # This is an approximation, but effective.
    # It finds functions where the text content of the function node is over 1200 bytes.
    rdump "func:. & size:>1200b"
    ```
-   **Enforce API conventions:** Find all `GET` endpoints that are missing a call to an authentication middleware.
    ```sh
    rdump "ext:go & func:/^Get/ & !call:requireAuth"
    ```
-   **Find magic strings/numbers:** Locate string or number literals outside of variable declarations.
    ```sh
    rdump "(str:. | contains:/ \d+;/) & !contains:/const / & !contains:/let / & !contains:/var /"
    ```

---

## 5. The `rdump` Query Language (RQL) &mdash; A Deep Dive

(This section is intentionally verbose for complete clarity.)

### Core Concepts & Syntax

-   **Predicates:** The building block of RQL is the `key:value` pair (e.g., `ext:rs`).
-   **Operators:** Combine predicates with `&` (AND), `|` (OR).
-   **Negation:** `!` negates a predicate or group (e.g., `!ext:md`).
-   **Grouping:** `()` controls the order of operations (e.g., `ext:rs & (contains:foo | contains:bar)`).
-   **Quoting:** Use `'` or `"` for values with spaces or special characters (e.g., `contains:'fn main()'`).

### Evaluation Order & Performance Tips

`rdump` is fast, but you can make it even faster by writing efficient queries. The key is to **eliminate the most files with the cheapest predicates first.**

-   **GOOD:** `ext:rs & struct:User`
    -   *Fast.* `rdump` first finds all `.rs` files (very cheap), then runs the expensive `struct` parser only on that small subset.
-   **BAD:** `struct:User & ext:rs`
    -   *Slow.* While `rdump`'s engine is smart enough to likely re-order this, writing it this way is logically less efficient. It implies parsing every file to look for a struct, then checking its extension.
-   **BEST:** `path:models/ & ext:rs & struct:User`
    -   *Blazing fast.* The search space is narrowed by path, then extension, before any files are even opened.

**Golden Rule:** Always lead with `path:`, `name:`, or `ext:` if you can.

### Predicate Reference: Metadata

| Key | Example | Description |
| :--- | :--- | :--- |
| `ext` | `ext:ts` | Matches file extension. Case-insensitive. |
| `name`| `name:"*_test.go"` | Matches filename (basename) against a glob pattern. |
| `path`| `path:src/api` | Matches if the substring appears anywhere in the full path. |
| `in`       | `in:"src/commands"`         | The directory path to search in. Matches all files that are descendants of the given directory.         |
| `size`| `size:>=10kb` | Filters by size. Operators: `>`, `<`, `>=`, `<=`, `=`. Units: `b`, `kb`, `mb`, `gb`. |
| `modified`| `modified:<2d` | Filters by modification time. Units: `m`, `h`, `d`, `w`, `y`. |

### Predicate Reference: Content

| Key | Example | Description |
| :--- | :--- | :--- |
| `contains` | `contains:"// HACK"` | Fast literal substring search. |
| `matches` | `matches:"\\w+_SECRET"` | Slower but powerful regex search. |

### Predicate Reference: Code-Aware (Semantic)

| Key | Example | Description |
| :--- | :--- | :--- |
| `def` | `def:User` | Finds a generic definition (class, struct, trait, etc.). |
| `func`| `func:get_user` | Finds a function or method definition. |
| `import`| `import:serde` | Finds an import/use/require statement. |
| `call`| `call:println` | Finds a function or method call site. |
| `struct`| `struct:Point` | Finds a `struct` definition. |
| `class`| `class:ApiHandler` | Finds a `class` definition. |
| `comment`| `comment:TODO` | Finds text within any comment. |
| `str` | `str:"api_key"` | Finds text within any string literal. |

### Advanced Querying Techniques

-   **The "Match All" Wildcard:** Using a single dot `.` as a value for a predicate means "match any value". This is useful for checking for the existence of a node type.
    -   `rdump "ext:rs & struct:."` &mdash; Find all Rust files that contain **any** struct definition.
    -   `rdump "ext:py & !import:."` &mdash; Find all Python files that have **no** import statements.

-   **Searching for Absence:** The `!` operator is very powerful when combined with the wildcard.
    -   `rdump "ext:js & !func:."` &mdash; Find JavaScript files that contain no functions (e.g., pure data/config files).

-   **Escaping Special Characters:** If you need to search for a literal quote, you can escape it.
    -   `rdump "str:'hello \'world\''"` &mdash; Finds the literal string `'hello 'world''`.

-   **Negating Groups:** Find Rust files that are *not* in the `tests` or `benches` directory.
    ```sh
    rdump "ext:rs & !(path:tests/ | path:benches/)"
    ```

-   **Distinguishing Content Types:** `contains:"foo"` finds `foo` anywhere. `str:"foo"` finds `foo` **only inside a string literal**. This is much more precise.

-   **Forcing Evaluation Order:** Use parentheses to ensure logical correctness for complex queries.
    ```sh
    # Find JS or TS files that either import React or define a 'Component' class
    rdump "(ext:js | ext:ts) & (import:react | class:Component)"
    ```


---

## 6. Command Reference
(Sections for `lang` and `preset` are omitted for brevity but would be here)

### `rdump search`
The primary command. Can be omitted (`rdump "ext:rs"` is the same as `rdump search "ext:rs"`).

**Usage:** `rdump [OPTIONS] <QUERY>`

**Options:**

| Flag | Alias | Description |
| :--- | :--- | :--- |
| `--format <FORMAT>` | `-f` | Sets the output format. See [Output Formats](#7-output-formats-a-visual-guide). |
| `--context <LINES>` | `-C` | Includes `<LINES>` of context around matches in `hunks` format. |
| `--preset <NAME>` | `-p` | Uses a saved query preset. |
| `--no-ignore` | | Disables all ignore logic. Searches everything. |
| `--hidden` | | Includes hidden files and directories (those starting with `.`). |
| `--config-path <PATH>` | | Path to a specific `rdump.toml` config file. |
| `--help` | `-h` | Displays help information. |
| `--version` | `-V` | Displays version information. |

---

## 7. Output Formats: A Visual Guide

| Format | Description |
| :--- | :--- |
| `hunks` | **(Default)** Shows only the matching code blocks, with optional context. |
| `markdown`| Wraps results in Markdown, useful for reports. |
| `json` | Machine-readable JSON output with file paths and content. |
| `paths` | A simple, newline-separated list of matching file paths. Perfect for piping. |
| `cat` | Concatenated content of all matching files. |
| `find` | `ls -l`-style output with permissions, size, modified date, and path. |

---

## 8. Configuration

### The `config.toml` File
`rdump` merges settings from a global and a local config file. Local settings override global ones.

- **Global Config:** `~/.config/rdump/config.toml`
- **Local Config:** `.rdump.toml` (in the current directory or any parent).

### The `.rdumpignore` System
`rdump` respects `.gitignore` by default and provides its own `.rdumpignore` for more control.

---

## 9. Extending `rdump`: Adding a New Language
Adding support for a new language is possible if there is a tree-sitter grammar available for it. This involves:
1.  Finding the `tree-sitter` grammar.
2.  Writing `.scm` query files to capture semantic nodes.
3.  Updating `rdump`'s language profiles.
4.  Recompiling.

---

## 10. Troubleshooting & FAQ
- **Q: My query is slow! Why?**
  - A: You are likely starting with an expensive predicate. Always try to filter by `ext:`, `path:`, or `name:` first.
- **Q: `rdump` isn't finding a file I know is there.**
  - A: It's probably being ignored. Run your query with `--no-ignore` to check.
- **Q: How do I search for a literal `!` or `&`?**
  - A: Quote the value, e.g., `contains:'&amp;'`.

---

## 11. Performance Benchmarks
(Illustrative) `rdump` is designed for accuracy and expressiveness, but it's still fast. On a large codebase (e.g., the Linux kernel):
- `ripgrep "some_string"`: ~0.1s
- `rdump "contains:some_string"`: ~0.5s
- `rdump "ext:c & func:some_func"`: ~2.0s

`rdump` will never beat `ripgrep` on raw text search, but `ripgrep` can't do structural search at all.

---

## 12. Contributing
Contributions are welcome! Please check the [GitHub Issues](https://github.com/user/repo/issues).

---

## 13. License
This project is licensed under the **MIT License**.

---

File: ./changes.txt
---
Excellent! This is a great feature to add, making the `in` predicate much more versatile. Here is the implementation to add wildcard support, primarily by modifying `rdump/src/predicates/in_path.rs` and its associated tests.

### 1. Add Dependency

First, you need to add the `globset` crate to your project's dependencies in `Cargo.toml`. This crate provides a fast and correct glob-matching implementation.

```toml
# In your [dependencies] section of Cargo.toml
globset = "0.4.10"
```

### 2. Updated `rdump/src/predicates/in_path.rs`

The main change is to bifurcate the logic in the `evaluate` function. If the input `value` contains glob metacharacters, we use `globset` to match against the file's parent directory. Otherwise, we retain the existing, efficient `starts_with` logic for exact paths. This provides the new functionality without breaking the old behavior.

```rust
use anyhow::Result;
use globset::Glob;
use std::path::PathBuf;

use super::PredicateEvaluator;
use crate::evaluator::{FileContext, MatchResult};
use crate::parser::PredicateKey;

pub(super) struct InPathEvaluator;

impl PredicateEvaluator for InPathEvaluator {
    fn evaluate(
        &self,
        context: &mut FileContext,
        _key: &PredicateKey,
        value: &str,
    ) -> Result<MatchResult> {
        // Check for glob metacharacters to switch between logic paths.
        if value.contains('*') || value.contains('?') || value.contains('[') || value.contains('{')
        {
            // --- Wildcard Logic ---
            let glob = Glob::new(value)?.compile_matcher();

            // We match the glob pattern against the file's parent directory.
            // If there's no parent (e.g., file is at the root "/"), it's not "in" a directory.
            if let Some(parent) = context.path.parent() {
                // The glob is matched against the entire parent path.
                // For example, a glob "**/src" will match a parent path like "/home/user/project/src".
                // A glob "/home/user/project_*/src" will also work as expected.
                Ok(MatchResult::Boolean(glob.is_match(parent)))
            } else {
                Ok(MatchResult::Boolean(false))
            }
        } else {
            // --- Existing Exact-Path Logic (for non-wildcard patterns) ---
            let target_dir = PathBuf::from(value);
            let absolute_target_dir = if target_dir.is_absolute() {
                target_dir
            } else {
                context.root.join(target_dir)
            };

            // If the target directory doesn't exist, it can't contain any files.
            if !absolute_target_dir.exists() {
                return Ok(MatchResult::Boolean(false));
            }

            // Canonicalize to resolve `.` or `..` for a reliable comparison.
            // On failure (e.g., broken symlink), we consider it a non-match rather than erroring out.
            let canonical_target = match dunce::canonicalize(&absolute_target_dir) {
                Ok(path) => path,
                Err(_) => return Ok(MatchResult::Boolean(false)),
            };
            let canonical_file_path = match dunce::canonicalize(&context.path) {
                Ok(path) => path,
                // This should not fail for a file that is being processed, but be robust.
                Err(_) => return Ok(MatchResult::Boolean(false)),
            };

            // `starts_with` handles the "is contained within" logic perfectly for exact paths.
            // e.g., a file in `/a/b/c` is also considered "in" `/a/b`.
            Ok(MatchResult::Boolean(
                canonical_file_path.starts_with(&canonical_target),
            ))
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs;
    use tempfile::tempdir;

    #[test]
    fn test_in_path_evaluator_exact() -> Result<()> {
        let evaluator = InPathEvaluator;

        // Create a temporary directory structure
        let root_dir = tempdir()?;
        let root_path = root_dir.path();

        let project_dir = root_path.join("project");
        let src_dir = project_dir.join("src");
        let other_project_dir = root_path.join("other_project");
        fs::create_dir_all(&src_dir)?;
        fs::create_dir_all(&other_project_dir)?;

        let main_rs_path = src_dir.join("main.rs");
        fs::write(&main_rs_path, "fn main() {}")?;

        // --- Test Cases ---

        let mut context = FileContext::new(main_rs_path.clone(), root_path.to_path_buf());

        // 1. Absolute Path: Exact parent directory
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::In, src_dir.to_str().unwrap())?
            .is_match());

        // 2. Absolute Path: Grandparent directory
        assert!(evaluator
            .evaluate(
                &mut context,
                &PredicateKey::In,
                project_dir.to_str().unwrap()
            )?
            .is_match());

        // 3. Absolute Path: Non-matching directory
        assert!(!evaluator
            .evaluate(
                &mut context,
                &PredicateKey::In,
                other_project_dir.to_str().unwrap()
            )?
            .is_match());

        // 4. Relative Path: from the root
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::In, "project/src")?
            .is_match());

        // 5. Relative Path: with dot-slash
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::In, "./project/src")?
            .is_match());

        // 6. Relative Path: non-matching
        assert!(!evaluator
            .evaluate(&mut context, &PredicateKey::In, "other_project")?
            .is_match());

        // 7. A file is considered to be "in" the directory represented by its own path
        assert!(evaluator
            .evaluate(
                &mut context,
                &PredicateKey::In,
                main_rs_path.to_str().unwrap()
            )?
            .is_match());

        // 8. Non-existent directory should not error, just return false
        assert!(!evaluator
            .evaluate(&mut context, &PredicateKey::In, "non_existent_dir")?
            .is_match());

        Ok(())
    }

    #[test]
    fn test_in_path_evaluator_wildcard() -> Result<()> {
        let evaluator = InPathEvaluator;

        // Create a temporary directory structure
        let root_dir = tempdir()?;
        let root_path = root_dir.path();

        let project_a_src = root_path.join("project_a").join("src");
        let project_b_source = root_path.join("project_b").join("source");
        let other_src = root_path.join("other").join("src");
        fs::create_dir_all(&project_a_src)?;
        fs::create_dir_all(&project_b_source)?;
        fs::create_dir_all(&other_src)?;

        let file_a = project_a_src.join("main.rs");
        fs::write(&file_a, "")?;
        let file_b = project_b_source.join("lib.rs");
        fs::write(&file_b, "")?;
        let file_c = other_src.join("component.js");
        fs::write(&file_c, "")?;

        let mut context_a = FileContext::new(file_a, root_path.to_path_buf());
        let mut context_b = FileContext::new(file_b, root_path.to_path_buf());
        let mut context_c = FileContext::new(file_c, root_path.to_path_buf());

        // --- Test Cases ---

        // 1. `**/src` should match files in any `src` directory
        assert!(evaluator
            .evaluate(&mut context_a, &PredicateKey::In, "**/src")?
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context_b, &PredicateKey::In, "**/src")?
            .is_match());
        assert!(evaluator
            .evaluate(&mut context_c, &PredicateKey::In, "**/src")?
            .is_match());

        // 2. `project_*/src` glob needs to match against the absolute path.
        let project_wildcard_glob = root_path
            .join("project_*")
            .join("src")
            .to_string_lossy()
            .to_string();
        assert!(evaluator
            .evaluate(&mut context_a, &PredicateKey::In, &project_wildcard_glob)?
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context_b, &PredicateKey::In, &project_wildcard_glob)?
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context_c, &PredicateKey::In, &project_wildcard_glob)?
            .is_match());

        // 3. More specific glob `**/project_a/s?c`
        assert!(evaluator
            .evaluate(&mut context_a, &PredicateKey::In, "**/project_a/s?c")?
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context_b, &PredicateKey::In, "**/project_a/s?c")?
            .is_match());

        // 4. Glob that should not match anything
        assert!(!evaluator
            .evaluate(&mut context_a, &PredicateKey::In, "**/test")?
            .is_match());

        // 5. Glob matching a different directory `**/so*ce`
        assert!(!evaluator
            .evaluate(&mut context_a, &PredicateKey::In, "**/so*ce")?
            .is_match());
        assert!(evaluator
            .evaluate(&mut context_b, &PredicateKey::In, "**/so*ce")?
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context_c, &PredicateKey::In, "**/so*ce")?
            .is_match());

        Ok(())
    }
}
```

---

File: ./docs/code-aware-spec.md
---
Of course. This is the perfect time to document our progress and solidify the vision for the future. A detailed handoff document ensures that we (or anyone else) can pick this project up and understand its purpose, current state, and future direction.

Here is the comprehensive handoff document you requested.

---

## **rdump: Project Handoff & Technical Specification**

**Version:** 1.1.0 (Feature-Complete Core)
**Date:** July 5, 2024
**Lead Collaborator:** You

### **1. Motivation & Vision: The "Why"**

#### **1.1 The Problem: The Developer-to-LLM "Context Gap"**

In the current landscape of AI-assisted development, a significant bottleneck exists in providing Large Language Models (LLMs) and AI agents with relevant context from a codebase. The standard workflow is a painful, manual ritual:

1.  Use `ls` to explore the directory structure.
2.  Use `find` with complex, often-forgotten syntax to locate potentially relevant files.
3.  Use `grep` or `ripgrep` to see if those files contain specific keywords.
4.  Finally, use `cat` to dump the contents of the discovered files into a single, massive text blob to be pasted into a prompt.

This process is slow, error-prone, and produces a low-quality result. The final output is an **unstructured firehose of text** that is noisy, lacks clear file boundaries, and often exceeds the LLM's context window with irrelevant boilerplate, comments, and imports. For an autonomous AI agent, navigating this workflow is even more difficult, requiring dozens of brittle, trial-and-error shell commands.

#### **1.2 The Solution: `rdump` - ETL for Code Context**

`rdump` was conceived to solve this problem by being a purpose-built tool for **Extracting, Transforming, and Loading** code context for language models. It bridges the "context gap" by providing a single, powerful interface to find and aggregate relevant information.

Its core strengths are:

*   **An Expressive Query Language:** Instead of arcane shell commands, `rdump` offers an intuitive, SQL-like query language (`ext:rs & (contains:'foo' | name:'*_test.rs')`) that is easy for both humans and AI agents to read, write, and generate.
*   **High-Performance Search:** Built in Rust and powered by parallel processing (`rayon`) and intelligent file discovery (`ignore`), `rdump` is designed to be exceptionally fast, even on large codebases.
*   **Structured, Agent-Ready Output:** The output is not just a text blob. It is structured (Markdown, JSON) to preserve file boundaries and metadata, making it far more useful for an LLM to reason about the provided context.

#### **1.3 Use Cases**

**For Human Developers:**

*   **Rapid Context Grabbing:** Quickly generate a context blob for a prompt: `rdump "path:src/api/ & (def:User | def:Order)" > context.txt`
*   **Codebase Exploration:** Answer complex questions about a new codebase instantly: "Find all TOML files or YAML files that mention 'database'": `rdump "(ext:toml | ext:yml) & contains:database"`
*   **Impact Analysis:** Before a refactor, find all files that import a specific module and are larger than 2kb: `rdump "import:old_module & size:>2kb"`

**For AI Agents / LLMs:**

`rdump` is designed to be the **primary file interaction tool for an AI agent**. Instead of teaching an agent to fumble with `ls`, `grep`, and `cat`, you can give it a single, powerful tool.

*   **Task:** "Refactor the `Database` class."
*   **Without `rdump`:** The agent runs `ls -R`, gets a huge list, tries `grep -r Database .`, gets thousands of results including variable names, then tries to `cat` a few likely-looking files. This is slow and inefficient.
*   **With `rdump`:** The agent can be prompted to generate a single command:
    `rdump --format=json "def:Database"`
    This one command returns a perfect, structured JSON object containing only the file(s) where the `Database` class or struct is defined. The agent can then parse this JSON and proceed with the task, having acquired perfect context in a single step.

---

### **2. The v2.0 Roadmap: Code-Aware Intelligence**

The current version of `rdump` is a powerful text-search tool. The next major phase is to transform it into a **language-aware code query engine**. The goal is to allow queries that understand the semantic structure of code, not just the characters it contains.

#### **2.1 The Vision: Semantic Search**

Users should be able to ask questions about the code's structure directly.

*   "Find the definition of the `Cli` struct in my Rust code."
    *   `rdump "def:Cli & ext:rs"`
*   "Show me all Python functions named `process_data`."
    *   `rdump "func:process_data & ext:py"`
*   "List all JavaScript files that import the `react` library."
    *   `rdump --format=paths "import:react & (ext:js | ext:tsx)"`

#### **2.2 Core Technology: `tree-sitter`**

To achieve this, we will integrate the `tree-sitter` parser generator library. `tree-sitter` is the ideal choice because it is:
*   **Fast:** Designed for real-time use in text editors.
*   **Robust:** It can gracefully handle syntax errors, producing a partial syntax tree even for incomplete code.
*   **Multi-Language:** It has a vast library of mature grammars for dozens of programming languages.

#### **2.3 The Architectural Plan: A Pluggable Abstraction Layer**

A direct implementation faces a major challenge that you correctly identified: the names for concepts like "function" or "class" are different in every language's `tree-sitter` grammar (`function_item` in Rust, `function_definition` in Python, etc.).

Our architecture will solve this with a **Language Profile Abstraction Layer**.

1.  **Universal Predicates:** We will define a set of universal `rdump` predicates (`def`, `func`, `import`, etc.).
2.  **`LanguageProfile` Struct:** For each supported language, we will create a `LanguageProfile` that maps our universal predicate names to the specific `tree-sitter` query for that language.

    *A conceptual example:*
    ```rust
    // Python Profile
    queries: {
        "def": "(class_definition name: (identifier) @match)",
        "func": "(function_definition name: (identifier) @match)"
    }

    // Rust Profile
    queries: {
        "def": "[(struct_item name: (identifier) @match) (enum_item name: (identifier) @match)]",
        "func": "(function_item name: (identifier) @match)"
    }
    ```

3.  **`CodeAwareEvaluator` Plugin:** We will create a new, smart `PredicateEvaluator` "plugin". When it evaluates a query like `def:Cli` on a `.rs` file, it will:
    a. Look up the Rust `LanguageProfile`.
    b. Get the `tree-sitter` query string associated with the `"def"` key.
    c. Parse the file using the Rust `tree-sitter` grammar.
    d. Execute the query against the resulting syntax tree.
    e. Check if any of the nodes captured by `@match` have the text `Cli`.

This design is highly modular and extensible. To add support for a new language, we simply need to write its `LanguageProfile` and add the `tree-sitter` grammar crate; no changes to the core evaluator logic will be needed.

#### **2.4 Phased Implementation Plan**

We will build this ambitious feature incrementally.

1.  **Phase 2.0 (Core Integration):** Implement the `def`, `func`, and `import` predicates for a **single language: Rust**. This will prove the architecture and provide immediate value.
2.  **Phase 2.1 (Expansion):** Add support for **Python**. This will validate the extensibility of our `LanguageProfile` design.
3.  **Phase 2.2 (Further Expansion):** Add support for other major languages like JavaScript/TypeScript, Go, etc., and consider new predicates like `call:<NAME>`.

This roadmap provides a clear path to transforming `rdump` into a next-generation developer tool, purpose-built for the age of AI-assisted programming.

---

File: ./docs/spec.md
---
Of course. Here is the complete, consolidated technical specification in a single file, incorporating all our decisions.

---

## **Technical Specification: `rdump` v1.0**

### **1. Guiding Principles & Design Philosophy**

*   **Zero-Configuration by Default:** The tool must be useful out-of-the-box with no setup. It will intelligently use common conventions like `.gitignore`.
*   **Performance is a Feature:** Every design decision will be weighed against its performance impact. We will prefer compile-time guarantees and parallel execution wherever possible.
*   **Clarity over Conciseness:** Error messages, query syntax, and output must be unambiguous, both for human users and AI agents.
*   **Deterministic Execution:** For a given filesystem state and query, the output must always be identical.

### **2. The Command-Line Interface (CLI)**

The CLI is the sole entry point for users. It is responsible for parsing all arguments and flags and passing them to the core engine.

**Command:** `rdump`

**Synopsis:** `rdump [FLAGS/OPTIONS] <QUERY_STRING>`

**Positional Arguments:**

*   **`<QUERY_STRING>`** (Required, String): A string encapsulating the query. Must be quoted by the shell to be treated as a single argument.

**Flags (Boolean Switches):**

*   `--no-ignore`: Disables all ignore file logic (`.gitignore`, `.ignore`, etc.). All files not explicitly excluded by the query are considered candidates.
*   `--hidden`: Forces the inclusion of hidden files and directories (those starting with a `.`), which are ignored by default.
*   `--line-numbers, -n`: Prepends line numbers to each line of the file content in the output. This affects `markdown` and `cat` formats. It has no effect on `json` or `paths` formats.
*   `--no-headers`: Strips all file path headers and metadata, effectively creating a concatenated stream of (optionally line-numbered) file contents. If used, it overrides the `markdown` and `json` formats, making the output equivalent to `cat`.
*   `--verbose, -v`: Prints detailed logging to `stderr`, including the parsed AST, directories being scanned, and reasons for file rejections.
*   `--help, -h`: Prints the help message and exits.
*   `--version, -V`: Prints the version number and exits.

**Options (Flags with Values):**

*   `--output <PATH>, -o <PATH>`: Redirects the formatted output to the specified file path. If not provided, output is written to `stdout`.
*   `--format <FORMAT>`: Specifies the output format.
    *   **Allowed values:** `markdown` (default), `json`, `cat`, `paths`.
    *   **Note:** If `--no-headers` is used, the effective output format will be `cat`, overriding this option.
*   `--root <DIR>`: Sets the root directory for the search. Defaults to the current working directory.
*   `--max-depth <N>`: Limits directory traversal to `N` levels deep. A depth of `0` searches only the root directory itself.
*   `--threads <N>`: Sets the number of worker threads. Defaults to the number of logical CPU cores.

---

### **3. The `rdump` Query Language (RQL)**

RQL is the core of the tool's expressiveness.

#### **3.1. Syntax and Grammar**

*   **Operators:** `&` (AND), `|` (OR), `!` (NOT).
*   **Grouping:** `( ... )` for explicit precedence.
*   **Precedence (Highest to Lowest):** `!`, then `&`, then `|`.
*   **Predicates:** `key:value` pairs.
    *   `key` is an alphanumeric identifier.
    *   `value` can be unquoted if it contains no special characters. If it contains spaces or operators, it **must** be enclosed in single `'...'` or double `"..."` quotes.

#### **3.2. Predicate Specification**

| Key (`key:value`) | Value Type | Matching Logic |
| :--- | :--- | :--- |
| **`ext`** | `string` | **Exact Match.** Matches the file extension *without* the leading dot. Case-insensitive. `ext:rs` matches `file.rs` and `file.RS`. |
| **`name`** | `glob` | **Glob Pattern Match.** Matches against the file's base name (e.g., `foo.txt`). Uses standard glob syntax (`*`, `?`, `[]`). `name:"*_test.rs"` |
| **`path`** | `string` | **Substring Match.** Matches if the value appears anywhere in the file's full canonical path. `path:src/components` |
| **`path_exact`** | `string` | **Exact Path Match.** Matches if the value is identical to the file's full canonical path. |
| **`size`** | `size_qualifier` | **Numeric Comparison.** `value` is `[>\|<][number][kb\|mb\|gb]`. No space between operator and number. `size:>100kb` |
| **`modified`** | `time_qualifier` | **Timestamp Comparison.** `value` is `[>\|<][number][s\|m\|h\|d\|w]`. `modified:<2d` matches files modified in the last 48 hours. |
| **`contains` / `c`** | `string` | **Literal Substring Search.** Case-sensitive. Reads the file content and returns true if the exact substring is found. `c:'fn main()'` |
| **`matches` / `m`** | `regex` | **Regular Expression Search.** The `value` is a regular expression. The tool will use the Rust `regex` crate. `m:'/struct \w+/'` |

---

### **4. Core Architecture & Execution Flow**

1.  **Initialization:** `clap` parses all CLI arguments. The `root` directory is canonicalized. The `rayon` thread pool is configured.

2.  **Query Parsing:** The `<QUERY_STRING>` is fed into the **Parser Module** (e.g., `pest`), which transforms it into an **Abstract Syntax Tree (AST)**. On failure, the program exits with a user-friendly syntax error.

3.  **Candidate Discovery:** A parallel directory walker (`jwalk`) discovers all files, respecting ignore-file logic (unless `--no-ignore`) and hidden file rules (unless `--hidden`).

4.  **Concurrent Evaluation Pipeline:** The stream of discovered files is piped into a `rayon` parallel iterator. For each file on a worker thread:
    a.  An internal **`FileContext`** struct is created, lazily loading path, then metadata, and finally content only when absolutely required.
    b.  The `FileContext` is evaluated against the AST using a **short-circuiting strategy**. Cheap metadata checks are performed before expensive content checks. A file is only read from disk if all preceding metadata predicates in an `&` chain pass.
    c.  If the AST evaluates to `true`, the `FileContext` is sent to the main thread for aggregation.

5.  **Result Aggregation & Sorting:** The main thread collects all matching `FileContext` objects. The final list is sorted alphabetically by path to ensure deterministic output.

6.  **Output Rendering:** The sorted list is passed to the **Formatter Module**, whose behavior is modified by the output flags:
    a.  **Internal Pre-processing:** If `--line-numbers` is active, the `content` string within each matching `FileContext` is transformed line-by-line before formatting.
    b.  **Format Logic:**
    *   **If `--no-headers` is specified:** The formatter ignores `--format`. It simply iterates through results and prints the (potentially line-numbered) content of each file.
    *   **If `--no-headers` is NOT specified:** The formatter uses `--format`:
    *   **`markdown`:** Prints a separator, metadata header, and the (potentially line-numbered) content for each file.
    *   **`json`:** The `content` field in the JSON will **always be the original, unmodified file content**. Line numbers are not injected to preserve data integrity.
    *   **`cat`:** Prints the concatenated (and potentially line-numbered) content.
    *   **`paths`:** Prints only the list of matching file paths.

---

### **5. Output Schemas**

#### **Markdown Format (Example with `--line-numbers`)**
```markdown
---
File: src/main.rs
Size: 78 B
Modified: 2023-10-29T10:30:00Z
---
    1 | use std::io;
    2 | 
    3 | fn main() {
    4 |     println!("Hello, rdump!");
    5 | }
```

#### **`cat` / `--no-headers` Format (Example with `--line-numbers`)**
*Assuming `file1.txt` ("a\nb") and `file2.txt` ("c\nd") matched:*
```
    1 | a
    2 | b
    1 | c
    2 | d
```

#### **JSON Format (Schema)**
*The output is a single JSON array `[...]`. Each object conforms to this schema:*
```json
{
  "path": "string",             // Canonical path to the file
  "size_bytes": "integer",          // File size in bytes
  "modified_iso8601": "string", // ISO 8601 formatted UTC timestamp
  "content": "string"             // The raw, original content of the file. NO line numbers.
}
```

---

File: ./dump.txt
---

---

File: ./insane_test_bed/ArrayListTest.java
---
import java.util.ArrayList;

public class ArrayListTest {
    public static void main(String[] args) {
        ArrayList<String> list = new ArrayList<>();
    }
}

---

File: ./insane_test_bed/HelloWorld.java
---
public class HelloWorld {
    public static void main(String[] args) {
        System.out.println("Hello, World");
    }
}

---

File: ./insane_test_bed/MyClass.java
---
import java.util.List;

public class MyClass {
    public static void main(String[] args) {
        System.out.println("Hello, World");
    }
}

---

File: ./insane_test_bed/UtilsTest.java
---
import com.mycompany.utils.List;

public class UtilsTest {
    public static void main(String[] args) {
        // Do nothing
    }
}

---

File: ./insane_test_bed/calls.rs
---
// For testing call expressions
fn callee1() {}
fn callee2() {}
fn main() {
    callee1();
    callee2();
}

---

File: ./insane_test_bed/code.js
---
// Test file for rdump
function myFunction(param) {
    console.log(`param: ${param}`);
}

class MyClass {
    constructor() {
        this.x = 1;
    }
}

---

File: ./insane_test_bed/code.py
---
# Test file for rdump
class MyClass:
    def __init__(self, value):
        self.value = value

    def my_method(self):
        """A docstring."""
        print(f"Value: {self.value}")

# A comment

---

File: ./insane_test_bed/code.rs
---
// Test file for rdump
struct MyStruct {
    field: i32,
}

fn my_func(arg: &str) -> Result<(), ()> {
    println!("Hello, {}!", arg);
    Ok(())
}

/*
A multi-line comment
*/

---

File: ./insane_test_bed/complex_query.rs
---
fn main() {
    let x = 10; // This is a comment
    let y = "hello";
    let z = MyStruct { field: 42 };
    my_func("world");
}

---

File: ./insane_test_bed/defs.py
---
class MyClass:
    pass

def my_function():
    pass

---

File: ./insane_test_bed/enum.rs
---
enum MyEnum {
    Variant1,
    Variant2,
}

---

File: ./insane_test_bed/exact_size_123.bin
---
                                                                                                                           

---

File: ./insane_test_bed/file_no_ext
---

---

File: ./insane_test_bed/hunks_context_zero.txt
---
line1\nline2\nline3\nline4\nline5

---

File: ./insane_test_bed/important.log
---

---

File: ./insane_test_bed/imports.js
---
import { a } from 'a';
import { b } from 'b';
console.log('hello');

---

File: ./insane_test_bed/imports_a.js
---
import { a } from 'a';
console.log('hello');

---

File: ./insane_test_bed/interface.ts
---
interface MyInterface {
    name: string;
}

---

File: ./insane_test_bed/large_file.txt
---
This is a large file.

---

File: ./insane_test_bed/level1/level2/hooks/my-feature/use-boolean.js
---

---

File: ./insane_test_bed/logical1.rs
---
foo

---

File: ./insane_test_bed/logical2.rs
---
bar

---

File: ./insane_test_bed/logical3.rs
---
bar baz

---

File: ./insane_test_bed/logical4.md
---
some other content

---

File: ./insane_test_bed/logical5.md
---
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 

---

File: ./insane_test_bed/main.go
---
package main

import "fmt"

func main() {
    fmt.Println("Hello, Go!")
}

---

File: ./insane_test_bed/my file with spaces.txt
---

---

File: ./insane_test_bed/not_tests/test_code.rs
---
// A file that looks like a test but isn't
#[test]
fn test_something() {
    assert_eq!(1, 1);
}

---

File: ./insane_test_bed/old_file.txt
---

---

File: ./insane_test_bed/old_large_file.txt
---
this is an old large file

---

File: ./insane_test_bed/recently_modified.txt
---
This file was recently modified.

---

File: ./insane_test_bed/same_file_def_call.rs
---
fn my_func() {
    println!("Hello from my_func!");
}

fn main() {
    my_func();
}

---

File: ./insane_test_bed/small_file.txt
---
small

---

File: ./insane_test_bed/sub/dir/some_file.txt
---

---

File: ./insane_test_bed/trait.rs
---
trait MyTrait {
    fn my_trait_method(&self);
}

---

File: ./insane_test_bed/type.rs
---
type MyType = u32;

---

File: ./insane_test_bed/type.ts
---
type MyType = string;

---

File: ./rdump/Cargo.lock
---
# This file is automatically @generated by Cargo.
# It is not intended for manual editing.
version = 4

[[package]]
name = "adler2"
version = "2.0.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "320119579fcad9c21884f5c4861d16174d0e06250625266f50fe6898340abefa"

[[package]]
name = "aho-corasick"
version = "1.1.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8e60d3430d3a69478ad0993f19238d2df97c507009a52b3c10addcd7f6bcb916"
dependencies = [
 "memchr",
]

[[package]]
name = "android-tzdata"
version = "0.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e999941b234f3131b00bc13c22d06e8c5ff726d1b6318ac7eb276997bbb4fef0"

[[package]]
name = "android_system_properties"
version = "0.1.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "819e7219dbd41043ac279b19830f2efc897156490d7fd6ea916720117ee66311"
dependencies = [
 "libc",
]

[[package]]
name = "anstream"
version = "0.6.19"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "301af1932e46185686725e0fad2f8f2aa7da69dd70bf6ecc44d6b703844a3933"
dependencies = [
 "anstyle",
 "anstyle-parse",
 "anstyle-query",
 "anstyle-wincon",
 "colorchoice",
 "is_terminal_polyfill",
 "utf8parse",
]

[[package]]
name = "anstyle"
version = "1.0.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "862ed96ca487e809f1c8e5a8447f6ee2cf102f846893800b20cebdf541fc6bbd"

[[package]]
name = "anstyle-parse"
version = "0.2.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4e7644824f0aa2c7b9384579234ef10eb7efb6a0deb83f9630a49594dd9c15c2"
dependencies = [
 "utf8parse",
]

[[package]]
name = "anstyle-query"
version = "1.1.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6c8bdeb6047d8983be085bab0ba1472e6dc604e7041dbf6fcd5e71523014fae9"
dependencies = [
 "windows-sys 0.59.0",
]

[[package]]
name = "anstyle-wincon"
version = "3.0.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "403f75924867bb1033c59fbf0797484329750cfbe3c4325cd33127941fabc882"
dependencies = [
 "anstyle",
 "once_cell_polyfill",
 "windows-sys 0.59.0",
]

[[package]]
name = "anyhow"
version = "1.0.98"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e16d2d3311acee920a9eb8d33b8cbc1787ce4a264e85f964c2404b969bdcd487"

[[package]]
name = "assert_cmd"
version = "2.0.17"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2bd389a4b2970a01282ee455294913c0a43724daedcd1a24c3eb0ec1c1320b66"
dependencies = [
 "anstyle",
 "bstr",
 "doc-comment",
 "libc",
 "predicates",
 "predicates-core",
 "predicates-tree",
 "wait-timeout",
]

[[package]]
name = "atty"
version = "0.2.14"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d9b39be18770d11421cdb1b9947a45dd3f37e93092cbf377614828a319d5fee8"
dependencies = [
 "hermit-abi",
 "libc",
 "winapi",
]

[[package]]
name = "autocfg"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c08606f8c3cbf4ce6ec8e28fb0014a2c086708fe954eaa885384a6165172e7e8"

[[package]]
name = "base64"
version = "0.22.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "72b3254f16251a8381aa12e40e3c4d2f0199f8c6508fbecb9d91f575e0fbb8c6"

[[package]]
name = "bincode"
version = "1.3.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b1f45e9417d87227c7a56d22e471c6206462cba514c7590c09aff4cf6d1ddcad"
dependencies = [
 "serde",
]

[[package]]
name = "bitflags"
version = "1.3.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bef38d45163c2f1dde094a7dfd33ccf595c92905c8f8f4fdc18d06fb1037718a"

[[package]]
name = "bitflags"
version = "2.9.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1b8e56985ec62d17e9c1001dc89c88ecd7dc08e47eba5ec7c29c7b5eeecde967"

[[package]]
name = "block-buffer"
version = "0.10.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3078c7629b62d3f0439517fa394996acacc5cbc91c5a20d8c658e77abd503a71"
dependencies = [
 "generic-array",
]

[[package]]
name = "bstr"
version = "1.12.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "234113d19d0d7d613b40e86fb654acf958910802bcceab913a4f9e7cda03b1a4"
dependencies = [
 "memchr",
 "regex-automata",
 "serde",
]

[[package]]
name = "bumpalo"
version = "3.19.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "46c5e41b57b8bba42a04676d81cb89e9ee8e859a1a66f80a5a72e1cb76b34d43"

[[package]]
name = "cc"
version = "1.0.106"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "066fce287b1d4eafef758e89e09d724a24808a9196fe9756b8ca90e86d0719a2"

[[package]]
name = "cfg-if"
version = "1.0.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9555578bc9e57714c812a1f84e4fc5b4d21fcb063490c624de019f7464c91268"

[[package]]
name = "chrono"
version = "0.4.41"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c469d952047f47f91b68d1cba3f10d63c11d73e4636f24f08daf0278abf01c4d"
dependencies = [
 "android-tzdata",
 "iana-time-zone",
 "js-sys",
 "num-traits",
 "serde",
 "wasm-bindgen",
 "windows-link",
]

[[package]]
name = "clap"
version = "4.5.40"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "40b6887a1d8685cebccf115538db5c0efe625ccac9696ad45c409d96566e910f"
dependencies = [
 "clap_builder",
 "clap_derive",
]

[[package]]
name = "clap_builder"
version = "4.5.40"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e0c66c08ce9f0c698cbce5c0279d0bb6ac936d8674174fe48f736533b964f59e"
dependencies = [
 "anstream",
 "anstyle",
 "clap_lex",
 "strsim",
]

[[package]]
name = "clap_derive"
version = "4.5.40"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d2c7947ae4cc3d851207c1adb5b5e260ff0cca11446b1d6d1423788e442257ce"
dependencies = [
 "heck",
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "clap_lex"
version = "0.7.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b94f61472cee1439c0b966b47e3aca9ae07e45d070759512cd390ea2bebc6675"

[[package]]
name = "colorchoice"
version = "1.0.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b05b61dc5112cbb17e4b6cd61790d9845d13888356391624cbe7e41efeac1e75"

[[package]]
name = "core-foundation-sys"
version = "0.8.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "773648b94d0e5d620f64f280777445740e61fe701025087ec8b57f45c791888b"

[[package]]
name = "cpufeatures"
version = "0.2.17"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "59ed5838eebb26a2bb2e58f6d5b5316989ae9d08bab10e0e6d103e656d1b0280"
dependencies = [
 "libc",
]

[[package]]
name = "crc32fast"
version = "1.4.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a97769d94ddab943e4510d138150169a2758b5ef3eb191a9ee688de3e23ef7b3"
dependencies = [
 "cfg-if",
]

[[package]]
name = "crossbeam-deque"
version = "0.8.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9dd111b7b7f7d55b72c0a6ae361660ee5853c9af73f70c3c2ef6858b950e2e51"
dependencies = [
 "crossbeam-epoch",
 "crossbeam-utils",
]

[[package]]
name = "crossbeam-epoch"
version = "0.9.18"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5b82ac4a3c2ca9c3460964f020e1402edd5753411d7737aa39c3714ad1b5420e"
dependencies = [
 "crossbeam-utils",
]

[[package]]
name = "crossbeam-utils"
version = "0.8.21"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d0a5c400df2834b80a4c3327b3aad3a4c4cd4de0629063962b03235697506a28"

[[package]]
name = "crypto-common"
version = "0.1.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1bfb12502f3fc46cca1bb51ac28df9d618d813cdc3d2f25b9fe775a34af26bb3"
dependencies = [
 "generic-array",
 "typenum",
]

[[package]]
name = "deranged"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9c9e6a11ca8224451684bc0d7d5a7adbf8f2fd6887261a1cfc3c0432f9d4068e"
dependencies = [
 "powerfmt",
]

[[package]]
name = "difflib"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6184e33543162437515c2e2b48714794e37845ec9851711914eec9d308f6ebe8"

[[package]]
name = "digest"
version = "0.10.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9ed9a281f7bc9b7576e61468ba615a66a5c8cfdff42420a70aa82701a3b1e292"
dependencies = [
 "block-buffer",
 "crypto-common",
]

[[package]]
name = "dirs"
version = "5.0.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "44c45a9d03d6676652bcb5e724c7e988de1acad23a711b5217ab9cbecbec2225"
dependencies = [
 "dirs-sys",
]

[[package]]
name = "dirs-sys"
version = "0.4.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "520f05a5cbd335fae5a99ff7a6ab8627577660ee5cfd6a94a6a929b52ff0321c"
dependencies = [
 "libc",
 "option-ext",
 "redox_users",
 "windows-sys 0.48.0",
]

[[package]]
name = "doc-comment"
version = "0.3.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "fea41bba32d969b513997752735605054bc0dfa92b4c56bf1189f2e174be7a10"

[[package]]
name = "dunce"
version = "1.0.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "92773504d58c093f6de2459af4af33faa518c13451eb8f2b5698ed3d36e7c813"

[[package]]
name = "either"
version = "1.15.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "48c757948c5ede0e46177b7add2e67155f70e33c07fea8284df6576da70b3719"

[[package]]
name = "equivalent"
version = "1.0.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "877a4ace8713b0bcf2a4e7eec82529c029f1d0619886d18145fea96c3ffe5c0f"

[[package]]
name = "errno"
version = "0.3.13"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "778e2ac28f6c47af28e4907f13ffd1e1ddbd400980a9abd7c8df189bf578a5ad"
dependencies = [
 "libc",
 "windows-sys 0.59.0",
]

[[package]]
name = "fastrand"
version = "2.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "37909eebbb50d72f9059c3b6d82c0463f2ff062c9e95845c43a6c9c0355411be"

[[package]]
name = "flate2"
version = "1.1.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4a3d7db9596fecd151c5f638c0ee5d5bd487b6e0ea232e5dc96d5250f6f94b1d"
dependencies = [
 "crc32fast",
 "miniz_oxide",
]

[[package]]
name = "float-cmp"
version = "0.10.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b09cf3155332e944990140d967ff5eceb70df778b34f77d8075db46e4704e6d8"
dependencies = [
 "num-traits",
]

[[package]]
name = "fnv"
version = "1.0.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3f9eec918d3f24069decb9af1554cad7c880e2da24a9afd88aca000531ab82c1"

[[package]]
name = "generic-array"
version = "0.14.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "85649ca51fd72272d7821adaf274ad91c288277713d9c18820d8499a7ff69e9a"
dependencies = [
 "typenum",
 "version_check",
]

[[package]]
name = "getrandom"
version = "0.2.16"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "335ff9f135e4384c8150d6f27c6daed433577f86b4750418338c01a1a2528592"
dependencies = [
 "cfg-if",
 "libc",
 "wasi 0.11.1+wasi-snapshot-preview1",
]

[[package]]
name = "getrandom"
version = "0.3.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "26145e563e54f2cadc477553f1ec5ee650b00862f0a58bcd12cbdc5f0ea2d2f4"
dependencies = [
 "cfg-if",
 "libc",
 "r-efi",
 "wasi 0.14.2+wasi-0.2.4",
]

[[package]]
name = "glob"
version = "0.3.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a8d1add55171497b4705a648c6b583acafb01d58050a51727785f0b2c8e0a2b2"

[[package]]
name = "globset"
version = "0.4.16"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "54a1028dfc5f5df5da8a56a73e6c153c9a9708ec57232470703592a3f18e49f5"
dependencies = [
 "aho-corasick",
 "bstr",
 "log",
 "regex-automata",
 "regex-syntax",
]

[[package]]
name = "hashbrown"
version = "0.15.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5971ac85611da7067dbfcabef3c70ebb5606018acd9e2a3903a0da507521e0d5"

[[package]]
name = "heck"
version = "0.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2304e00983f87ffb38b55b444b5e3b60a884b5d30c0fca7d82fe33449bbe55ea"

[[package]]
name = "hermit-abi"
version = "0.1.19"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "62b467343b94ba476dcb2500d242dadbb39557df889310ac77c5d99100aaac33"
dependencies = [
 "libc",
]

[[package]]
name = "iana-time-zone"
version = "0.1.63"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b0c919e5debc312ad217002b8048a17b7d83f80703865bbfcfebb0458b0b27d8"
dependencies = [
 "android_system_properties",
 "core-foundation-sys",
 "iana-time-zone-haiku",
 "js-sys",
 "log",
 "wasm-bindgen",
 "windows-core",
]

[[package]]
name = "iana-time-zone-haiku"
version = "0.1.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f31827a206f56af32e590ba56d5d2d085f558508192593743f16b2306495269f"
dependencies = [
 "cc",
]

[[package]]
name = "ignore"
version = "0.4.23"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6d89fd380afde86567dfba715db065673989d6253f42b88179abd3eae47bda4b"
dependencies = [
 "crossbeam-deque",
 "globset",
 "log",
 "memchr",
 "regex-automata",
 "same-file",
 "walkdir",
 "winapi-util",
]

[[package]]
name = "indexmap"
version = "2.10.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "fe4cd85333e22411419a0bcae1297d25e58c9443848b11dc6a86fefe8c78a661"
dependencies = [
 "equivalent",
 "hashbrown",
]

[[package]]
name = "is_terminal_polyfill"
version = "1.70.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7943c866cc5cd64cbc25b2e01621d07fa8eb2a1a23160ee81ce38704e97b8ecf"

[[package]]
name = "itoa"
version = "1.0.15"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4a5f13b858c8d314ee3e8f639011f7ccefe71f97f96e50151fb991f267928e2c"

[[package]]
name = "js-sys"
version = "0.3.77"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1cfaf33c695fc6e08064efbc1f72ec937429614f25eef83af942d0e227c3a28f"
dependencies = [
 "once_cell",
 "wasm-bindgen",
]

[[package]]
name = "libc"
version = "0.2.174"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1171693293099992e19cddea4e8b849964e9846f4acee11b3948bcc337be8776"

[[package]]
name = "libredox"
version = "0.1.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1580801010e535496706ba011c15f8532df6b42297d2e471fec38ceadd8c0638"
dependencies = [
 "bitflags 2.9.1",
 "libc",
]

[[package]]
name = "linked-hash-map"
version = "0.5.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0717cef1bc8b636c6e1c1bbdefc09e6322da8a9321966e8928ef80d20f7f770f"

[[package]]
name = "linux-raw-sys"
version = "0.9.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cd945864f07fe9f5371a27ad7b52a172b4b499999f1d97574c9fa68373937e12"

[[package]]
name = "log"
version = "0.4.27"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "13dc2df351e3202783a1fe0d44375f7295ffb4049267b0f3018346dc122a1d94"

[[package]]
name = "memchr"
version = "2.7.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "32a282da65faaf38286cf3be983213fcf1d2e2a58700e808f83f4ea9a4804bc0"

[[package]]
name = "miniz_oxide"
version = "0.8.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1fa76a2c86f704bdb222d66965fb3d63269ce38518b83cb0575fca855ebb6316"
dependencies = [
 "adler2",
]

[[package]]
name = "normalize-line-endings"
version = "0.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "61807f77802ff30975e01f4f071c8ba10c022052f98b3294119f3e615d13e5be"

[[package]]
name = "num-conv"
version = "0.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "51d515d32fb182ee37cda2ccdcb92950d6a3c2893aa280e540671c2cd0f3b1d9"

[[package]]
name = "num-traits"
version = "0.2.19"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "071dfc062690e90b734c0b2273ce72ad0ffa95f0c74596bc250dcfd960262841"
dependencies = [
 "autocfg",
]

[[package]]
name = "once_cell"
version = "1.21.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "42f5e15c9953c5e4ccceeb2e7382a716482c34515315f7b03532b8b4e8393d2d"

[[package]]
name = "once_cell_polyfill"
version = "1.70.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a4895175b425cb1f87721b59f0f286c2092bd4af812243672510e1ac53e2e0ad"

[[package]]
name = "onig"
version = "6.5.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "336b9c63443aceef14bea841b899035ae3abe89b7c486aaf4c5bd8aafedac3f0"
dependencies = [
 "bitflags 2.9.1",
 "libc",
 "once_cell",
 "onig_sys",
]

[[package]]
name = "onig_sys"
version = "69.9.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c7f86c6eef3d6df15f23bcfb6af487cbd2fed4e5581d58d5bf1f5f8b7f6727dc"
dependencies = [
 "cc",
 "pkg-config",
]

[[package]]
name = "option-ext"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "04744f49eae99ab78e0d5c0b603ab218f515ea8cfe5a456d7629ad883a3b6e7d"

[[package]]
name = "pest"
version = "2.8.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1db05f56d34358a8b1066f67cbb203ee3e7ed2ba674a6263a1d5ec6db2204323"
dependencies = [
 "memchr",
 "thiserror 2.0.12",
 "ucd-trie",
]

[[package]]
name = "pest_derive"
version = "2.8.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bb056d9e8ea77922845ec74a1c4e8fb17e7c218cc4fc11a15c5d25e189aa40bc"
dependencies = [
 "pest",
 "pest_generator",
]

[[package]]
name = "pest_generator"
version = "2.8.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "87e404e638f781eb3202dc82db6760c8ae8a1eeef7fb3fa8264b2ef280504966"
dependencies = [
 "pest",
 "pest_meta",
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "pest_meta"
version = "2.8.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "edd1101f170f5903fde0914f899bb503d9ff5271d7ba76bbb70bea63690cc0d5"
dependencies = [
 "pest",
 "sha2",
]

[[package]]
name = "pkg-config"
version = "0.3.32"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7edddbd0b52d732b21ad9a5fab5c704c14cd949e5e9a1ec5929a24fded1b904c"

[[package]]
name = "plist"
version = "1.7.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3af6b589e163c5a788fab00ce0c0366f6efbb9959c2f9874b224936af7fce7e1"
dependencies = [
 "base64",
 "indexmap",
 "quick-xml",
 "serde",
 "time",
]

[[package]]
name = "powerfmt"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "439ee305def115ba05938db6eb1644ff94165c5ab5e9420d1c1bcedbba909391"

[[package]]
name = "predicates"
version = "3.1.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a5d19ee57562043d37e82899fade9a22ebab7be9cef5026b07fda9cdd4293573"
dependencies = [
 "anstyle",
 "difflib",
 "float-cmp",
 "normalize-line-endings",
 "predicates-core",
 "regex",
]

[[package]]
name = "predicates-core"
version = "1.0.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "727e462b119fe9c93fd0eb1429a5f7647394014cf3c04ab2c0350eeb09095ffa"

[[package]]
name = "predicates-tree"
version = "1.0.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "72dd2d6d381dfb73a193c7fca536518d7caee39fc8503f74e7dc0be0531b425c"
dependencies = [
 "predicates-core",
 "termtree",
]

[[package]]
name = "proc-macro2"
version = "1.0.95"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "02b3e5e68a3a1a02aad3ec490a98007cbc13c37cbe84a3cd7b8e406d76e7f778"
dependencies = [
 "unicode-ident",
]

[[package]]
name = "quick-xml"
version = "0.38.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8927b0664f5c5a98265138b7e3f90aa19a6b21353182469ace36d4ac527b7b1b"
dependencies = [
 "memchr",
]

[[package]]
name = "quote"
version = "1.0.40"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1885c039570dc00dcb4ff087a89e185fd56bae234ddc7f056a945bf36467248d"
dependencies = [
 "proc-macro2",
]

[[package]]
name = "r-efi"
version = "5.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "69cdb34c158ceb288df11e18b4bd39de994f6657d83847bdffdbd7f346754b0f"

[[package]]
name = "rayon"
version = "1.10.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b418a60154510ca1a002a752ca9714984e21e4241e804d32555251faf8b78ffa"
dependencies = [
 "either",
 "rayon-core",
]

[[package]]
name = "rayon-core"
version = "1.12.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1465873a3dfdaa8ae7cb14b4383657caab0b3e8a0aa9ae8e04b044854c8dfce2"
dependencies = [
 "crossbeam-deque",
 "crossbeam-utils",
]

[[package]]
name = "rdump"
version = "0.1.0"
dependencies = [
 "anyhow",
 "assert_cmd",
 "atty",
 "chrono",
 "clap",
 "dirs",
 "dunce",
 "glob",
 "globset",
 "ignore",
 "once_cell",
 "pest",
 "pest_derive",
 "predicates",
 "rayon",
 "regex",
 "serde",
 "serde_json",
 "syntect",
 "tempfile",
 "toml",
 "tree-sitter",
 "tree-sitter-go",
 "tree-sitter-java",
 "tree-sitter-javascript",
 "tree-sitter-python",
 "tree-sitter-rust",
 "tree-sitter-typescript",
]

[[package]]
name = "redox_users"
version = "0.4.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ba009ff324d1fc1b900bd1fdb31564febe58a8ccc8a6fdbb93b543d33b13ca43"
dependencies = [
 "getrandom 0.2.16",
 "libredox",
 "thiserror 1.0.69",
]

[[package]]
name = "regex"
version = "1.11.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b544ef1b4eac5dc2db33ea63606ae9ffcfac26c1416a2806ae0bf5f56b201191"
dependencies = [
 "aho-corasick",
 "memchr",
 "regex-automata",
 "regex-syntax",
]

[[package]]
name = "regex-automata"
version = "0.4.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "809e8dc61f6de73b46c85f4c96486310fe304c434cfa43669d7b40f711150908"
dependencies = [
 "aho-corasick",
 "memchr",
 "regex-syntax",
]

[[package]]
name = "regex-syntax"
version = "0.8.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2b15c43186be67a4fd63bee50d0303afffcef381492ebe2c5d87f324e1b8815c"

[[package]]
name = "rustix"
version = "1.0.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c71e83d6afe7ff64890ec6b71d6a69bb8a610ab78ce364b3352876bb4c801266"
dependencies = [
 "bitflags 2.9.1",
 "errno",
 "libc",
 "linux-raw-sys",
 "windows-sys 0.59.0",
]

[[package]]
name = "rustversion"
version = "1.0.21"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8a0d197bd2c9dc6e53b84da9556a69ba4cdfab8619eb41a8bd1cc2027a0f6b1d"

[[package]]
name = "ryu"
version = "1.0.20"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "28d3b2b1366ec20994f1fd18c3c594f05c5dd4bc44d8bb0c1c632c8d6829481f"

[[package]]
name = "same-file"
version = "1.0.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "93fc1dc3aaa9bfed95e02e6eadabb4baf7e3078b0bd1b4d7b6b0b68378900502"
dependencies = [
 "winapi-util",
]

[[package]]
name = "serde"
version = "1.0.219"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5f0e2c6ed6606019b4e29e69dbaba95b11854410e5347d525002456dbbb786b6"
dependencies = [
 "serde_derive",
]

[[package]]
name = "serde_derive"
version = "1.0.219"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5b0276cf7f2c73365f7157c8123c21cd9a50fbbd844757af28ca1f5925fc2a00"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "serde_json"
version = "1.0.140"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "20068b6e96dc6c9bd23e01df8827e6c7e1f2fddd43c21810382803c136b99373"
dependencies = [
 "itoa",
 "memchr",
 "ryu",
 "serde",
]

[[package]]
name = "serde_spanned"
version = "0.6.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bf41e0cfaf7226dca15e8197172c295a782857fcb97fad1808a166870dee75a3"
dependencies = [
 "serde",
]

[[package]]
name = "sha2"
version = "0.10.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a7507d819769d01a365ab707794a4084392c824f54a7a6a7862f8c3d0892b283"
dependencies = [
 "cfg-if",
 "cpufeatures",
 "digest",
]

[[package]]
name = "strsim"
version = "0.11.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7da8b5736845d9f2fcb837ea5d9e2628564b3b043a70948a3f0b778838c5fb4f"

[[package]]
name = "syn"
version = "2.0.104"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "17b6f705963418cdb9927482fa304bc562ece2fdd4f616084c50b7023b435a40"
dependencies = [
 "proc-macro2",
 "quote",
 "unicode-ident",
]

[[package]]
name = "syntect"
version = "5.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "874dcfa363995604333cf947ae9f751ca3af4522c60886774c4963943b4746b1"
dependencies = [
 "bincode",
 "bitflags 1.3.2",
 "flate2",
 "fnv",
 "once_cell",
 "onig",
 "plist",
 "regex-syntax",
 "serde",
 "serde_derive",
 "serde_json",
 "thiserror 1.0.69",
 "walkdir",
 "yaml-rust",
]

[[package]]
name = "tempfile"
version = "3.20.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e8a64e3985349f2441a1a9ef0b853f869006c3855f2cda6862a94d26ebb9d6a1"
dependencies = [
 "fastrand",
 "getrandom 0.3.3",
 "once_cell",
 "rustix",
 "windows-sys 0.59.0",
]

[[package]]
name = "termtree"
version = "0.5.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8f50febec83f5ee1df3015341d8bd429f2d1cc62bcba7ea2076759d315084683"

[[package]]
name = "thiserror"
version = "1.0.69"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b6aaf5339b578ea85b50e080feb250a3e8ae8cfcdff9a461c9ec2904bc923f52"
dependencies = [
 "thiserror-impl 1.0.69",
]

[[package]]
name = "thiserror"
version = "2.0.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "567b8a2dae586314f7be2a752ec7474332959c6460e02bde30d702a66d488708"
dependencies = [
 "thiserror-impl 2.0.12",
]

[[package]]
name = "thiserror-impl"
version = "1.0.69"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4fee6c4efc90059e10f81e6d42c60a18f76588c3d74cb83a0b242a2b6c7504c1"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "thiserror-impl"
version = "2.0.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7f7cf42b4507d8ea322120659672cf1b9dbb93f8f2d4ecfd6e51350ff5b17a1d"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "time"
version = "0.3.41"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8a7619e19bc266e0f9c5e6686659d394bc57973859340060a69221e57dbc0c40"
dependencies = [
 "deranged",
 "itoa",
 "num-conv",
 "powerfmt",
 "serde",
 "time-core",
 "time-macros",
]

[[package]]
name = "time-core"
version = "0.1.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c9e9a38711f559d9e3ce1cdb06dd7c5b8ea546bc90052da6d06bb76da74bb07c"

[[package]]
name = "time-macros"
version = "0.2.22"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3526739392ec93fd8b359c8e98514cb3e8e021beb4e5f597b00a0221f8ed8a49"
dependencies = [
 "num-conv",
 "time-core",
]

[[package]]
name = "toml"
version = "0.8.23"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "dc1beb996b9d83529a9e75c17a1686767d148d70663143c7854d8b4a09ced362"
dependencies = [
 "serde",
 "serde_spanned",
 "toml_datetime",
 "toml_edit",
]

[[package]]
name = "toml_datetime"
version = "0.6.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "22cddaf88f4fbc13c51aebbf5f8eceb5c7c5a9da2ac40a13519eb5b0a0e8f11c"
dependencies = [
 "serde",
]

[[package]]
name = "toml_edit"
version = "0.22.27"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "41fe8c660ae4257887cf66394862d21dbca4a6ddd26f04a3560410406a2f819a"
dependencies = [
 "indexmap",
 "serde",
 "serde_spanned",
 "toml_datetime",
 "toml_write",
 "winnow",
]

[[package]]
name = "toml_write"
version = "0.1.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5d99f8c9a7727884afe522e9bd5edbfc91a3312b36a77b5fb8926e4c31a41801"

[[package]]
name = "tree-sitter"
version = "0.22.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "df7cc499ceadd4dcdf7ec6d4cbc34ece92c3fa07821e287aedecd4416c516dca"
dependencies = [
 "cc",
 "regex",
]

[[package]]
name = "tree-sitter-go"
version = "0.21.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b8d702a98d3c7e70e466456e58ff2b1ac550bf1e29b97e5770676d2fdabec00d"
dependencies = [
 "cc",
 "tree-sitter",
]

[[package]]
name = "tree-sitter-java"
version = "0.21.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "33bc21adf831a773c075d9d00107ab43965e6a6ea7607b47fd9ec6f3db4b481b"
dependencies = [
 "cc",
 "tree-sitter",
]

[[package]]
name = "tree-sitter-javascript"
version = "0.21.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8710a71bc6779e33811a8067bdda3ed08bed1733296ff915e44faf60f8c533d7"
dependencies = [
 "cc",
 "tree-sitter",
]

[[package]]
name = "tree-sitter-python"
version = "0.21.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b4066c6cf678f962f8c2c4561f205945c84834cce73d981e71392624fdc390a9"
dependencies = [
 "cc",
 "tree-sitter",
]

[[package]]
name = "tree-sitter-rust"
version = "0.21.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "277690f420bf90741dea984f3da038ace46c4fe6047cba57a66822226cde1c93"
dependencies = [
 "cc",
 "tree-sitter",
]

[[package]]
name = "tree-sitter-typescript"
version = "0.21.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ecb35d98a688378e56c18c9c159824fd16f730ccbea19aacf4f206e5d5438ed9"
dependencies = [
 "cc",
 "tree-sitter",
]

[[package]]
name = "typenum"
version = "1.18.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1dccffe3ce07af9386bfd29e80c0ab1a8205a2fc34e4bcd40364df902cfa8f3f"

[[package]]
name = "ucd-trie"
version = "0.1.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2896d95c02a80c6d6a5d6e953d479f5ddf2dfdb6a244441010e373ac0fb88971"

[[package]]
name = "unicode-ident"
version = "1.0.18"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5a5f39404a5da50712a4c1eecf25e90dd62b613502b7e925fd4e4d19b5c96512"

[[package]]
name = "utf8parse"
version = "0.2.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "06abde3611657adf66d383f00b093d7faecc7fa57071cce2578660c9f1010821"

[[package]]
name = "version_check"
version = "0.9.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0b928f33d975fc6ad9f86c8f283853ad26bdd5b10b7f1542aa2fa15e2289105a"

[[package]]
name = "wait-timeout"
version = "0.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "09ac3b126d3914f9849036f826e054cbabdc8519970b8998ddaf3b5bd3c65f11"
dependencies = [
 "libc",
]

[[package]]
name = "walkdir"
version = "2.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "29790946404f91d9c5d06f9874efddea1dc06c5efe94541a7d6863108e3a5e4b"
dependencies = [
 "same-file",
 "winapi-util",
]

[[package]]
name = "wasi"
version = "0.11.1+wasi-snapshot-preview1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ccf3ec651a847eb01de73ccad15eb7d99f80485de043efb2f370cd654f4ea44b"

[[package]]
name = "wasi"
version = "0.14.2+wasi-0.2.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9683f9a5a998d873c0d21fcbe3c083009670149a8fab228644b8bd36b2c48cb3"
dependencies = [
 "wit-bindgen-rt",
]

[[package]]
name = "wasm-bindgen"
version = "0.2.100"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1edc8929d7499fc4e8f0be2262a241556cfc54a0bea223790e71446f2aab1ef5"
dependencies = [
 "cfg-if",
 "once_cell",
 "rustversion",
 "wasm-bindgen-macro",
]

[[package]]
name = "wasm-bindgen-backend"
version = "0.2.100"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2f0a0651a5c2bc21487bde11ee802ccaf4c51935d0d3d42a6101f98161700bc6"
dependencies = [
 "bumpalo",
 "log",
 "proc-macro2",
 "quote",
 "syn",
 "wasm-bindgen-shared",
]

[[package]]
name = "wasm-bindgen-macro"
version = "0.2.100"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7fe63fc6d09ed3792bd0897b314f53de8e16568c2b3f7982f468c0bf9bd0b407"
dependencies = [
 "quote",
 "wasm-bindgen-macro-support",
]

[[package]]
name = "wasm-bindgen-macro-support"
version = "0.2.100"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8ae87ea40c9f689fc23f209965b6fb8a99ad69aeeb0231408be24920604395de"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
 "wasm-bindgen-backend",
 "wasm-bindgen-shared",
]

[[package]]
name = "wasm-bindgen-shared"
version = "0.2.100"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1a05d73b933a847d6cccdda8f838a22ff101ad9bf93e33684f39c1f5f0eece3d"
dependencies = [
 "unicode-ident",
]

[[package]]
name = "winapi"
version = "0.3.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5c839a674fcd7a98952e593242ea400abe93992746761e38641405d28b00f419"
dependencies = [
 "winapi-i686-pc-windows-gnu",
 "winapi-x86_64-pc-windows-gnu",
]

[[package]]
name = "winapi-i686-pc-windows-gnu"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ac3b87c63620426dd9b991e5ce0329eff545bccbbb34f3be09ff6fb6ab51b7b6"

[[package]]
name = "winapi-util"
version = "0.1.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cf221c93e13a30d793f7645a0e7762c55d169dbb0a49671918a2319d289b10bb"
dependencies = [
 "windows-sys 0.59.0",
]

[[package]]
name = "winapi-x86_64-pc-windows-gnu"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "712e227841d057c1ee1cd2fb22fa7e5a5461ae8e48fa2ca79ec42cfc1931183f"

[[package]]
name = "windows-core"
version = "0.61.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c0fdd3ddb90610c7638aa2b3a3ab2904fb9e5cdbecc643ddb3647212781c4ae3"
dependencies = [
 "windows-implement",
 "windows-interface",
 "windows-link",
 "windows-result",
 "windows-strings",
]

[[package]]
name = "windows-implement"
version = "0.60.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a47fddd13af08290e67f4acabf4b459f647552718f683a7b415d290ac744a836"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "windows-interface"
version = "0.59.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bd9211b69f8dcdfa817bfd14bf1c97c9188afa36f4750130fcdf3f400eca9fa8"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "windows-link"
version = "0.1.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5e6ad25900d524eaabdbbb96d20b4311e1e7ae1699af4fb28c17ae66c80d798a"

[[package]]
name = "windows-result"
version = "0.3.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "56f42bd332cc6c8eac5af113fc0c1fd6a8fd2aa08a0119358686e5160d0586c6"
dependencies = [
 "windows-link",
]

[[package]]
name = "windows-strings"
version = "0.4.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "56e6c93f3a0c3b36176cb1327a4958a0353d5d166c2a35cb268ace15e91d3b57"
dependencies = [
 "windows-link",
]

[[package]]
name = "windows-sys"
version = "0.48.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "677d2418bec65e3338edb076e806bc1ec15693c5d0104683f2efe857f61056a9"
dependencies = [
 "windows-targets 0.48.5",
]

[[package]]
name = "windows-sys"
version = "0.59.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1e38bc4d79ed67fd075bcc251a1c39b32a1776bbe92e5bef1f0bf1f8c531853b"
dependencies = [
 "windows-targets 0.52.6",
]

[[package]]
name = "windows-targets"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9a2fa6e2155d7247be68c096456083145c183cbbbc2764150dda45a87197940c"
dependencies = [
 "windows_aarch64_gnullvm 0.48.5",
 "windows_aarch64_msvc 0.48.5",
 "windows_i686_gnu 0.48.5",
 "windows_i686_msvc 0.48.5",
 "windows_x86_64_gnu 0.48.5",
 "windows_x86_64_gnullvm 0.48.5",
 "windows_x86_64_msvc 0.48.5",
]

[[package]]
name = "windows-targets"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9b724f72796e036ab90c1021d4780d4d3d648aca59e491e6b98e725b84e99973"
dependencies = [
 "windows_aarch64_gnullvm 0.52.6",
 "windows_aarch64_msvc 0.52.6",
 "windows_i686_gnu 0.52.6",
 "windows_i686_gnullvm",
 "windows_i686_msvc 0.52.6",
 "windows_x86_64_gnu 0.52.6",
 "windows_x86_64_gnullvm 0.52.6",
 "windows_x86_64_msvc 0.52.6",
]

[[package]]
name = "windows_aarch64_gnullvm"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2b38e32f0abccf9987a4e3079dfb67dcd799fb61361e53e2882c3cbaf0d905d8"

[[package]]
name = "windows_aarch64_gnullvm"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "32a4622180e7a0ec044bb555404c800bc9fd9ec262ec147edd5989ccd0c02cd3"

[[package]]
name = "windows_aarch64_msvc"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "dc35310971f3b2dbbf3f0690a219f40e2d9afcf64f9ab7cc1be722937c26b4bc"

[[package]]
name = "windows_aarch64_msvc"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "09ec2a7bb152e2252b53fa7803150007879548bc709c039df7627cabbd05d469"

[[package]]
name = "windows_i686_gnu"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a75915e7def60c94dcef72200b9a8e58e5091744960da64ec734a6c6e9b3743e"

[[package]]
name = "windows_i686_gnu"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8e9b5ad5ab802e97eb8e295ac6720e509ee4c243f69d781394014ebfe8bbfa0b"

[[package]]
name = "windows_i686_gnullvm"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0eee52d38c090b3caa76c563b86c3a4bd71ef1a819287c19d586d7334ae8ed66"

[[package]]
name = "windows_i686_msvc"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8f55c233f70c4b27f66c523580f78f1004e8b5a8b659e05a4eb49d4166cca406"

[[package]]
name = "windows_i686_msvc"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "240948bc05c5e7c6dabba28bf89d89ffce3e303022809e73deaefe4f6ec56c66"

[[package]]
name = "windows_x86_64_gnu"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "53d40abd2583d23e4718fddf1ebec84dbff8381c07cae67ff7768bbf19c6718e"

[[package]]
name = "windows_x86_64_gnu"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "147a5c80aabfbf0c7d901cb5895d1de30ef2907eb21fbbab29ca94c5b08b1a78"

[[package]]
name = "windows_x86_64_gnullvm"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0b7b52767868a23d5bab768e390dc5f5c55825b6d30b86c844ff2dc7414044cc"

[[package]]
name = "windows_x86_64_gnullvm"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "24d5b23dc417412679681396f2b49f3de8c1473deb516bd34410872eff51ed0d"

[[package]]
name = "windows_x86_64_msvc"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ed94fce61571a4006852b7389a063ab983c02eb1bb37b47f8272ce92d06d9538"

[[package]]
name = "windows_x86_64_msvc"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "589f6da84c646204747d1270a2a5661ea66ed1cced2631d546fdfb155959f9ec"

[[package]]
name = "winnow"
version = "0.7.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "74c7b26e3480b707944fc872477815d29a8e429d2f93a1ce000f5fa84a15cbcd"
dependencies = [
 "memchr",
]

[[package]]
name = "wit-bindgen-rt"
version = "0.39.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6f42320e61fe2cfd34354ecb597f86f413484a798ba44a8ca1165c58d42da6c1"
dependencies = [
 "bitflags 2.9.1",
]

[[package]]
name = "yaml-rust"
version = "0.4.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "56c1936c4cc7a1c9ab21a1ebb602eb942ba868cbd44a99cb7cdc5892335e1c85"
dependencies = [
 "linked-hash-map",
]

---

File: ./rdump/Cargo.toml
---
[package]
name = "rdump"
version = "0.1.0"
edition = "2021"

[dependencies]
clap = { version = "4.5.4", features = ["derive"] }
anyhow = "1.0.86"
ignore = "0.4.22"
rayon = "1.10.0"
regex = "1.10.4"
serde = { version = "1.0.203", features = ["derive"] }
serde_json = "1.0.117"
pest = "2.7.10"
pest_derive = "2.7.10"
tempfile = "3.10.1" # Version from dev-dependencies was newer, consolidated here.
glob = "0.3.1"
dirs = "5.0.1"
toml = "0.8.12"
chrono = { version = "0.4", features = ["serde"] }
once_cell = "1.19.0" # Replaced lazy_static
tree-sitter = "0.22.6"
tree-sitter-rust = "0.21.0"
tree-sitter-python = "0.21.0"
tree-sitter-javascript = "0.21.0"
tree-sitter-typescript = "0.21.0"
tree-sitter-go = "0.21.0"
tree-sitter-java = "0.21.0"
syntect = "5.2.0"
atty = "0.2.14"
dunce = "1.0.4"
globset = "0.4.10"

[dev-dependencies]
assert_cmd = "2.0.14"
predicates = "3.1.0"
tree-sitter-rust = "0.21.0"

[[test]]
name = "rust_search_traits"
path = "tests/rust_search_traits.rs"

[[test]]
name = "rust_search_macros"
path = "tests/rust_search_macros.rs"

---

File: ./rdump/GEMINI_EDITS.log
---
2025-07-12: Fixed a regression where color codes were still present in the output file when using the --output flag. The logic was patched to disable colors when --output is used, unless --color=always is also specified. Added integration tests to verify this behavior and prevent future regressions.

---

File: ./rdump/README.md
---
# `rdump` &mdash; The Definitive Developer's Guide to Code-Aware Search

**`rdump` is a next-generation, command-line tool for developers. It finds and processes files by combining filesystem metadata, content matching, and deep structural code analysis.**

[![Build Status](https://img.shields.io/github/actions/workflow/status/user/repo/rust.yml?branch=main)](https://github.com/user/repo/actions)
[![Crates.io](https://img.shields.io/crates/v/rdump.svg)](https://crates.io/crates/rdump)
[![License](https://img.shields.io/crates/l/rdump.svg)](https://github.com/user/repo/blob/main/LICENSE)

It's a developer's swiss-army knife for code discovery. It goes beyond the text-based search of tools like `grep` and `ripgrep` by using **tree-sitter** to parse your code into a syntax tree. This allows you to ask questions that are impossible for other tools to answer efficiently:

- *"Find the 'User' struct definition, but only in non-test Rust files."*
- *"Show me every call to 'console.log' in my JavaScript files with 3 lines of context."*
- *"List all Python files larger than 10KB that import 'requests' and were modified in the last week."*

`rdump` is written in Rust for blazing-fast performance, ensuring that even complex structural queries on large codebases are executed in moments.

---

## Table of Contents

1.  [**Why `rdump`?**](#1-why-rdump-a-comparative-look)
    - [The Problem with Text-Based Search](#the-problem-with-text-based-search)
    - [The `rdump` Solution: Structural Awareness](#the-rdump-solution-structural-awareness)
    - [Comparison with Other Tools](#comparison-with-other-tools)
2.  [**Architecture & Design Philosophy**](#2-architecture--design-philosophy)
    - [The Core Philosophy](#the-core-philosophy)
    - [Data Flow Diagram](#data-flow-diagram)
    - [Component Breakdown](#component-breakdown)
3.  [**Installation**](#3-installation)
    - [With Cargo (Recommended)](#with-cargo-recommended)
    - [From Pre-compiled Binaries](#from-pre-compiled-binaries)
    - [From Source](#from-source)
4.  [**Practical Recipes for Real-World Use**](#4-practical-recipes-for-real-world-use)
    - [Code Auditing & Security](#code-auditing--security)
    - [Refactoring & Maintenance](#refactoring--maintenance)
    - [Codebase Exploration & Learning](#codebase-exploration--learning)
    - [DevOps & Automation](#devops--automation)
5.  [**The `rdump` Query Language (RQL) &mdash; A Deep Dive**](#5-the-rdump-query-language-rql--a-deep-dive)
    - [Core Concepts & Syntax](#core-concepts--syntax)
    - [Evaluation Order & Performance Tips](#evaluation-order--performance-tips)
    - [Predicate Reference: Metadata](#predicate-reference-metadata)
    - [Predicate Reference: Content](#predicate-reference-content)
    - [Predicate Reference: Code-Aware (Semantic)](#predicate-reference-code-aware-semantic)
    - [Advanced Querying Techniques](#advanced-querying-techniques)
6.  [**Command Reference**](#6-command-reference)
    - [`rdump search`](#rdump-search)
    - [`rdump lang`](#rdump-lang)
    - [`rdump preset`](#rdump-preset)
7.  [**Output Formats: A Visual Guide**](#7-output-formats-a-visual-guide)
8.  [**Configuration**](#8-configuration)
    - [The `config.toml` File](#the-configtoml-file)
    - [The `.rdumpignore` System](#the-rdumpignore-system)
9.  [**Extending `rdump`: Adding a New Language**](#9-extending-rdump-adding-a-new-language)
10. [**Troubleshooting & FAQ**](#10-troubleshooting--faq)
11. [**Performance Benchmarks**](#11-performance-benchmarks)
12. [**Contributing**](#12-contributing)
13. [**License**](#13-license)

---

## 1. Why `rdump`? A Comparative Look

### The Problem with Text-Based Search

For decades, developers have relied on text-based search tools like `grep`, `ack`, and `ripgrep`. These tools are phenomenal for finding literal strings and regex patterns. However, they share a fundamental limitation: **they don't understand code.** They see a file as a flat sequence of characters.

This leads to noisy and inaccurate results for code-related questions. A `grep` for `User` will find:
- The `struct User` definition.
- A variable named `NewUser`.
- A function parameter `user_permission`.
- Comments mentioning `User`.
- String literals like `"Failed to create User"`.

### The `rdump` Solution: Structural Awareness

`rdump` sees code the way a compiler does: as a structured tree of nodes. It uses the powerful `tree-sitter` library to parse source code into a Concrete Syntax Tree (CST).

This means you can ask for `struct:User`, and `rdump` will navigate the syntax tree to find **only the node representing the definition of the `User` struct**. This is a paradigm shift in code search.

### Comparison with Other Tools

| Feature | `ripgrep` / `grep` | `semgrep` | **`rdump`** |
| :--- | :--- | :--- | :--- |
| **Search Paradigm** | Regex / Literal Text | Abstract Semantic Patterns | **Metadata + Content + Code Structure** |
| **Primary Use Case** | Finding specific lines of text | Enforcing static analysis rules | **Interactive code exploration & filtering** |
| **Speed** | Unmatched for text search | Fast for patterns | **Very fast; optimizes by layer** |
| **Query `func:foo`** | `grep "func foo"` (noisy) | `pattern: function foo(...)` | `func:foo` (precise) |
| **Query `size:>10kb`** | No | No | `size:>10kb` (built-in) |
| **Query `import:react`** | `grep "import.*react"` (noisy) | `pattern: import ... from "react"` | `import:react` (precise) |
| **Combine Filters** | Possible via shell pipes | Limited | **Natively via RQL (`&`, `|`, `!`)** |

---

## 2. Architecture, Frameworks, and Libraries: A Technical Deep Dive

`rdump`'s power and simplicity are not accidental; they are the result of deliberate architectural choices and the leveraging of best-in-class libraries from the Rust ecosystem. This section details how these pieces fit together to create a performant, modular, and extensible tool.

### The Core Philosophy: A Pipeline of Composable Filters

At its heart, `rdump` is a highly optimized pipeline. It starts with a massive set of potential files and, at each stage, applies progressively more powerful (and expensive) filters to narrow down the set.

1.  **Declarative Interface:** The user experience is paramount. We define *what* we want, not *how* to get it.
2.  **Composition over Inheritance:** Functionality is built from small, single-purpose, reusable units (predicates, formatters). This avoids complex class hierarchies and makes the system easy to reason about.
3.  **Extensibility by Design:** The architecture anticipates change. Adding a new language or predicate requires adding new data/modules, not rewriting the core evaluation logic.
4.  **Performance Through Layering:** Cheap checks (metadata) are performed first to minimize the work for expensive checks (code parsing).

### Data Flow & Component Breakdown

```
[Query String] -> [1. CLI Parser (clap)] -> [2. RQL Parser (pest)] -> [AST] -> [3. Evaluator Engine] -> [Matched Files] -> [6. Formatter (syntect)] -> [Final Output]
                                                                                    |
                                                                                    V
                                                                    [4. Predicate Trait System]
                                                                                    |
                                                                                    +------> [Metadata Predicates]
                                                                                    |
                                                                                    +------> [Content Predicates]
                                                                                    |
                                                                                    +------> [5. Semantic Engine (tree-sitter)]
```

#### 1. CLI Parsing: `clap`

-   **Library:** `clap` (Command Line Argument Parser)
-   **Role:** `clap` is the face of `rdump`. It provides a declarative macro-based API to define the entire CLI structure: subcommands (`search`, `lang`, `preset`), flags (`--format`, `-C`), and arguments (`<QUERY>`).
-   **Implementation Benefits:**
    -   **Automatic Help Generation:** `rdump --help` is generated for free, perfectly in sync with the defined CLI.
    -   **Type-Safe Parsing:** It parses arguments into strongly-typed Rust structs and enums, eliminating manual validation and parsing code.
    -   **Modularity:** The CLI definition is co-located with the `main` function, providing a single, clear entry point to the application's logic.

#### 2. RQL Parser: `pest`

-   **Library:** `pest` (Parser-Expressive Syntax Trees)
-   **Role:** `pest` transforms the human-readable RQL query string (e.g., `"ext:rs & (struct:User | !path:tests)"`) into a machine-readable Abstract Syntax Tree (AST).
-   **Implementation Benefits:**
    -   **Decoupled Grammar:** The entire RQL grammar is defined in a separate file (`src/rql.pest`). This allows the language syntax to evolve independently of the Rust code that processes it.
    -   **Resilience & Error Reporting:** `pest` generates a robust parser with excellent, human-readable error messages out of the box (e.g., "error: expected logical_op, found...").
    -   **AST Generation:** It automatically creates an iterator over the parsed pairs, which our `build_ast_from_pairs` function in `src/parser.rs` recursively walks to build our `AstNode` enum (e.g., `AstNode::LogicalOp(...)`).

#### 3. The Evaluator Engine

-   **Library:** Standard Rust
-   **Role:** The evaluator is the brain. It takes the AST from `pest` and a list of candidate files, and returns only the files that match the query.
-   **Implementation Benefits:**
    -   **Recursive Evaluation:** It's a simple, elegant recursive function that walks the `AstNode` tree. If it sees a `LogicalOp`, it calls itself on the left and right children. If it sees a `Predicate`, it dispatches to the predicate system.
    -   **Performance via Short-Circuiting:** When evaluating `ext:rs & struct:User`, if `ext:rs` returns `false`, the evaluator **immediately stops** and does not execute the expensive `struct:User` predicate. This is a critical performance optimization.

#### 4. The Predicate System: Rust's Trait System

-   **Library:** Standard Rust (specifically, `trait` objects)
-   **Role:** This is the heart of `rdump`'s modularity. Each predicate (`ext`, `size`, `contains`, `func`, etc.) is an independent module that implements a common `Predicate` trait.
-   **Implementation Benefits:**
    -   **Dynamic Dispatch:** The evaluator holds a collection of `Box<dyn Predicate>`. When it encounters a predicate key in the AST, it dynamically finds and executes the correct predicate's `evaluate()` method.
    -   **Extreme Modularity:** To add a new predicate, say `author:<name>`, a developer simply needs to:
        1.  Create a new file `src/predicates/author.rs`.
        2.  Implement the `Predicate` trait for an `AuthorPredicate` struct.
        3.  Register the new predicate in the evaluator's lookup map.
        *No other part of the codebase needs to change.*

#### 5. The Semantic Engine: `tree-sitter`

-   **Library:** `tree-sitter` and its Rust binding.
-   **Role:** `tree-sitter` is the universal parser that powers all code-aware predicates. It takes source code text and produces a concrete syntax tree.
-   **Implementation Benefits:**
    -   **Language Agnostic Core:** The core semantic predicate logic doesn't know anything about Rust, Python, or Go. It only knows how to execute a `tree-sitter` query against a syntax tree.
    -   **Data-Driven Extensibility:** A language is "supported" by providing data, not code:
        1.  The compiled `tree-sitter` grammar (as a crate).
        2.  A set of `.scm` files containing tree-sitter queries (e.g., `(function_definition name: (identifier) @func-name)`).
    -   This design means adding `func` support for a new language involves writing a one-line query in a text file, not writing complex Rust code to traverse a language-specific AST.

#### 6. Parallelism & Performance: `rayon`

-   **Library:** `rayon`
-   **Role:** `rayon` is the secret sauce for `rdump`'s performance on multi-core machines. While the evaluator processes a single query, the file search itself is a massively parallel problem. `rayon` provides incredibly simple, data-parallel iterators.
-   **Implementation Benefits:**
    -   **Effortless Parallelism:** With `rayon`, converting a sequential iterator over files into a parallel one is often a one-line change (e.g., `files.iter()` becomes `files.par_iter()`). `rayon` handles thread pooling, work-stealing, and synchronization automatically.
    -   **Fearless Concurrency:** Rust's ownership model and `rayon`'s design guarantee that this parallelism is memory-safe, preventing data races at compile time.
    -   **Scalability:** This allows `rdump` to scale its performance linearly with the number of available CPU cores, making it exceptionally fast on modern hardware when searching large numbers of files.

#### 7. The Formatter & Syntax Highlighting: `syntect`

-   **Library:** `syntect`
-   **Role:** The formatter takes the final list of matched files and hunks and presents them to the user.
-   **Implementation Benefits:**
    -   **Professional-Grade Highlighting:** `syntect` uses the same syntax and theme definitions as Sublime Text, providing robust, accurate, and beautiful highlighting for a vast number of languages.
    -   **Lazy Loading:** The `SYNTAX_SET` and `THEME_SET` are wrapped in `once_cell::sync::Lazy` to ensure they are loaded from disk and parsed only once on the first use, making subsequent runs faster.
    -   **Clean Separation:** The `Format` enum allows the `print_output` function to act as a clean dispatcher, routing to different printing functions (`print_highlighted_content`, `print_markdown_fenced_content`, etc.) based on the user's choice. This keeps the presentation logic clean and separated.

---

## 3. Installation

### With Cargo (Recommended)
If you have the Rust toolchain (`rustup`), you can install directly from Crates.io. This ensures you have the latest version.
```sh
cargo install rdump
```

### From Pre-compiled Binaries
Pre-compiled binaries for Linux, macOS, and Windows are available on the [**GitHub Releases**](https://github.com/user/repo/releases) page. Download the appropriate archive, extract the `rdump` executable, and place it in a directory on your system's `PATH`.

### From Source
To build `rdump` from source, you'll need `git` and the Rust toolchain.
```sh
git clone https://github.com/user/repo.git
cd rdump
cargo build --release
# The executable will be at ./target/release/rdump
./target/release/rdump --help
```

---

## 4. Practical Recipes for Real-World Use

### Code Auditing & Security

-   **Find potential hardcoded secrets, ignoring test data:**
    ```sh
    rdump "str:/[A-Za-z0-9_\\-]{20,}/ & !path:test"
    ```
-   **Locate all disabled or skipped tests:**
    ```sh
    rdump "(comment:ignore | comment:skip) & name:*test*"
    ```
-   **Find all raw SQL queries that are not in a `db` or `repository` package:**
    ```sh
    rdump "str:/SELECT.*FROM/ & !(path:/db/ | path:/repository/)"
    ```

### Refactoring & Maintenance

-   **Find all call sites of a function to analyze its usage before changing its signature:**
    ```sh
    rdump "call:process_payment" --format hunks -C 3
    ```
-   **Identify "god files" that might need to be broken up:**
    List Go files over 50KB.
    ```sh
    rdump "ext:go & size:>50kb" --format find
    ```
-   **Clean up dead code:** Find functions that have no corresponding calls within the project.
    ```sh
    # This is a two-step process, but rdump helps find the candidates
    rdump "ext:py & func:." --format json > funcs.json
    # Then, a script could check which function names from funcs.json are never found with a `call:` query.
    ```

### Codebase Exploration & Learning

-   **Get a high-level overview of a new Rust project's data structures:**
    ```sh
    rdump "ext:rs & (struct:. | enum:.) & !path:tests"
    ```
-   **Trace a configuration variable from definition to use:**
    ```sh
    rdump "contains:APP_PORT"
    ```
-   **Understand a project's API surface:** List all functions defined in files under an `api/` directory.
    ```sh
    rdump "path:src/api/ & func:."
    ```

### DevOps & Automation

-   **Find all Dockerfiles that don't pin to a specific image digest:**
    ```sh
    rdump "name:Dockerfile & !contains:/@sha256:/"
    ```
-   **List all TOML configuration files larger than 1KB that have been changed in the last 2 days:**
    ```sh
    rdump "ext:toml & size:>1kb & modified:<2d" --format find
    ```
-   **Pipe files to another command:** Delete all `.tmp` files older than a week.
    ```sh
    rdump "ext:tmp & modified:>7d" --format paths | xargs rm -v
    ```

### Code Quality & Consistency

-   **Find functions that are too long (e.g., > 50 lines):**
    ```sh
    # This is an approximation, but effective.
    # It finds functions where the text content of the function node is over 1200 bytes.
    rdump "func:. & size:>1200b"
    ```
-   **Enforce API conventions:** Find all `GET` endpoints that are missing a call to an authentication middleware.
    ```sh
    rdump "ext:go & func:/^Get/ & !call:requireAuth"
    ```
-   **Find magic strings/numbers:** Locate string or number literals outside of variable declarations.
    ```sh
    rdump "(str:. | contains:/ \d+;/) & !contains:/const / & !contains:/let / & !contains:/var /"
    ```

---

## 5. The `rdump` Query Language (RQL) &mdash; A Deep Dive

(This section is intentionally verbose for complete clarity.)

### Core Concepts & Syntax

-   **Predicates:** The building block of RQL is the `key:value` pair (e.g., `ext:rs`).
-   **Operators:** Combine predicates with `&` (AND), `|` (OR).
-   **Negation:** `!` negates a predicate or group (e.g., `!ext:md`).
-   **Grouping:** `()` controls the order of operations (e.g., `ext:rs & (contains:foo | contains:bar)`).
-   **Quoting:** Use `'` or `"` for values with spaces or special characters (e.g., `contains:'fn main()'`).

### Evaluation Order & Performance Tips

`rdump` is fast, but you can make it even faster by writing efficient queries. The key is to **eliminate the most files with the cheapest predicates first.**

-   **GOOD:** `ext:rs & struct:User`
    -   *Fast.* `rdump` first finds all `.rs` files (very cheap), then runs the expensive `struct` parser only on that small subset.
-   **BAD:** `struct:User & ext:rs`
    -   *Slow.* While `rdump`'s engine is smart enough to likely re-order this, writing it this way is logically less efficient. It implies parsing every file to look for a struct, then checking its extension.
-   **BEST:** `path:models/ & ext:rs & struct:User`
    -   *Blazing fast.* The search space is narrowed by path, then extension, before any files are even opened.

**Golden Rule:** Always lead with `path:`, `name:`, or `ext:` if you can.

### Predicate Reference: Metadata

| Key | Example | Description |
| :--- | :--- | :--- |
| `ext` | `ext:ts` | Matches file extension. Case-insensitive. |
| `name`| `name:"*_test.go"` | Matches filename (basename) against a glob pattern. |
| `path`| `path:src/api` | Matches if the substring appears anywhere in the full path. |
| `in`       | `in:"src/commands"`         | The directory path to search in. Matches all files that are descendants of the given directory.         |
| `size`| `size:>=10kb` | Filters by size. Operators: `>`, `<`, `>=`, `<=`, `=`. Units: `b`, `kb`, `mb`, `gb`. |
| `modified`| `modified:<2d` | Filters by modification time. Units: `m`, `h`, `d`, `w`, `y`. |

### Predicate Reference: Content

| Key | Example | Description |
| :--- | :--- | :--- |
| `contains` | `contains:"// HACK"` | Fast literal substring search. |
| `matches` | `matches:"\\w+_SECRET"` | Slower but powerful regex search. |

### Predicate Reference: Code-Aware (Semantic)

| Key | Example | Description |
| :--- | :--- | :--- |
| `def` | `def:User` | Finds a generic definition (class, struct, trait, etc.). |
| `func`| `func:get_user` | Finds a function or method definition. |
| `import`| `import:serde` | Finds an import/use/require statement. |
| `call`| `call:println` | Finds a function or method call site. |
| `struct`| `struct:Point` | Finds a `struct` definition. |
| `class`| `class:ApiHandler` | Finds a `class` definition. |
| `comment`| `comment:TODO` | Finds text within any comment. |
| `str` | `str:"api_key"` | Finds text within any string literal. |

### Advanced Querying Techniques

-   **The "Match All" Wildcard:** Using a single dot `.` as a value for a predicate means "match any value". This is useful for checking for the existence of a node type.
    -   `rdump "ext:rs & struct:."` &mdash; Find all Rust files that contain **any** struct definition.
    -   `rdump "ext:py & !import:."` &mdash; Find all Python files that have **no** import statements.

-   **Searching for Absence:** The `!` operator is very powerful when combined with the wildcard.
    -   `rdump "ext:js & !func:."` &mdash; Find JavaScript files that contain no functions (e.g., pure data/config files).

-   **Escaping Special Characters:** If you need to search for a literal quote, you can escape it.
    -   `rdump "str:'hello \'world\''"` &mdash; Finds the literal string `'hello 'world''`.

-   **Negating Groups:** Find Rust files that are *not* in the `tests` or `benches` directory.
    ```sh
    rdump "ext:rs & !(path:tests/ | path:benches/)"
    ```

-   **Distinguishing Content Types:** `contains:"foo"` finds `foo` anywhere. `str:"foo"` finds `foo` **only inside a string literal**. This is much more precise.

-   **Forcing Evaluation Order:** Use parentheses to ensure logical correctness for complex queries.
    ```sh
    # Find JS or TS files that either import React or define a 'Component' class
    rdump "(ext:js | ext:ts) & (import:react | class:Component)"
    ```


---

## 6. Command Reference
(Sections for `lang` and `preset` are omitted for brevity but would be here)

### `rdump search`
The primary command. Can be omitted (`rdump "ext:rs"` is the same as `rdump search "ext:rs"`).

**Usage:** `rdump [OPTIONS] <QUERY>`

**Options:**

| Flag | Alias | Description |
| :--- | :--- | :--- |
| `--format <FORMAT>` | `-f` | Sets the output format. See [Output Formats](#7-output-formats-a-visual-guide). |
| `--context <LINES>` | `-C` | Includes `<LINES>` of context around matches in `hunks` format. |
| `--preset <NAME>` | `-p` | Uses a saved query preset. |
| `--no-ignore` | | Disables all ignore logic. Searches everything. |
| `--hidden` | | Includes hidden files and directories (those starting with `.`). |
| `--config-path <PATH>` | | Path to a specific `rdump.toml` config file. |
| `--help` | `-h` | Displays help information. |
| `--version` | `-V` | Displays version information. |

---

## 7. Output Formats: A Visual Guide

| Format | Description |
| :--- | :--- |
| `hunks` | **(Default)** Shows only the matching code blocks, with optional context. |
| `markdown`| Wraps results in Markdown, useful for reports. |
| `json` | Machine-readable JSON output with file paths and content. |
| `paths` | A simple, newline-separated list of matching file paths. Perfect for piping. |
| `cat` | Concatenated content of all matching files. |
| `find` | `ls -l`-style output with permissions, size, modified date, and path. |

---

## 8. Configuration

### The `config.toml` File
`rdump` merges settings from a global and a local config file. Local settings override global ones.

- **Global Config:** `~/.config/rdump/config.toml`
- **Local Config:** `.rdump.toml` (in the current directory or any parent).

### The `.rdumpignore` System
`rdump` respects `.gitignore` by default and provides its own `.rdumpignore` for more control.

---

## 9. Extending `rdump`: Adding a New Language
Adding support for a new language is possible if there is a tree-sitter grammar available for it. This involves:
1.  Finding the `tree-sitter` grammar.
2.  Writing `.scm` query files to capture semantic nodes.
3.  Updating `rdump`'s language profiles.
4.  Recompiling.

---

## 10. Troubleshooting & FAQ
- **Q: My query is slow! Why?**
  - A: You are likely starting with an expensive predicate. Always try to filter by `ext:`, `path:`, or `name:` first.
- **Q: `rdump` isn't finding a file I know is there.**
  - A: It's probably being ignored. Run your query with `--no-ignore` to check.
- **Q: How do I search for a literal `!` or `&`?**
  - A: Quote the value, e.g., `contains:'&amp;'`.

---

## 11. Performance Benchmarks
(Illustrative) `rdump` is designed for accuracy and expressiveness, but it's still fast. On a large codebase (e.g., the Linux kernel):
- `ripgrep "some_string"`: ~0.1s
- `rdump "contains:some_string"`: ~0.5s
- `rdump "ext:c & func:some_func"`: ~2.0s

`rdump` will never beat `ripgrep` on raw text search, but `ripgrep` can't do structural search at all.

---

## 12. Contributing
Contributions are welcome! Please check the [GitHub Issues](https://github.com/user/repo/issues).

---

## 13. License
This project is licensed under the **MIT License**.

---

File: ./rdump/dump.ts
---
import * as fs from 'fs';
import * as path from 'path';

async function dumpFiles() {
  const projectRoot = path.resolve(__dirname, '..');
  const dumpFilePath = path.join(__dirname, 'dump.txt');
  const cargoTomlPath = path.join(__dirname, 'Cargo.toml');
  const srcDir = path.join(__dirname, 'src');

  const findRustFiles = (dir: string): string[] => {
    let results: string[] = [];
    const list = fs.readdirSync(dir);
    list.forEach((file) => {
      file = path.join(dir, file);
      const stat = fs.statSync(file);
      if (stat && stat.isDirectory()) {
        results = results.concat(findRustFiles(file));
      } else if (file.endsWith('.rs')) {
        results.push(file);
      }
    });
    return results;
  };

  try {
    const rustFiles = findRustFiles(srcDir);
    const filesToDump = [cargoTomlPath, ...rustFiles];

    let dumpContent = '';

    for (const filePath of filesToDump) {
      const projectRelativePath = path.relative(projectRoot, filePath);
      dumpContent += `// START ${projectRelativePath}\n\n`;
      const fileContent = fs.readFileSync(filePath, 'utf-8');
      dumpContent += fileContent;
      dumpContent += `\n\n// END ${projectRelativePath}\n\n`;
    }

    fs.writeFileSync(dumpFilePath, dumpContent);
    console.log(`Successfully dumped files to ${dumpFilePath}`);
  } catch (error) {
    console.error('Error dumping files:', error);
  }
}

dumpFiles();

---

File: ./rdump/evaluator.rs
---
use anyhow::{anyhow, Context, Result};
use std::collections::HashMap;
use std::fs;
use std::path::PathBuf;
use tree_sitter::{Parser, Range, Tree};

use crate::parser::{AstNode, LogicalOperator, PredicateKey};
use crate::predicates::PredicateEvaluator;

/// The result of an evaluation for a single file.
#[derive(Debug, Clone)]
pub enum MatchResult {
    // For simple, non-hunkable predicates like `ext:rs` or `size:>10kb`
    Boolean(bool),
    // For code-aware predicates that can identify specific code blocks.
    Hunks(Vec<Range>),
}

/// Holds the context for a single file being evaluated.
/// It lazily loads content and caches the tree-sitter AST.
pub struct FileContext {
    pub path: PathBuf,
    content: Option<String>,
    // Cache for the parsed tree-sitter AST
    tree: Option<Tree>,
}

impl FileContext {
    pub fn new(path: PathBuf) -> Self {
        FileContext {
            path,
            content: None,
            tree: None,
        }
    }

    pub fn get_content(&mut self) -> Result<&str> {
        if self.content.is_none() {
            let content = fs::read_to_string(&self.path)
                .with_context(|| format!("Failed to read file {}", self.path.display()))?;
            self.content = Some(content);
        }
        Ok(self.content.as_ref().unwrap())
    }

    // Lazily parses the file with tree-sitter and caches the result.
    pub fn get_tree(&mut self, language: tree_sitter::Language) -> Result<&Tree> {
        if self.tree.is_none() {
            let path_display = self.path.display().to_string();
            let content = self.get_content()?;
            let mut parser = Parser::new();
            parser.set_language(&language).with_context(|| {
                format!("Failed to set language for tree-sitter parser on {path_display}")
            })?;
            let tree = parser
                .parse(content, None)
                .ok_or_else(|| anyhow!("Tree-sitter failed to parse {}", path_display))?;
            self.tree = Some(tree);
        }
        Ok(self.tree.as_ref().unwrap())
    }
}

/// The main evaluator struct. It holds the AST and the predicate registry.
pub struct Evaluator {
    ast: AstNode,
    registry: HashMap<PredicateKey, Box<dyn PredicateEvaluator + Send + Sync>>,
}

impl Evaluator {
    pub fn new(
        ast: AstNode,
        registry: HashMap<PredicateKey, Box<dyn PredicateEvaluator + Send + Sync>>,
    ) -> Self {
        Evaluator { ast, registry }
    }

    /// Evaluates the query for a given file path.
    pub fn evaluate(&self, context: &mut FileContext) -> Result<MatchResult> {
        self.evaluate_node(&self.ast, context)
    }

    /// Recursively evaluates an AST node.
    fn evaluate_node(&self, node: &AstNode, context: &mut FileContext) -> Result<MatchResult> {
        match node {
            AstNode::Predicate(key, value) => self.evaluate_predicate(key, value, context),
            AstNode::LogicalOp(op, left, right) => {
                let left_res = self.evaluate_node(left, context)?;

                // Short-circuit AND if left is false
                if *op == LogicalOperator::And && !left_res.is_match() {
                    return Ok(MatchResult::Boolean(false));
                }

                // Short-circuit OR if left is a full-file match
                if *op == LogicalOperator::Or {
                    if let MatchResult::Boolean(true) = left_res {
                        return Ok(left_res);
                    }
                }

                let right_res = self.evaluate_node(right, context)?;
                Ok(left_res.combine_with(right_res, op))
            }
            AstNode::Not(inner_node) => {
                // If the inner predicate of a NOT is not in the registry (e.g., a content
                // predicate during the metadata-only pass), we cannot definitively say the file
                // *doesn't* match. We must assume it *could* match and let the full evaluator decide.
                if let AstNode::Predicate(key, _) = &**inner_node {
                    if !self.registry.contains_key(key) {
                        return Ok(MatchResult::Boolean(true));
                    }
                }
                let result = self.evaluate_node(inner_node, context)?;
                Ok(MatchResult::Boolean(!result.is_match()))
            }
        }
    }

    /// Evaluates a single predicate.
    fn evaluate_predicate(
        &self,
        key: &PredicateKey,
        value: &str,
        context: &mut FileContext,
    ) -> Result<MatchResult> {
        if let Some(evaluator) = self.registry.get(key) {
            evaluator.evaluate(context, key, value)
        } else {
            // If a predicate is not in the current registry (e.g., a content predicate
            // during the metadata-only pass), it's considered a "pass" for this stage.
            Ok(MatchResult::Boolean(true))
        }
    }
}

impl MatchResult {
    /// Returns true if the result is considered a match.
    pub fn is_match(&self) -> bool {
        match self {
            MatchResult::Boolean(b) => *b,
            MatchResult::Hunks(h) => !h.is_empty(),
        }
    }

    /// Combines two match results based on a logical operator.
    pub fn combine_with(self, other: MatchResult, op: &LogicalOperator) -> Self {
        match op {
            LogicalOperator::And => {
                if !self.is_match() || !other.is_match() {
                    return MatchResult::Boolean(false);
                }
                match (self, other) {
                    (MatchResult::Hunks(mut a), MatchResult::Hunks(b)) => {
                        a.extend(b);
                        a.sort_by_key(|r| r.start_byte);
                        a.dedup();
                        MatchResult::Hunks(a)
                    }
                    (h @ MatchResult::Hunks(_), MatchResult::Boolean(true)) => h,
                    (MatchResult::Boolean(true), h @ MatchResult::Hunks(_)) => h,
                    (MatchResult::Boolean(true), MatchResult::Boolean(true)) => MatchResult::Boolean(true),
                    _ => MatchResult::Boolean(false),
                }
            }
            LogicalOperator::Or => {
                match (self, other) {
                    (MatchResult::Boolean(true), _) | (_, MatchResult::Boolean(true)) => MatchResult::Boolean(true),
                    (MatchResult::Hunks(mut a), MatchResult::Hunks(b)) => {
                        a.extend(b);
                        a.sort_by_key(|r| r.start_byte);
                        a.dedup();
                        MatchResult::Hunks(a)
                    }
                    (h @ MatchResult::Hunks(_), MatchResult::Boolean(false)) => h,
                    (MatchResult::Boolean(false), h @ MatchResult::Hunks(_)) => h,
                    (MatchResult::Boolean(false), MatchResult::Boolean(false)) => MatchResult::Boolean(false),
                }
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::parser::parse_query;
    use crate::predicates;
    use std::io::Write;
    use tempfile::NamedTempFile;

    fn create_temp_file(content: &str) -> NamedTempFile {
        let file = NamedTempFile::new().unwrap();
        write!(file.as_file(), "{}", content).unwrap();
        file
    }

    #[test]
    fn test_evaluate_logical_and() {
        let file = create_temp_file("hello world");
        let mut context = FileContext::new(file.path().to_path_buf());
        let ast = parse_query("contains:hello & contains:world").unwrap();
        let evaluator = Evaluator::new(ast, predicates::create_predicate_registry());
        assert!(evaluator.evaluate(&mut context).unwrap().is_match());

        let ast_fail = parse_query("contains:hello & contains:goodbye").unwrap();
        let evaluator_fail = Evaluator::new(ast_fail, predicates::create_predicate_registry());
        assert!(!evaluator_fail.evaluate(&mut context).unwrap().is_match());
    }
}

---

File: ./rdump/package-lock.json
---
{
  "name": "rdump",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {
    "": {
      "devDependencies": {
        "@types/node": "^24.0.10",
        "ts-node": "^10.9.2",
        "typescript": "^5.8.3"
      }
    },
    "node_modules/@cspotcode/source-map-support": {
      "version": "0.8.1",
      "resolved": "https://registry.npmjs.org/@cspotcode/source-map-support/-/source-map-support-0.8.1.tgz",
      "integrity": "sha512-IchNf6dN4tHoMFIn/7OE8LWZ19Y6q/67Bmf6vnGREv8RSbBVb9LPJxEcnwrcwX6ixSvaiGoomAUvu4YSxXrVgw==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/trace-mapping": "0.3.9"
      },
      "engines": {
        "node": ">=12"
      }
    },
    "node_modules/@jridgewell/resolve-uri": {
      "version": "3.1.2",
      "resolved": "https://registry.npmjs.org/@jridgewell/resolve-uri/-/resolve-uri-3.1.2.tgz",
      "integrity": "sha512-bRISgCIjP20/tbWSPWMEi54QVPRZExkuD9lJL+UIxUKtwVJA8wW1Trb1jMs1RFXo1CBTNZ/5hpC9QvmKWdopKw==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6.0.0"
      }
    },
    "node_modules/@jridgewell/sourcemap-codec": {
      "version": "1.5.4",
      "resolved": "https://registry.npmjs.org/@jridgewell/sourcemap-codec/-/sourcemap-codec-1.5.4.tgz",
      "integrity": "sha512-VT2+G1VQs/9oz078bLrYbecdZKs912zQlkelYpuf+SXF+QvZDYJlbx/LSx+meSAwdDFnF8FVXW92AVjjkVmgFw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@jridgewell/trace-mapping": {
      "version": "0.3.9",
      "resolved": "https://registry.npmjs.org/@jridgewell/trace-mapping/-/trace-mapping-0.3.9.tgz",
      "integrity": "sha512-3Belt6tdc8bPgAtbcmdtNJlirVoTmEb5e2gC94PnkwEW9jI6CAHUeoG85tjWP5WquqfavoMtMwiG4P926ZKKuQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@jridgewell/resolve-uri": "^3.0.3",
        "@jridgewell/sourcemap-codec": "^1.4.10"
      }
    },
    "node_modules/@tsconfig/node10": {
      "version": "1.0.11",
      "resolved": "https://registry.npmjs.org/@tsconfig/node10/-/node10-1.0.11.tgz",
      "integrity": "sha512-DcRjDCujK/kCk/cUe8Xz8ZSpm8mS3mNNpta+jGCA6USEDfktlNvm1+IuZ9eTcDbNk41BHwpHHeW+N1lKCz4zOw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@tsconfig/node12": {
      "version": "1.0.11",
      "resolved": "https://registry.npmjs.org/@tsconfig/node12/-/node12-1.0.11.tgz",
      "integrity": "sha512-cqefuRsh12pWyGsIoBKJA9luFu3mRxCA+ORZvA4ktLSzIuCUtWVxGIuXigEwO5/ywWFMZ2QEGKWvkZG1zDMTag==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@tsconfig/node14": {
      "version": "1.0.3",
      "resolved": "https://registry.npmjs.org/@tsconfig/node14/-/node14-1.0.3.tgz",
      "integrity": "sha512-ysT8mhdixWK6Hw3i1V2AeRqZ5WfXg1G43mqoYlM2nc6388Fq5jcXyr5mRsqViLx/GJYdoL0bfXD8nmF+Zn/Iow==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@tsconfig/node16": {
      "version": "1.0.4",
      "resolved": "https://registry.npmjs.org/@tsconfig/node16/-/node16-1.0.4.tgz",
      "integrity": "sha512-vxhUy4J8lyeyinH7Azl1pdd43GJhZH/tP2weN8TntQblOY+A0XbT8DJk1/oCPuOOyg/Ja757rG0CgHcWC8OfMA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/@types/node": {
      "version": "24.0.10",
      "resolved": "https://registry.npmjs.org/@types/node/-/node-24.0.10.tgz",
      "integrity": "sha512-ENHwaH+JIRTDIEEbDK6QSQntAYGtbvdDXnMXnZaZ6k13Du1dPMmprkEHIL7ok2Wl2aZevetwTAb5S+7yIF+enA==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "undici-types": "~7.8.0"
      }
    },
    "node_modules/acorn": {
      "version": "8.15.0",
      "resolved": "https://registry.npmjs.org/acorn/-/acorn-8.15.0.tgz",
      "integrity": "sha512-NZyJarBfL7nWwIq+FDL6Zp/yHEhePMNnnJ0y3qfieCrmNvYct8uvtiV41UvlSe6apAfk0fY1FbWx+NwfmpvtTg==",
      "dev": true,
      "license": "MIT",
      "bin": {
        "acorn": "bin/acorn"
      },
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/acorn-walk": {
      "version": "8.3.4",
      "resolved": "https://registry.npmjs.org/acorn-walk/-/acorn-walk-8.3.4.tgz",
      "integrity": "sha512-ueEepnujpqee2o5aIYnvHU6C0A42MNdsIDeqy5BydrkuC5R1ZuUFnm27EeFJGoEHJQgn3uleRvmTXaJgfXbt4g==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "acorn": "^8.11.0"
      },
      "engines": {
        "node": ">=0.4.0"
      }
    },
    "node_modules/arg": {
      "version": "4.1.3",
      "resolved": "https://registry.npmjs.org/arg/-/arg-4.1.3.tgz",
      "integrity": "sha512-58S9QDqG0Xx27YwPSt9fJxivjYl432YCwfDMfZ+71RAqUrZef7LrKQZ3LHLOwCS4FLNBplP533Zx895SeOCHvA==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/create-require": {
      "version": "1.1.1",
      "resolved": "https://registry.npmjs.org/create-require/-/create-require-1.1.1.tgz",
      "integrity": "sha512-dcKFX3jn0MpIaXjisoRvexIJVEKzaq7z2rZKxf+MSr9TkdmHmsU4m2lcLojrj/FHl8mk5VxMmYA+ftRkP/3oKQ==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/diff": {
      "version": "4.0.2",
      "resolved": "https://registry.npmjs.org/diff/-/diff-4.0.2.tgz",
      "integrity": "sha512-58lmxKSA4BNyLz+HHMUzlOEpg09FV+ev6ZMe3vJihgdxzgcwZ8VoEEPmALCZG9LmqfVoNMMKpttIYTVG6uDY7A==",
      "dev": true,
      "license": "BSD-3-Clause",
      "engines": {
        "node": ">=0.3.1"
      }
    },
    "node_modules/make-error": {
      "version": "1.3.6",
      "resolved": "https://registry.npmjs.org/make-error/-/make-error-1.3.6.tgz",
      "integrity": "sha512-s8UhlNe7vPKomQhC1qFelMokr/Sc3AgNbso3n74mVPA5LTZwkB9NlXf4XPamLxJE8h0gh73rM94xvwRT2CVInw==",
      "dev": true,
      "license": "ISC"
    },
    "node_modules/ts-node": {
      "version": "10.9.2",
      "resolved": "https://registry.npmjs.org/ts-node/-/ts-node-10.9.2.tgz",
      "integrity": "sha512-f0FFpIdcHgn8zcPSbf1dRevwt047YMnaiJM3u2w2RewrB+fob/zePZcrOyQoLMMO7aBIddLcQIEK5dYjkLnGrQ==",
      "dev": true,
      "license": "MIT",
      "dependencies": {
        "@cspotcode/source-map-support": "^0.8.0",
        "@tsconfig/node10": "^1.0.7",
        "@tsconfig/node12": "^1.0.7",
        "@tsconfig/node14": "^1.0.0",
        "@tsconfig/node16": "^1.0.2",
        "acorn": "^8.4.1",
        "acorn-walk": "^8.1.1",
        "arg": "^4.1.0",
        "create-require": "^1.1.0",
        "diff": "^4.0.1",
        "make-error": "^1.1.1",
        "v8-compile-cache-lib": "^3.0.1",
        "yn": "3.1.1"
      },
      "bin": {
        "ts-node": "dist/bin.js",
        "ts-node-cwd": "dist/bin-cwd.js",
        "ts-node-esm": "dist/bin-esm.js",
        "ts-node-script": "dist/bin-script.js",
        "ts-node-transpile-only": "dist/bin-transpile.js",
        "ts-script": "dist/bin-script-deprecated.js"
      },
      "peerDependencies": {
        "@swc/core": ">=1.2.50",
        "@swc/wasm": ">=1.2.50",
        "@types/node": "*",
        "typescript": ">=2.7"
      },
      "peerDependenciesMeta": {
        "@swc/core": {
          "optional": true
        },
        "@swc/wasm": {
          "optional": true
        }
      }
    },
    "node_modules/typescript": {
      "version": "5.8.3",
      "resolved": "https://registry.npmjs.org/typescript/-/typescript-5.8.3.tgz",
      "integrity": "sha512-p1diW6TqL9L07nNxvRMM7hMMw4c5XOo/1ibL4aAIGmSAt9slTE1Xgw5KWuof2uTOvCg9BY7ZRi+GaF+7sfgPeQ==",
      "dev": true,
      "license": "Apache-2.0",
      "bin": {
        "tsc": "bin/tsc",
        "tsserver": "bin/tsserver"
      },
      "engines": {
        "node": ">=14.17"
      }
    },
    "node_modules/undici-types": {
      "version": "7.8.0",
      "resolved": "https://registry.npmjs.org/undici-types/-/undici-types-7.8.0.tgz",
      "integrity": "sha512-9UJ2xGDvQ43tYyVMpuHlsgApydB8ZKfVYTsLDhXkFL/6gfkp+U8xTGdh8pMJv1SpZna0zxG1DwsKZsreLbXBxw==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/v8-compile-cache-lib": {
      "version": "3.0.1",
      "resolved": "https://registry.npmjs.org/v8-compile-cache-lib/-/v8-compile-cache-lib-3.0.1.tgz",
      "integrity": "sha512-wa7YjyUGfNZngI/vtK0UHAN+lgDCxBPCylVXGp0zu59Fz5aiGtNXaq3DhIov063MorB+VfufLh3JlF2KdTK3xg==",
      "dev": true,
      "license": "MIT"
    },
    "node_modules/yn": {
      "version": "3.1.1",
      "resolved": "https://registry.npmjs.org/yn/-/yn-3.1.1.tgz",
      "integrity": "sha512-Ux4ygGWsu2c7isFWe8Yu1YluJmqVhxqK2cLXNQA5AcC3QfbGNpM7fu0Y8b/z16pXLnFxZYvWhd3fhBY9DLmC6Q==",
      "dev": true,
      "license": "MIT",
      "engines": {
        "node": ">=6"
      }
    }
  }
}

---

File: ./rdump/package.json
---
{
  "devDependencies": {
    "@types/node": "^24.0.10",
    "ts-node": "^10.9.2",
    "typescript": "^5.8.3"
  }
}

---

File: ./rdump/src/commands/lang.rs
---
use crate::predicates::code_aware::profiles::list_language_profiles;
use crate::LangAction;
use anyhow::{anyhow, Result};

pub fn run_lang(action: LangAction) -> Result<()> {
    match action {
        LangAction::List => {
            let profiles = list_language_profiles();
            println!("{:<12} EXTENSIONS", "NAME");
            println!("──────────────────────────");
            for profile in profiles {
                println!("{:<12} {}", profile.name, profile.extensions.join(", "));
            }
        }
        LangAction::Describe { language } => {
            let lang_lower = language.to_lowercase();
            let profiles = list_language_profiles();
            let profile = profiles
                .into_iter()
                .find(|p| p.name.to_lowercase() == lang_lower || p.extensions.contains(&lang_lower.as_str()))
                .ok_or_else(|| anyhow!("Language '{}' not supported. Run `rdump lang list` to see available languages.", language))?;

            println!(
                "Predicates for {} ({})",
                profile.name,
                profile.extensions.join(", ")
            );

            let metadata_preds = ["ext", "name", "path", "size", "modified"];
            let content_preds = ["contains", "matches"];

            println!("\nMETADATA");
            println!("  {}", metadata_preds.join(", "));

            println!("\nCONTENT");
            println!("  {}", content_preds.join(", "));

            let semantic_preds: Vec<&str> = profile.queries.keys().map(|k| k.as_ref()).collect();
            if !semantic_preds.is_empty() {
                println!("\nSEMANTIC");
                println!("  {}", semantic_preds.join(", "));
            }
        }
    }
    Ok(())
}

---

File: ./rdump/src/commands/mod.rs
---
// This makes the functions inside search.rs and preset.rs available
// to other parts of the program that use the `commands` module.
pub mod lang;
pub mod preset;
pub mod search;

---

File: ./rdump/src/commands/preset.rs
---
use crate::config::{self, Config};
use crate::PresetAction;
use anyhow::{anyhow, Result};
use std::fs; // We'll need to make PresetAction public

/// The main entry point for the `preset` command.
pub fn run_preset(action: PresetAction) -> Result<()> {
    match action {
        PresetAction::List => {
            let config = config::load_config()?;
            if config.presets.is_empty() {
                println!("No presets found.");
            } else {
                println!("Available presets:");
                let max_len = config.presets.keys().map(|k| k.len()).max().unwrap_or(0);
                for (name, query) in config.presets {
                    println!("  {name:<max_len$} : {query}");
                }
            }
        }
        PresetAction::Add { name, query } => {
            let path = config::global_config_path()
                .ok_or_else(|| anyhow!("Could not determine global config path"))?;

            let mut config = if path.exists() {
                let config_str = fs::read_to_string(&path)?;
                toml::from_str(&config_str)?
            } else {
                Config::default()
            };

            println!("Adding/updating preset '{name}'...");
            config.presets.insert(name, query);
            config::save_config(&config)?;
        }
        PresetAction::Remove { name } => {
            let path = config::global_config_path()
                .ok_or_else(|| anyhow!("Could not determine global config path"))?;

            if !path.exists() {
                return Err(anyhow!(
                    "Global config file does not exist. No presets to remove."
                ));
            }

            let mut config: Config = toml::from_str(&fs::read_to_string(&path)?)?;

            if config.presets.remove(&name).is_some() {
                println!("Removing preset '{name}'...");
                config::save_config(&config)?;
            } else {
                return Err(anyhow!("Preset '{}' not found in global config.", name));
            }
        }
    }
    Ok(())
}

---

File: ./rdump/src/commands/search.rs
---
use crate::{config, ColorChoice, SearchArgs};
use anyhow::anyhow;
use anyhow::Result;
use atty::Stream;
use ignore::WalkBuilder;
use rayon::prelude::*;
use std::fs::File;
use std::io::{self, Write};
use std::path::PathBuf;
use std::sync::Mutex;
use tempfile::NamedTempFile;
use tree_sitter::Range;

use crate::evaluator::{Evaluator, FileContext, MatchResult};
use crate::formatter;
use crate::parser;
use crate::predicates;

/// The main entry point for the `search` command.
pub fn run_search(mut args: SearchArgs) -> Result<()> {
    // --- Handle Shorthand Flags ---
    if args.no_headers {
        args.format = crate::Format::Cat;
    }
    if args.find {
        args.format = crate::Format::Find;
    }

    // --- Load Config and Build Query ---
    let config = config::load_config()?;
    let mut final_query = args.query.join(" ");

    for preset_name in args.preset.iter().rev() {
        let preset_query = config
            .presets
            .get(preset_name)
            .ok_or_else(|| anyhow!("Preset '{}' not found", preset_name))?;

        if final_query.is_empty() {
            final_query = format!("({preset_query})");
        } else {
            final_query = format!("({preset_query}) & ({final_query})");
        }
    }

    if final_query.is_empty() {
        return Err(anyhow!(
            "Empty query. Provide a query string or use a preset."
        ));
    }

    // --- 1. Find initial candidates ---
    let candidate_files =
        get_candidate_files(&args.root, args.no_ignore, args.hidden, args.max_depth)?;

    // --- 2. Parse query ---
    let ast = parser::parse_query(&final_query)?;

    // --- 3. Pre-filtering Pass (Metadata) ---
    // This pass uses an evaluator with only fast metadata predicates.
    // It quickly reduces the number of files needing full evaluation.
    let metadata_registry = predicates::create_metadata_predicate_registry();
    let pre_filter_evaluator = Evaluator::new(ast.clone(), metadata_registry);

    let first_error = Mutex::new(None);
    let pre_filtered_files: Vec<PathBuf> = candidate_files
        .into_iter() // This pass is not parallel, it's fast enough.
        .filter(|path| {
            if first_error.lock().unwrap().is_some() {
                return false;
            }
            let mut context = FileContext::new(path.clone(), args.root.clone());
            match pre_filter_evaluator.evaluate(&mut context) {
                Ok(result) => result.is_match(),
                Err(e) => {
                    let mut error_guard = first_error.lock().unwrap();
                    if error_guard.is_none() {
                        *error_guard = Some(anyhow!("Error during pre-filter on {}: {}", path.display(), e));
                    }
                    false
                }
            }
        })
        .collect();

    if let Some(e) = first_error.into_inner().unwrap() {
        return Err(e);
    }

    // --- Determine if color should be used ---
    let mut use_color = match args.color {
        ColorChoice::Always => true,
        ColorChoice::Never => false,
        ColorChoice::Auto => atty::is(Stream::Stdout),
    };

    // If outputting to a file, disable color unless explicitly forced.
    if args.output.is_some() && args.color != ColorChoice::Always {
        use_color = false;
    }

    // If the output format is `Cat` (likely for piping), we should not use color
    // unless the user has explicitly forced it with `Always`.
    if let crate::Format::Cat = args.format {
        if args.color != ColorChoice::Always {
            use_color = false;
        }
    }

    // --- 4. Main Evaluation Pass (Content + Semantic) ---
    // This pass uses the full evaluator on the smaller, pre-filtered set of files.
    let full_registry = predicates::create_predicate_registry();
    let evaluator = Evaluator::new(ast, full_registry);

    let first_error = Mutex::new(None);
    let mut matching_files: Vec<(PathBuf, Vec<Range>)> = pre_filtered_files
        .par_iter()
        .filter_map(|path| {
            if first_error.lock().unwrap().is_some() {
                return None;
            }
            let mut context = FileContext::new(path.clone(), args.root.clone());
            match evaluator.evaluate(&mut context) {
                Ok(MatchResult::Boolean(true)) => Some((path.clone(), Vec::new())),
                Ok(MatchResult::Boolean(false)) => None,
                Ok(MatchResult::Hunks(hunks)) => {
                    if hunks.is_empty() {
                        None
                    } else {
                        Some((path.clone(), hunks))
                    }
                }
                Err(e) => {
                    let mut error_guard = first_error.lock().unwrap();
                    if error_guard.is_none() {
                        *error_guard = Some(anyhow!("Error evaluating file {}: {}", path.display(), e));
                    }
                    None
                }
            }
        })
        .collect();

    if let Some(e) = first_error.into_inner().unwrap() {
        return Err(e);
    }

    matching_files.sort_by(|a, b| a.0.cmp(&b.0));

    // --- 5. Format and print results ---
    let mut writer: Box<dyn Write> = if let Some(output_path) = &args.output {
        Box::new(File::create(output_path)?)
    } else {
        Box::new(io::stdout())
    };

    formatter::print_output(
        &mut writer,
        &matching_files,
        &args.format,
        args.line_numbers,
        args.no_headers,
        use_color,
        args.context.unwrap_or(0),
    )?;

    Ok(())
}

/// Walks the directory, respecting .gitignore, and applies our own smart defaults.
fn get_candidate_files(
    root: &PathBuf,
    no_ignore: bool,
    hidden: bool,
    max_depth: Option<usize>,
) -> Result<Vec<PathBuf>> {
    let mut files = Vec::new();
    let mut walker_builder = WalkBuilder::new(root);

    walker_builder.hidden(!hidden).max_depth(max_depth);

    if no_ignore {
        // If --no-ignore is passed, disable everything.
        walker_builder
            .ignore(false)
            .git_ignore(false)
            .git_global(false)
            .git_exclude(false);
    } else {
        // Layer 1: Our "sane defaults". These have the lowest precedence.
        let default_ignores = "
           # Default rdump ignores
           node_modules/
           target/
           dist/
           build/
           .git/
           .svn/
           .hg/
           *.pyc
           __pycache__/
       ";
        let mut temp_ignore = NamedTempFile::new()?;
        write!(temp_ignore, "{default_ignores}")?;
        walker_builder.add_ignore(temp_ignore.path());

        // Layer 2: A user's custom global ignore file.
        if let Some(global_ignore_path) = dirs::config_dir().map(|p| p.join("rdump/ignore")) {
            if global_ignore_path.exists() {
                if let Some(err) = walker_builder.add_ignore(global_ignore_path) {
                    eprintln!("Warning: could not add global ignore file: {err}");
                }
            }
        }

        // Layer 3: A user's custom project-local .rdumpignore file.
        walker_builder.add_custom_ignore_filename(".rdumpignore");

        // Layer 4: Standard .gitignore files.
        walker_builder.git_global(true);
        walker_builder.git_ignore(true);
    }

    for result in walker_builder.build() {
        let entry = result?;
        if entry.file_type().is_some_and(|ft| ft.is_file()) {
            files.push(entry.into_path());
        }
    }
    Ok(files)
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs;
    use std::io::Write;
    use std::path::PathBuf;
    use tempfile::tempdir;

    fn get_sorted_file_names(
        root: &PathBuf,
        no_ignore: bool,
        hidden: bool,
        max_depth: Option<usize>,
    ) -> Vec<String> {
        let mut paths = get_candidate_files(root, no_ignore, hidden, max_depth).unwrap();
        paths.sort();
        paths
            .into_iter()
            .map(|p| {
                p.strip_prefix(root)
                    .unwrap()
                    .to_string_lossy()
                    .replace('\\', "/")
            })
            .collect()
    }

    #[test]
    fn test_custom_rdumpignore_file() {
        let dir = tempdir().unwrap();
        let root = dir.path();
        let mut ignore_file = fs::File::create(root.join(".rdumpignore")).unwrap();
        writeln!(ignore_file, "*.log").unwrap();
        fs::File::create(root.join("app.js")).unwrap();
        fs::File::create(root.join("app.log")).unwrap();

        let files = get_sorted_file_names(&root.to_path_buf(), false, false, None);
        assert_eq!(files, vec!["app.js"]);
    }

    #[test]
    fn test_unignore_via_rdumpignore() {
        let dir = tempdir().unwrap();
        let root = dir.path();

        let node_modules = root.join("node_modules");
        fs::create_dir(&node_modules).unwrap();
        fs::File::create(node_modules.join("some_dep.js")).unwrap();
        fs::File::create(root.join("app.js")).unwrap();

        let mut ignore_file = fs::File::create(root.join(".rdumpignore")).unwrap();
        writeln!(ignore_file, "!node_modules/").unwrap();

        let files = get_sorted_file_names(&root.to_path_buf(), false, false, None);
        assert_eq!(files.len(), 2);
        assert!(files.contains(&"app.js".to_string()));
        let expected_path = PathBuf::from("node_modules").join("some_dep.js");
        assert!(files.contains(&expected_path.to_string_lossy().to_string()));
    }
}


---

File: ./rdump/src/config.rs
---
// rdump/src/config.rs - FINAL CORRECTED VERSION

use anyhow::{Context, Result};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::env;
use std::fs;
use std::path::{Path, PathBuf};

#[derive(Deserialize, Serialize, Debug, Default)]
pub struct Config {
    #[serde(default)]
    pub presets: HashMap<String, String>,
}

/// Returns the path to the global configuration file.
/// It can be overridden by the RDUMP_TEST_CONFIG_DIR environment variable for testing.
pub fn global_config_path() -> Option<PathBuf> {
    // First, check for the override environment variable. This is active in ALL builds.
    if let Ok(path_str) = env::var("RDUMP_TEST_CONFIG_DIR") {
        return Some(PathBuf::from(path_str).join("rdump/config.toml"));
    }

    // If the override is not set, fall back to the default platform-specific directory.
    dirs::config_dir().map(|p| p.join("rdump/config.toml"))
}

/// Searches for a local `.rdump.toml` in the given directory and its parents.
fn find_local_config(start_dir: &Path) -> Option<PathBuf> {
    for ancestor in start_dir.ancestors() {
        let config_path = ancestor.join(".rdump.toml");
        if config_path.exists() {
            return Some(config_path);
        }
    }
    None
}

/// Finds and loads the configuration, merging global and local files.
pub fn load_config() -> Result<Config> {
    let mut final_config = Config::default();

    // 1. Load the global config file, if it exists.
    if let Some(global_config_path) = global_config_path() {
        if global_config_path.exists() {
            let global_config_str = fs::read_to_string(&global_config_path).with_context(|| {
                format!("Failed to read global config at {global_config_path:?}")
            })?;
            let global_config: Config = toml::from_str(&global_config_str)?;
            final_config.presets.extend(global_config.presets);
        }
    }

    // 2. Find and load the local config file, if it exists.
    let current_dir = env::current_dir()?;
    if let Some(local_config_path) = find_local_config(&current_dir) {
        if local_config_path.exists() {
            let local_config_str = fs::read_to_string(&local_config_path)
                .with_context(|| format!("Failed to read local config at {local_config_path:?}"))?;
            let local_config: Config = toml::from_str(&local_config_str)?;
            final_config.presets.extend(local_config.presets);
        }
    }

    Ok(final_config)
}

/// Saves the given config to the global configuration file.
pub fn save_config(config: &Config) -> Result<()> {
    let path = global_config_path()
        .ok_or_else(|| anyhow::anyhow!("Could not determine global config path"))?;

    if let Some(parent) = path.parent() {
        fs::create_dir_all(parent)
            .with_context(|| format!("Failed to create config directory at {parent:?}"))?;
    }

    let toml_string = toml::to_string_pretty(config)?;
    fs::write(&path, toml_string)
        .with_context(|| format!("Failed to write global config to {path:?}"))?;

    println!("Successfully saved config to {path:?}");
    Ok(())
}

// The unit tests for config.rs remain the same and will still pass.
#[cfg(test)]
mod tests {
    use super::*;
    use once_cell::sync::Lazy;
    use std::io::Write;
    use std::sync::Mutex;
    use tempfile::tempdir;

    static ENV_MUTEX: Lazy<Mutex<()>> = Lazy::new(|| Mutex::new(()));

    #[test]
    fn test_find_local_config_in_parent() {
        let _lock = ENV_MUTEX.lock().unwrap();
        let root = tempdir().unwrap();
        let sub = root.path().join("sub");
        fs::create_dir(&sub).unwrap();

        let config_path = root.path().join(".rdump.toml");
        fs::File::create(&config_path).unwrap();

        let found_path = find_local_config(&sub).unwrap();
        assert_eq!(found_path, config_path);
    }

    #[test]
    fn test_find_local_config_not_found() {
        let _lock = ENV_MUTEX.lock().unwrap();
        let root = tempdir().unwrap();
        assert!(find_local_config(root.path()).is_none());
    }

    #[test]
    fn test_load_config_merging_and_overriding() {
        let _lock = ENV_MUTEX.lock().unwrap();
        let test_dir = tempdir().unwrap();

        let fake_home_dir = test_dir.path().join("home");
        let global_config_dir = fake_home_dir.join("rdump");
        fs::create_dir_all(&global_config_dir).unwrap();
        let global_config_path = global_config_dir.join("config.toml");
        let mut global_file = fs::File::create(&global_config_path).unwrap();
        writeln!(
            global_file,
            r#"
            [presets]
            rust = "ext:rs"
            docs = "ext:md"
        "#
        )
        .unwrap();

        let project_dir = test_dir.path().join("project");
        fs::create_dir(&project_dir).unwrap();
        let local_config_path = project_dir.join(".rdump.toml");
        let mut local_file = fs::File::create(&local_config_path).unwrap();
        writeln!(
            local_file,
            r#"
            [presets]
            docs = "ext:md | ext:txt"
            scripts = "ext:sh"
        "#
        )
        .unwrap();

        env::set_var("RDUMP_TEST_CONFIG_DIR", fake_home_dir.to_str().unwrap());
        let original_dir = env::current_dir().unwrap();
        env::set_current_dir(&project_dir).unwrap();
        let config = load_config().unwrap();
        env::set_current_dir(&original_dir).unwrap();

        assert_eq!(config.presets.len(), 3);
        assert_eq!(config.presets.get("rust").unwrap(), "ext:rs");
        assert_eq!(config.presets.get("scripts").unwrap(), "ext:sh");
        assert_eq!(config.presets.get("docs").unwrap(), "ext:md | ext:txt");

        env::remove_var("RDUMP_TEST_CONFIG_DIR");
    }
}

---

File: ./rdump/src/evaluator.rs
---
use anyhow::{anyhow, Context, Result};
use std::collections::HashMap;
use std::fs;
use std::path::PathBuf;
use tree_sitter::{Parser, Range, Tree};

use crate::parser::{AstNode, LogicalOperator, PredicateKey};
use crate::predicates::PredicateEvaluator;

/// The result of an evaluation for a single file.
#[derive(Debug, Clone)]
pub enum MatchResult {
    // For simple, non-hunkable predicates like `ext:rs` or `size:>10kb`
    Boolean(bool),
    // For code-aware predicates that can identify specific code blocks.
    Hunks(Vec<Range>),
}

/// Holds the context for a single file being evaluated.
/// It lazily loads content and caches the tree-sitter AST.
pub struct FileContext {
    pub path: PathBuf,
    pub root: PathBuf,
    content: Option<String>,
    // Cache for the parsed tree-sitter AST
    tree: Option<Tree>,
}

impl FileContext {
    pub fn new(path: PathBuf, root: PathBuf) -> Self {
        FileContext {
            path,
            root,
            content: None,
            tree: None,
        }
    }

    pub fn get_content(&mut self) -> Result<&str> {
        if self.content.is_none() {
            let content = fs::read_to_string(&self.path)
                .with_context(|| format!("Failed to read file {}", self.path.display()))?;
            self.content = Some(content);
        }
        Ok(self.content.as_ref().unwrap())
    }

    // Lazily parses the file with tree-sitter and caches the result.
    pub fn get_tree(&mut self, language: tree_sitter::Language) -> Result<&Tree> {
        if self.tree.is_none() {
            let path_display = self.path.display().to_string();
            let content = self.get_content()?;
            let mut parser = Parser::new();
            parser.set_language(&language).with_context(|| {
                format!("Failed to set language for tree-sitter parser on {path_display}")
            })?;
            let tree = parser
                .parse(content, None)
                .ok_or_else(|| anyhow!("Tree-sitter failed to parse {}", path_display))?;
            self.tree = Some(tree);
        }
        Ok(self.tree.as_ref().unwrap())
    }
}

/// The main evaluator struct. It holds the AST and the predicate registry.
pub struct Evaluator {
    ast: AstNode,
    registry: HashMap<PredicateKey, Box<dyn PredicateEvaluator + Send + Sync>>,
}

impl Evaluator {
    pub fn new(
        ast: AstNode,
        registry: HashMap<PredicateKey, Box<dyn PredicateEvaluator + Send + Sync>>,
    ) -> Self {
        Evaluator { ast, registry }
    }

    /// Evaluates the query for a given file path.
    pub fn evaluate(&self, context: &mut FileContext) -> Result<MatchResult> {
        self.evaluate_node(&self.ast, context)
    }

    /// Recursively evaluates an AST node.
    fn evaluate_node(&self, node: &AstNode, context: &mut FileContext) -> Result<MatchResult> {
        match node {
            AstNode::Predicate(key, value) => self.evaluate_predicate(key, value, context),
            AstNode::LogicalOp(op, left, right) => {
                let left_res = self.evaluate_node(left, context)?;

                // Short-circuit AND if left is false
                if *op == LogicalOperator::And && !left_res.is_match() {
                    return Ok(MatchResult::Boolean(false));
                }

                // Short-circuit OR if left is a full-file match
                if *op == LogicalOperator::Or {
                    if let MatchResult::Boolean(true) = left_res {
                        return Ok(left_res);
                    }
                }

                let right_res = self.evaluate_node(right, context)?;
                Ok(left_res.combine_with(right_res, op))
            }
            AstNode::Not(inner_node) => {
                // If the inner predicate of a NOT is not in the registry (e.g., a content
                // predicate during the metadata-only pass), we cannot definitively say the file
                // *doesn't* match. We must assume it *could* match and let the full evaluator decide.
                if let AstNode::Predicate(key, _) = &**inner_node {
                    if !self.registry.contains_key(key) {
                        return Ok(MatchResult::Boolean(true));
                    }
                }
                let result = self.evaluate_node(inner_node, context)?;
                Ok(MatchResult::Boolean(!result.is_match()))
            }
        }
    }

    /// Evaluates a single predicate.
    fn evaluate_predicate(
        &self,
        key: &PredicateKey,
        value: &str,
        context: &mut FileContext,
    ) -> Result<MatchResult> {
        if let Some(evaluator) = self.registry.get(key) {
            evaluator.evaluate(context, key, value)
        } else {
            // If a predicate is not in the current registry (e.g., a content predicate
            // during the metadata-only pass), it's considered a "pass" for this stage.
            Ok(MatchResult::Boolean(true))
        }
    }
}

impl MatchResult {
    /// Returns true if the result is considered a match.
    pub fn is_match(&self) -> bool {
        match self {
            MatchResult::Boolean(b) => *b,
            MatchResult::Hunks(h) => !h.is_empty(),
        }
    }

    /// Combines two match results based on a logical operator.
    pub fn combine_with(self, other: MatchResult, op: &LogicalOperator) -> Self {
        match op {
            LogicalOperator::And => self.combine_and(other),
            LogicalOperator::Or => self.combine_or(other),
        }
    }

    // Helper for AND logic
    fn combine_and(self, other: MatchResult) -> Self {
        if !self.is_match() || !other.is_match() {
            return MatchResult::Boolean(false);
        }
        match (self, other) {
            // Both are hunks: combine them, sort, and deduplicate.
            (MatchResult::Hunks(mut a), MatchResult::Hunks(b)) => {
                a.extend(b);
                a.sort_by_key(|r| r.start_byte);
                a.dedup();
                MatchResult::Hunks(a)
            }
            // One is a hunk, the other is a full-file match (true). Keep the hunks.
            (h @ MatchResult::Hunks(_), MatchResult::Boolean(true)) => h,
            (MatchResult::Boolean(true), h @ MatchResult::Hunks(_)) => h,
            // Both are full-file matches.
            (MatchResult::Boolean(true), MatchResult::Boolean(true)) => MatchResult::Boolean(true),
            // Should be unreachable due to the initial `is_match` check.
            _ => MatchResult::Boolean(false),
        }
    }

    // Helper for OR logic
    fn combine_or(self, other: MatchResult) -> Self {
        match (self, other) {
            // If either is a full-file match, the result is a full-file match.
            (MatchResult::Boolean(true), _) | (_, MatchResult::Boolean(true)) => {
                MatchResult::Boolean(true)
            }
            // Both are hunks: combine them, sort, and deduplicate.
            (MatchResult::Hunks(mut a), MatchResult::Hunks(b)) => {
                a.extend(b);
                a.sort_by_key(|r| r.start_byte);
                a.dedup();
                MatchResult::Hunks(a)
            }
            // One is a hunk, the other is a non-match. Keep the hunks.
            (h @ MatchResult::Hunks(_), MatchResult::Boolean(false)) => h,
            (MatchResult::Boolean(false), h @ MatchResult::Hunks(_)) => h,
            // Both are non-matches.
            (MatchResult::Boolean(false), MatchResult::Boolean(false)) => {
                MatchResult::Boolean(false)
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::parser::LogicalOperator;
    use std::fs;
    use tempfile::tempdir;
    use tree_sitter::Point;
    use tree_sitter_rust::language;

    #[test]
    fn test_combine_with_hunks_and() {
        let hunks1 = vec![Range {
            start_byte: 10,
            end_byte: 20,
            start_point: Point { row: 0, column: 0 },
            end_point: Point { row: 0, column: 0 },
        }];
        let hunks2 = vec![Range {
            start_byte: 30,
            end_byte: 40,
            start_point: Point { row: 0, column: 0 },
            end_point: Point { row: 0, column: 0 },
        }];
        let result1 = MatchResult::Hunks(hunks1);
        let result2 = MatchResult::Hunks(hunks2);

        let combined = result1.combine_with(result2, &LogicalOperator::And);

        if let MatchResult::Hunks(h) = combined {
            assert_eq!(h.len(), 2);
            assert_eq!(h[0].start_byte, 10);
            assert_eq!(h[1].start_byte, 30);
        } else {
            panic!("Expected Hunks result");
        }
    }

    #[test]
    fn test_combine_with_hunks_or() {
        let hunks1 = vec![Range {
            start_byte: 10,
            end_byte: 20,
            start_point: Point { row: 0, column: 0 },
            end_point: Point { row: 0, column: 0 },
        }];
        let hunks2 = vec![Range {
            start_byte: 30,
            end_byte: 40,
            start_point: Point { row: 0, column: 0 },
            end_point: Point { row: 0, column: 0 },
        }];
        let result1 = MatchResult::Hunks(hunks1);
        let result2 = MatchResult::Hunks(hunks2);

        let combined = result1.combine_with(result2, &LogicalOperator::Or);

        if let MatchResult::Hunks(h) = combined {
            assert_eq!(h.len(), 2);
        } else {
            panic!("Expected Hunks result");
        }
    }

    #[test]
    fn test_file_context_content_caching() {
        let dir = tempdir().unwrap();
        let file_path = dir.path().join("test.txt");
        fs::write(&file_path, "hello").unwrap();

        let mut context = FileContext::new(file_path.clone(), dir.path().to_path_buf());

        // First access should read from file
        assert_eq!(context.get_content().unwrap(), "hello");
        assert!(context.content.is_some());

        // Modify the file content
        fs::write(&file_path, "world").unwrap();

        // Second access should return cached content
        assert_eq!(context.get_content().unwrap(), "hello");
    }

    #[test]
    fn test_file_context_tree_caching() {
        let dir = tempdir().unwrap();
        let file_path = dir.path().join("test.rs");
        fs::write(&file_path, "fn main() {}").unwrap();

        let mut context = FileContext::new(file_path, dir.path().to_path_buf());
        let language = language();

        // First access should parse and cache the tree
        let tree1_sexp = context.get_tree(language.clone()).unwrap().root_node().to_sexp();
        assert!(context.tree.is_some());

        // Second access should return the cached tree
        let tree2_sexp = context.get_tree(language).unwrap().root_node().to_sexp();

        assert_eq!(tree1_sexp, tree2_sexp);
    }
}

---

File: ./rdump/src/formatter.rs
---
use anyhow::{Context, Result};
use chrono::{DateTime, Local}; // For formatting timestamps
use once_cell::sync::Lazy;
use serde::{Deserialize, Serialize};
use std::fs;
use std::io::Write;
use std::ops::Range as StdRange;
#[cfg(unix)]
use std::os::unix::fs::PermissionsExt; // For Unix permissions
use std::path::PathBuf;
use syntect::easy::HighlightLines;
use syntect::highlighting::{Style, ThemeSet};
use syntect::parsing::SyntaxSet;
use syntect::util::{as_24_bit_terminal_escaped, LinesWithEndings};
use tree_sitter::Range;

// We need to pass the format enum from main.rs
use crate::Format;

// Lazily load syntax and theme sets once.
static SYNTAX_SET: Lazy<SyntaxSet> = Lazy::new(SyntaxSet::load_defaults_newlines);
static THEME_SET: Lazy<ThemeSet> = Lazy::new(ThemeSet::load_defaults);

#[derive(Serialize, Deserialize, Debug, PartialEq)]
struct FileOutput {
    path: String,
    content: String,
}

fn print_markdown_format(
    writer: &mut impl Write,
    matching_files: &[(PathBuf, Vec<Range>)],
    with_line_numbers: bool,
    with_headers: bool,
) -> Result<()> {
    for (i, (path, _)) in matching_files.iter().enumerate() {
        if with_headers {
            if i > 0 {
                writeln!(writer, "
---
")?;
            }
            writeln!(writer, "File: {}", path.display())?;
            writeln!(writer, "---")?;
        }
        let content = fs::read_to_string(path)?;
        let extension = path.extension().and_then(|s| s.to_str()).unwrap_or("");

        // Markdown format should always use fenced content, not ANSI colors.
        print_markdown_fenced_content(writer, &content, extension, with_line_numbers, 0)?;
    }
    Ok(())
}

fn print_cat_format(
    writer: &mut impl Write,
    matching_files: &[(PathBuf, Vec<Range>)],
    with_line_numbers: bool,
    use_color: bool,
) -> Result<()> {
    for (path, _) in matching_files {
        let content = fs::read_to_string(path)?;
        if use_color {
            // To terminal
            print_highlighted_content(
                writer,
                &content,
                path.extension().and_then(|s| s.to_str()).unwrap_or(""),
                with_line_numbers,
                0,
            )?;
        } else {
            print_plain_content(writer, &content, with_line_numbers, 0)?; // To file/pipe
        }
    }
    Ok(())
}

fn print_json_format(
    writer: &mut impl Write,
    matching_files: &[(PathBuf, Vec<Range>)],
) -> Result<()> {
    let mut outputs = Vec::new();
    for (path, _) in matching_files {
        let content = fs::read_to_string(path)
            .with_context(|| format!("Failed to read file for final output: {}", path.display()))?;
        outputs.push(FileOutput {
            path: path.to_string_lossy().to_string(),
            content,
        });
    }
    // Use to_writer_pretty for readable JSON output
    serde_json::to_writer_pretty(writer, &outputs)?;
    Ok(())
}

fn print_paths_format(
    writer: &mut impl Write,
    matching_files: &[(PathBuf, Vec<Range>)],
) -> Result<()> {
    for (path, _) in matching_files {
        writeln!(writer, "{}", path.display())?;
    }
    Ok(())
}

fn print_find_format(
    writer: &mut impl Write,
    matching_files: &[(PathBuf, Vec<Range>)],
) -> Result<()> {
    for (path, _) in matching_files {
        let metadata = fs::metadata(path)
            .with_context(|| format!("Failed to read metadata for {}", path.display()))?;
        let size = metadata.len();
        let modified: DateTime<Local> = DateTime::from(metadata.modified()?);

        // Get permissions (basic implementation)
        let perms = metadata.permissions();
        #[cfg(unix)]
        let mode = perms.mode();
        #[cfg(not(unix))]
        let mode = 0; // Placeholder for non-unix
        let perms_str = format_mode(mode);

        // Format size into human-readable string
        let size_str = format_size(size);

        // Format time
        let time_str = modified.format("%b %d %H:%M").to_string();

        writeln!(
            writer,
            "{:<12} {:>8} {} {}",
            perms_str,
            size_str,
            time_str,
            path.display()
        )?;
    }
    Ok(())
}

fn print_hunks_format(
    writer: &mut impl Write,
    matching_files: &[(PathBuf, Vec<Range>)],
    with_line_numbers: bool,
    with_headers: bool,
    use_color: bool,
    context_lines: usize,
) -> Result<()> {
    for (i, (path, hunks)) in matching_files.iter().enumerate() {
        if with_headers {
            if i > 0 {
                writeln!(writer, "\n---\n")?;
            }
            writeln!(writer, "File: {}", path.display())?;
            writeln!(writer, "---")?;
        }
        let content = fs::read_to_string(path)?;
        let extension = path.extension().and_then(|s| s.to_str()).unwrap_or("");

        if hunks.is_empty() {
            // Boolean match, print the whole file
            print_content_with_style(writer, &content, extension, with_line_numbers, use_color, 0)?;
        } else {
            // Hunk match, print with context
            let lines: Vec<&str> = LinesWithEndings::from(&content).collect();
            let line_ranges = get_contextual_line_ranges(hunks, &lines, context_lines);

            for (i, range) in line_ranges.iter().enumerate() {
                if i > 0 {
                    writeln!(writer, "...")?;
                }
                let hunk_content = lines[range.clone()].join("");
                print_content_with_style(
                    writer,
                    &hunk_content,
                    extension,
                    with_line_numbers,
                    use_color,
                    range.start,
                )?;
            }
        }
    }
    Ok(())
}

/// Formats and prints the final output to a generic writer based on the chosen format.
pub fn print_output(
    writer: &mut impl Write,
    matching_files: &[(PathBuf, Vec<Range>)],
    format: &Format,
    with_line_numbers: bool,
    no_headers: bool,
    use_color: bool,
    context_lines: usize,
) -> Result<()> {
    match format {
        Format::Find => print_find_format(writer, matching_files)?,
        Format::Paths => print_paths_format(writer, matching_files)?,
        Format::Json => print_json_format(writer, matching_files)?,
        Format::Cat => print_cat_format(writer, matching_files, with_line_numbers, use_color)?,
        Format::Markdown => {
            print_markdown_format(writer, matching_files, with_line_numbers, !no_headers)?
        }
        Format::Hunks => print_hunks_format(
            writer,
            matching_files,
            with_line_numbers,
            !no_headers,
            use_color,
            context_lines,
        )?,
    }
    Ok(())
}

/// Helper to choose the correct printing function based on color/style preference.
fn print_content_with_style(
    writer: &mut impl Write,
    content: &str,
    extension: &str,
    with_line_numbers: bool,
    use_color: bool,
    start_line_number: usize,
) -> Result<()> {
    if use_color {
        print_highlighted_content(
            writer,
            content,
            extension,
            with_line_numbers,
            start_line_number,
        )
    } else {
        print_plain_content(writer, content, with_line_numbers, start_line_number)
    }
}

/// Given a set of byte-offset ranges, calculate the line number ranges including context,
/// and merge any overlapping ranges.
fn get_contextual_line_ranges(
    hunks: &[Range],
    lines: &[&str],
    context_lines: usize,
) -> Vec<StdRange<usize>> {
    if hunks.is_empty() || lines.is_empty() {
        return vec![];
    }

    let mut line_ranges = Vec::new();
    for hunk in hunks {
        let start_line = hunk.start_point.row;
        let end_line = hunk.end_point.row;

        let context_start = start_line.saturating_sub(context_lines);
        let context_end = (end_line + context_lines).min(lines.len() - 1);

        if context_end >= context_start {
            line_ranges.push(context_start..context_end + 1);
        }
    }
    line_ranges.sort_by_key(|r| r.start);

    // Merge overlapping ranges
    let mut merged_ranges = Vec::new();
    let mut iter = line_ranges.into_iter();
    if let Some(mut current) = iter.next() {
        for next in iter {
            if next.start <= current.end {
                current.end = current.end.max(next.end);
            } else {
                merged_ranges.push(current);
                current = next;
            }
        }
        merged_ranges.push(current);
    }
    merged_ranges
}

/// Prints syntax-highlighted content to the writer.
fn print_highlighted_content(
    writer: &mut impl Write,
    content: &str,
    extension: &str,
    with_line_numbers: bool,
    start_line_number: usize,
) -> Result<()> {
    let syntax = SYNTAX_SET
        .find_syntax_by_extension(extension)
        .unwrap_or_else(|| SYNTAX_SET.find_syntax_plain_text());

    let theme = &THEME_SET.themes["base16-ocean.dark"];
    let mut highlighter = HighlightLines::new(syntax, theme);

    for (i, line) in LinesWithEndings::from(content).enumerate() {
        if with_line_numbers {
            write!(writer, "{: >5} | ", start_line_number + i + 1)?;
        }
        let ranges: Vec<(Style, &str)> = highlighter.highlight_line(line, &SYNTAX_SET)?;
        let escaped = as_24_bit_terminal_escaped(&ranges[..], false);
        write!(writer, "{escaped}")?;
    }
    // Reset color at the end
    write!(writer, "\x1b[0m")?;
    Ok(())
}

/// Prints plain content, optionally with line numbers.
fn print_plain_content(
    writer: &mut impl Write,
    content: &str,
    with_line_numbers: bool,
    start_line_number: usize,
) -> Result<()> {
    for (i, line) in content.lines().enumerate() {
        if with_line_numbers {
            writeln!(writer, "{: >5} | {}", start_line_number + i + 1, line)?;
        } else {
            writeln!(writer, "{line}")?;
        }
    }
    Ok(())
}

/// Prints content inside a Markdown code fence.
fn print_markdown_fenced_content(
    writer: &mut impl Write,
    content: &str,
    extension: &str,
    with_line_numbers: bool,
    start_line_number: usize,
) -> Result<()> {
    writeln!(writer, "```{extension}")?;
    // print_plain_content handles line numbers correctly
    print_plain_content(writer, content, with_line_numbers, start_line_number)?;
    writeln!(writer, "```")?;
    Ok(())
}

fn format_mode(mode: u32) -> String {
    #[cfg(unix)]
    {
        let user_r = if mode & 0o400 != 0 { 'r' } else { '-' };
        let user_w = if mode & 0o200 != 0 { 'w' } else { '-' };
        let user_x = if mode & 0o100 != 0 { 'x' } else { '-' };
        let group_r = if mode & 0o040 != 0 { 'r' } else { '-' };
        let group_w = if mode & 0o020 != 0 { 'w' } else { '-' };
        let group_x = if mode & 0o010 != 0 { 'x' } else { '-' };
        let other_r = if mode & 0o004 != 0 { 'r' } else { '-' };
        let other_w = if mode & 0o002 != 0 { 'w' } else { '-' };
        let other_x = if mode & 0o001 != 0 { 'x' } else { '-' };
        format!("-{user_r}{user_w}{user_x}{group_r}{group_w}{group_x}{other_r}{other_w}{other_x}")
    }
    #[cfg(not(unix))]
    {
        // Basic fallback for non-Unix platforms
        if mode & 0o200 != 0 {
            "-rw-------"
        } else {
            "-r--------"
        }
        .to_string()
    }
}

fn format_size(bytes: u64) -> String {
    const KB: u64 = 1024;
    const MB: u64 = KB * 1024;
    const GB: u64 = MB * 1024;

    if bytes >= GB {
        format!("{:.1}G", bytes as f64 / GB as f64)
    } else if bytes >= MB {
        format!("{:.1}M", bytes as f64 / MB as f64)
    } else if bytes >= KB {
        format!("{:.1}K", bytes as f64 / KB as f64)
    } else {
        format!("{bytes}B")
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::io::Write;
    use tempfile::NamedTempFile;

    // Helper to create a temp file with some content.
    fn create_temp_file_with_content(content: &str) -> NamedTempFile {
        let mut file = NamedTempFile::new().unwrap();
        file.write_all(content.as_bytes()).unwrap();
        file
    }

    #[test]
    fn test_format_plain_cat_with_line_numbers() {
        let file = create_temp_file_with_content("a\nb");
        let paths = vec![(file.path().to_path_buf(), vec![])];
        let mut writer = Vec::new();
        print_output(&mut writer, &paths, &Format::Cat, true, false, false, 0).unwrap();
        let output = String::from_utf8(writer).unwrap();
        assert_eq!(output, "    1 | a\n    2 | b\n");
    }

    #[test]
    fn test_format_paths() {
        let file1 = create_temp_file_with_content("a");
        let file2 = create_temp_file_with_content("b");
        let paths = vec![
            (file1.path().to_path_buf(), vec![]),
            (file2.path().to_path_buf(), vec![]),
        ];
        let mut writer = Vec::new();
        print_output(&mut writer, &paths, &Format::Paths, false, false, false, 0).unwrap();
        let output = String::from_utf8(writer).unwrap();
        let expected = format!("{}\n{}\n", file1.path().display(), file2.path().display());
        assert_eq!(output, expected);
    }

    #[test]
    fn test_format_markdown_with_fences() {
        let file = create_temp_file_with_content("line 1");
        let paths = vec![(file.path().to_path_buf(), vec![])];
        let mut writer = Vec::new();

        // Test with use_color = false to get markdown fences
        print_output(
            &mut writer,
            &paths,
            &Format::Markdown,
            false,
            false,
            false,
            0,
        )
        .unwrap();

        let output = String::from_utf8(writer).unwrap();

        let expected_header = format!("File: {}\n---\n", file.path().display());
        assert!(output.starts_with(&expected_header));
        // The extension of a tempfile is random, so we check for an empty language hint
        assert!(output.contains("```\nline 1\n```\n"));
    }

    #[test]
    fn test_format_markdown_with_ansi_color() {
        let file = create_temp_file_with_content("fn main() {}");
        // Give it a .rs extension so syntect can find the grammar
        let rs_path = file.path().with_extension("rs");
        std::fs::rename(file.path(), &rs_path).unwrap();

        let paths = vec![(rs_path, vec![])];
        let mut writer = Vec::new();
        print_output(&mut writer, &paths, &Format::Cat, false, false, true, 0).unwrap();
        let output = String::from_utf8(writer).unwrap();

        // Check for evidence of ANSI color, not the exact codes which can be brittle.
        assert!(output.contains("\x1b["), "Should contain ANSI escape codes");
        assert!(
            !output.contains("```"),
            "Should not contain markdown fences"
        );
    }

    #[test]
    fn test_format_markdown_ignores_color_flag() {
        let file = create_temp_file_with_content("fn main() {}");
        let paths = vec![(file.path().to_path_buf(), vec![])];
        let mut writer = Vec::new();

        // Test with use_color = true, which should be ignored for the Markdown format.
        print_output(&mut writer, &paths, &Format::Markdown, false, false, true, 0).unwrap();

        let output = String::from_utf8(writer).unwrap();

        // Check that the output is standard markdown and does not contain color codes.
        assert!(
            output.contains("```"),
            "Markdown format should use code fences"
        );
        assert!(
            !output.contains("\x1b["),
            "Markdown format should not contain ANSI escape codes"
        );
    }

    #[test]
    fn test_format_find() {
        let file = create_temp_file_with_content("hello");
        let paths = vec![(file.path().to_path_buf(), vec![])];
        let mut writer = Vec::new();
        print_output(&mut writer, &paths, &Format::Find, false, false, false, 0).unwrap();
        let output = String::from_utf8(writer).unwrap();
        assert!(output.contains("B")); // Size
        assert!(output.contains(&file.path().display().to_string()));
    }
}

---

File: ./rdump/src/main.rs
---
// Declare all our modules
mod commands;
mod config;
mod evaluator;
mod formatter;
mod parser;
mod predicates;

use anyhow::Result;
use clap::{Parser, Subcommand, ValueEnum};
use std::path::PathBuf;

// Bring our command functions into scope
use commands::{lang::run_lang, preset::run_preset, search::run_search};

// These structs and enums define the public API of our CLI.
// They need to be public so the `commands` modules can use them.
#[derive(Parser, Debug)]
#[command(
    version,
    about = "A fast, expressive, code-aware tool to find and dump file contents."
)]
pub struct Cli {
    #[command(subcommand)]
    pub command: Commands,
}

#[derive(Subcommand, Debug)]
pub enum Commands {
    /// Search for files using a query (default command).
    #[command(visible_alias = "s")]
    Search(SearchArgs),
    /// List supported languages and their available predicates.
    #[command(visible_alias = "l")]
    Lang(LangArgs),
    /// Manage saved presets.
    #[command(visible_alias = "p")]
    Preset(PresetArgs),
}

#[derive(Debug, Clone, ValueEnum, Default, PartialEq)]
pub enum ColorChoice {
    #[default]
    Auto,
    Always,
    Never,
}

#[derive(Parser, Debug)]
pub struct SearchArgs {
    /// The query string to search for, using rdump Query Language (RQL).
    ///
    /// RQL supports logical operators (&, |, !), parentheses, and key:value predicates.
    /// Values with spaces must be quoted (e.g., contains:'fn main').
    ///
    /// METADATA PREDICATES:
    ///   ext:<str>          - File extension (e.g., "rs", "toml")
    ///   name:<glob>        - File name glob pattern (e.g., "test_*.rs")
    ///   path:<str>         - Substring in the full file path
    ///   in:<path>          - Directory path to search within
    ///   size:[>|<]<num>[kb|mb] - File size (e.g., ">10kb")
    ///   modified:[>|<]<num>[h|d|w] - Modified time (e.g., "<2d")
    ///
    /// CONTENT PREDICATES:
    ///   contains:<str>     - Literal string a file contains
    ///   matches:<regex>    - Regular expression a file's content matches
    ///
    #[doc = "CODE-AWARE PREDICATES for supported languages:"]
    ///   def:<str>          - A generic definition (class, struct, enum, etc.)
    ///   func:<str>         - A function or method
    ///   import:<str>       - An import or use statement
    ///   call:<str>         - A function or method call site
    ///
    /// GRANULAR DEFINITIONS:
    ///   class:<str>        - A class definition
    ///   struct:<str>       - A struct definition
    ///   enum:<str>         - An enum definition
    ///   interface:<str>    - An interface definition
    ///   trait:<str>        - A trait definition
    ///   type:<str>         - A type alias
    ///
    /// SYNTACTIC CONTENT:
    ///   comment:<str>      - Text inside a comment (e.g., "TODO", "FIXME")
    ///   str:<str>          - Text inside a string literal
    #[arg(verbatim_doc_comment, name = "QUERY_PARTS")]
    pub query: Vec<String>,
    #[arg(long, short)]
    pub preset: Vec<String>,
    #[arg(short, long, default_value = ".")]
    pub root: PathBuf,
    #[arg(short, long)]
    pub output: Option<PathBuf>,
    #[arg(short, long)]
    pub line_numbers: bool,
    #[arg(long, help = "Alias for --format=cat, useful for piping")]
    pub no_headers: bool,
    #[arg(long, value_enum, default_value_t = Format::Hunks)]
    pub format: Format,
    #[arg(long)]
    pub no_ignore: bool,
    #[arg(long)]
    pub hidden: bool,
    #[arg(long, value_enum, default_value_t = ColorChoice::Auto, help = "When to use syntax highlighting")]
    pub color: ColorChoice,
    #[arg(long)]
    pub max_depth: Option<usize>,
    #[arg(
        long,
        short = 'C',
        value_name = "LINES",
        help = "Show LINES of context around matches for --format=hunks"
    )]
    pub context: Option<usize>,

    /// List files with metadata instead of dumping content. Alias for --format=find
    #[arg(long)]
    pub find: bool,
}

#[derive(Parser, Debug)]
pub struct LangArgs {
    #[command(subcommand)]
    pub action: Option<LangAction>,
}

#[derive(Subcommand, Debug, Clone)]
pub enum LangAction {
    /// List all supported languages.
    List,
    /// Describe the predicates available for a specific language.
    Describe { language: String },
}

#[derive(Parser, Debug)]
pub struct PresetArgs {
    #[command(subcommand)]
    pub action: PresetAction,
}

#[derive(Subcommand, Debug, Clone)]
pub enum PresetAction {
    /// List all available presets.
    List,
    /// Add or update a preset in the global config file.
    Add {
        #[arg(required = true)]
        name: String,
        #[arg(required = true)]
        query: String,
    },
    /// Remove a preset from the global config file.
    Remove {
        #[arg(required = true)]
        name: String,
    },
}

#[derive(Debug, Clone, ValueEnum)]
pub enum Format {
    /// Show only the specific code blocks ("hunks") that match a semantic query
    Hunks,
    /// Human-readable markdown with file headers
    Markdown,
    /// Machine-readable JSON
    Json,
    /// A simple list of matching file paths
    Paths,
    /// Raw concatenated file content, for piping
    Cat,
    /// `ls`-like output with file metadata
    Find,
}

/// The main entry point.
/// Its only job is to parse the CLI and delegate to the correct command module.
fn main() -> Result<()> {
    let cli = Cli::parse();

    match cli.command {
        Commands::Search(args) => run_search(args),
        Commands::Lang(args) => {
            // Default to `list` if no subcommand is given for `lang`
            let action = args.action.unwrap_or(LangAction::List);
            run_lang(action)
        }
        Commands::Preset(args) => run_preset(args.action),
    }
}

---

File: ./rdump/src/parser.rs
---
use anyhow::{anyhow, Result};
use pest::iterators::Pair;
use pest::Parser;
use pest_derive::Parser;

#[derive(Parser)]
#[grammar = "rql.pest"]
pub struct RqlParser;

#[derive(Debug, PartialEq, Eq, Hash, Clone)]
pub enum PredicateKey {
    Ext,
    Name,
    Path,
    Contains,
    Matches,
    Size,
    Modified,
    In,
    // --- SEMANTIC PREDICATES ---
    // Generic
    Def,
    Func,
    Import,
    // Granular Definitions
    Class,
    Struct,
    Enum,
    Interface,
    Trait,
    Type,
    // Syntactic Content
    Comment,
    Str,
    // Usage
    Call,
    // A key for testing or unknown predicates
    Other(String),
}

impl AsRef<str> for PredicateKey {
    fn as_ref(&self) -> &str {
        match self {
            PredicateKey::Ext => "ext",
            PredicateKey::Name => "name",
            PredicateKey::Path => "path",
            PredicateKey::Contains => "contains",
            PredicateKey::Matches => "matches",
            PredicateKey::Size => "size",
            PredicateKey::Modified => "modified",
            PredicateKey::In => "in",
            PredicateKey::Def => "def",
            PredicateKey::Func => "func",
            PredicateKey::Import => "import",
            PredicateKey::Class => "class",
            PredicateKey::Struct => "struct",
            PredicateKey::Enum => "enum",
            PredicateKey::Interface => "interface",
            PredicateKey::Trait => "trait",
            PredicateKey::Type => "type",
            PredicateKey::Comment => "comment",
            PredicateKey::Str => "str",
            PredicateKey::Call => "call",
            PredicateKey::Other(s) => s.as_str(),
        }
    }
}

impl From<&str> for PredicateKey {
    fn from(s: &str) -> Self {
        match s {
            "ext" => Self::Ext,
            "name" => Self::Name,
            "path" => Self::Path,
            "contains" => Self::Contains,
            "matches" => Self::Matches,
            "size" => Self::Size,
            "modified" => Self::Modified,
            "in" => Self::In,
            // --- SEMANTIC ---
            "def" => Self::Def,
            "func" => Self::Func,
            "import" => Self::Import,
            "class" => Self::Class,
            "struct" => Self::Struct,
            "enum" => Self::Enum,
            "interface" => Self::Interface,
            "trait" => Self::Trait,
            "type" => Self::Type,
            "comment" => Self::Comment,
            "str" => Self::Str,
            "call" => Self::Call,
            // Any other key is captured here.
            other => Self::Other(other.to_string()),
        }
    }
}

#[derive(Debug, PartialEq, Clone)]
pub enum AstNode {
    Predicate(PredicateKey, String),
    LogicalOp(LogicalOperator, Box<AstNode>, Box<AstNode>),
    Not(Box<AstNode>),
}

#[derive(Debug, PartialEq, Clone)]
pub enum LogicalOperator {
    And,
    Or,
}

pub fn parse_query(query: &str) -> Result<AstNode> {
    // Check for empty or whitespace-only queries BEFORE parsing.
    if query.trim().is_empty() {
        return Err(anyhow!("Query cannot be empty."));
    }

    match RqlParser::parse(Rule::query, query) {
        Ok(pairs) => build_ast_from_pairs(pairs.peek().unwrap()),
        Err(e) => {
            // Re-format the pest error to be more user-friendly.
            Err(anyhow!("Invalid query syntax:\n{}", e))
        }
    }
}

fn build_ast_from_pairs(pair: Pair<Rule>) -> Result<AstNode> {
    match pair.as_rule() {
        Rule::query => build_ast_from_pairs(pair.into_inner().next().unwrap()),
        Rule::expression | Rule::logical_or | Rule::logical_and => build_ast_from_logical_op(pair),
        Rule::term => {
            let mut inner = pair.into_inner();
            let first = inner.next().unwrap();
            if first.as_rule() == Rule::NOT {
                let factor = inner.next().unwrap();
                let ast = build_ast_from_pairs(factor)?;
                Ok(AstNode::Not(Box::new(ast)))
            } else {
                build_ast_from_pairs(first)
            }
        }
        Rule::factor => build_ast_from_pairs(pair.into_inner().next().unwrap()),
        Rule::predicate => {
            let mut predicate_parts = pair.into_inner();
            let key_pair = predicate_parts.next().unwrap();
            let value_pair = predicate_parts.next().unwrap();
            let key = PredicateKey::from(key_pair.as_str());
            let value = unescape_value(value_pair.as_str());
            Ok(AstNode::Predicate(key, value))
        }
        _ => Err(anyhow!("Unknown rule: {:?}", pair.as_rule())),
    }
}

fn build_ast_from_logical_op(pair: Pair<Rule>) -> Result<AstNode> {
    let mut inner_pairs = pair.into_inner();
    let mut ast = build_ast_from_pairs(inner_pairs.next().unwrap())?;

    while let Some(op_pair) = inner_pairs.next() {
        let op = match op_pair.as_str().to_lowercase().as_str() {
            "&" | "and" => LogicalOperator::And,
            "|" | "or" => LogicalOperator::Or,
            _ => unreachable!(),
        };
        let right_pair = inner_pairs.next().unwrap();
        let right_ast = build_ast_from_pairs(right_pair)?;
        ast = AstNode::LogicalOp(op, Box::new(ast), Box::new(right_ast));
    }
    Ok(ast)
}

fn unescape_value(value: &str) -> String {
    let quote_char = value.chars().next();
    if quote_char == Some('"') || quote_char == Some('\'') {
        let inner = &value[1..value.len() - 1];
        let mut unescaped = String::with_capacity(inner.len());
        let mut chars = inner.chars();
        while let Some(c) = chars.next() {
            if c == '\\' {
                if let Some(next_c) = chars.next() {
                    unescaped.push(next_c);
                }
            } else {
                unescaped.push(c);
            }
        }
        return unescaped;
    }
    value.to_string()
}

#[cfg(test)]
mod tests {
    use super::*;

    // Helper to create a predicate node for cleaner tests.
    fn predicate(key: PredicateKey, value: &str) -> Box<AstNode> {
        Box::new(AstNode::Predicate(key, value.to_string()))
    }

    #[test]
    fn test_parse_simple_predicate() {
        let ast = parse_query("ext:rs").unwrap();
        assert_eq!(ast, *predicate(PredicateKey::Ext, "rs"));
    }

    #[test]
    fn test_parse_predicate_with_quoted_value() {
        let ast = parse_query("name:\"foo bar\"").unwrap();
        assert_eq!(ast, *predicate(PredicateKey::Name, "foo bar"));
    }

    #[test]
    fn test_parse_logical_and() {
        let ast = parse_query("ext:rs & name:\"foo\"").unwrap();
        assert_eq!(
            ast,
            AstNode::LogicalOp(
                LogicalOperator::And,
                predicate(PredicateKey::Ext, "rs"),
                predicate(PredicateKey::Name, "foo")
            )
        );
    }

    #[test]
    fn test_parse_logical_or() {
        let ast = parse_query("ext:rs | ext:toml").unwrap();
        assert_eq!(
            ast,
            AstNode::LogicalOp(
                LogicalOperator::Or,
                predicate(PredicateKey::Ext, "rs"),
                predicate(PredicateKey::Ext, "toml")
            )
        );
    }

    #[test]
    fn test_parse_negation() {
        let ast = parse_query("!ext:rs").unwrap();
        assert_eq!(ast, AstNode::Not(predicate(PredicateKey::Ext, "rs")));
    }

    #[test]
    fn test_parse_complex_query() {
        let ast = parse_query("ext:rs & (name:\"foo\" | name:\"bar\") & !path:tests").unwrap();
        let inner_or = AstNode::LogicalOp(
            LogicalOperator::Or,
            predicate(PredicateKey::Name, "foo"),
            predicate(PredicateKey::Name, "bar"),
        );
        let and_with_or = AstNode::LogicalOp(
            LogicalOperator::And,
            predicate(PredicateKey::Ext, "rs"),
            Box::new(inner_or),
        );
        let final_ast = AstNode::LogicalOp(
            LogicalOperator::And,
            Box::new(and_with_or),
            Box::new(AstNode::Not(predicate(PredicateKey::Path, "tests"))),
        );
        assert_eq!(ast, final_ast);
    }

    #[test]
    fn test_unescape_value() {
        assert_eq!(unescape_value(r#""hello \"world\"""#), "hello \"world\"");
        assert_eq!(unescape_value(r#"'hello \'world\''"#), "hello 'world'");
        assert_eq!(unescape_value(r#""a \\ b""#), "a \\ b");
        assert_eq!(unescape_value("no_quotes"), "no_quotes");
    }

    #[test]
    fn test_parse_predicate_with_special_chars_in_value() {
        let ast = parse_query(r#"name:"foo&bar""#).unwrap();
        assert_eq!(ast, *predicate(PredicateKey::Name, "foo&bar"));
    }

    #[test]
    fn test_parse_semantic_predicates() {
        let ast_def = parse_query("def:User").unwrap();
        assert_eq!(ast_def, *predicate(PredicateKey::Def, "User"));

        let ast_func = parse_query("func:get_user").unwrap();
        assert_eq!(ast_func, *predicate(PredicateKey::Func, "get_user"));

        let ast_import = parse_query("import:serde").unwrap();
        assert_eq!(ast_import, *predicate(PredicateKey::Import, "serde"));
    }

    #[test]
    fn test_parse_granular_and_syntactic_predicates() {
        assert_eq!(
            parse_query("class:Foo").unwrap(),
            *predicate(PredicateKey::Class, "Foo")
        );
        assert_eq!(
            parse_query("struct:Bar").unwrap(),
            *predicate(PredicateKey::Struct, "Bar")
        );
        assert_eq!(
            parse_query("comment:TODO").unwrap(),
            *predicate(PredicateKey::Comment, "TODO")
        );
        assert_eq!(
            parse_query("str:'api_key'").unwrap(),
            *predicate(PredicateKey::Str, "api_key")
        );
        assert_eq!(
            parse_query("call:my_func").unwrap(),
            *predicate(PredicateKey::Call, "my_func")
        );
    }

    #[test]
    fn test_error_on_trailing_operator() {
        let result = parse_query("ext:rs &");
        let err = result.unwrap_err();
        assert!(err.to_string().contains("Invalid query syntax:"));
        assert!(err.to_string().contains("expected")); // Pest's pointer is still useful
    }

    #[test]
    fn test_error_on_missing_value() {
        let result = parse_query("ext:");
        let err = result.unwrap_err();
        assert!(err.to_string().contains("Invalid query syntax:"));
    }

    #[test]
    fn test_error_on_unclosed_parenthesis() {
        let result = parse_query("(ext:rs | path:src");
        let err = result.unwrap_err();
        assert!(err.to_string().contains("Invalid query syntax:"));
    }

    #[test]
    fn test_error_on_empty_query() {
        let result = parse_query("");
        assert_eq!(result.unwrap_err().to_string(), "Query cannot be empty.");
    }

    #[test]
    fn test_error_on_whitespace_query() {
        let result = parse_query("   ");
        assert_eq!(result.unwrap_err().to_string(), "Query cannot be empty.");
    }

    #[test]
    fn test_parse_keyword_operators() {
        // AND
        let ast_and = parse_query("ext:rs and name:\"foo\"").unwrap();
        assert_eq!(
            ast_and,
            AstNode::LogicalOp(
                LogicalOperator::And,
                predicate(PredicateKey::Ext, "rs"),
                predicate(PredicateKey::Name, "foo")
            )
        );

        // OR
        let ast_or = parse_query("ext:rs or ext:toml").unwrap();
        assert_eq!(
            ast_or,
            AstNode::LogicalOp(
                LogicalOperator::Or,
                predicate(PredicateKey::Ext, "rs"),
                predicate(PredicateKey::Ext, "toml")
            )
        );

        // NOT
        let ast_not = parse_query("not ext:rs").unwrap();
        assert_eq!(ast_not, AstNode::Not(predicate(PredicateKey::Ext, "rs")));
    }

    #[test]
    fn test_parse_mixed_operators() {
        let ast = parse_query("ext:rs and (name:foo or name:bar) & not path:tests").unwrap();
        let inner_or = AstNode::LogicalOp(
            LogicalOperator::Or,
            predicate(PredicateKey::Name, "foo"),
            predicate(PredicateKey::Name, "bar"),
        );
        let and_with_or = AstNode::LogicalOp(
            LogicalOperator::And,
            predicate(PredicateKey::Ext, "rs"),
            Box::new(inner_or),
        );
        let final_ast = AstNode::LogicalOp(
            LogicalOperator::And,
            Box::new(and_with_or),
            Box::new(AstNode::Not(predicate(PredicateKey::Path, "tests"))),
        );
        assert_eq!(ast, final_ast);
    }

    #[test]
    fn test_parse_unknown_predicate() {
        let ast = parse_query("unknown:predicate").unwrap();
        assert_eq!(
            ast,
            *predicate(PredicateKey::Other("unknown".to_string()), "predicate")
        );
    }
}

---

File: ./rdump/src/predicates/code_aware/mod.rs
---
use crate::evaluator::{FileContext, MatchResult};
use crate::parser::PredicateKey;
use crate::predicates::PredicateEvaluator;
use anyhow::{Context, Result};
use tree_sitter::{Query, QueryCursor};

pub mod profiles;

/// The evaluator that uses tree-sitter to perform code-aware queries.
#[derive(Debug, Clone)]
pub struct CodeAwareEvaluator;

impl PredicateEvaluator for CodeAwareEvaluator {
    fn evaluate(
        &self,
        context: &mut FileContext,
        key: &PredicateKey,
        value: &str,
    ) -> Result<MatchResult> {
        // 1. Determine the language from the file extension.
        let extension = context
            .path
            .extension()
            .and_then(|s| s.to_str())
            .unwrap_or("");
        let binding = profiles::list_language_profiles();
        let profile = match binding.iter().find(|p| p.extensions.contains(&extension)) {
            Some(p) => p,
            None => return Ok(MatchResult::Boolean(false)), // Not a supported language for this predicate.
        };

        // 2. Get the tree-sitter query string for the specific predicate.
        let ts_query_str = match profile.queries.get(key) {
            Some(q) if !q.is_empty() => q,
            _ => return Ok(MatchResult::Boolean(false)), // This predicate is not implemented for this language yet.
        };

        // 3. Get content and lazily get the parsed tree from the file context.
        let content = context.get_content()?.to_string(); // Clone to avoid borrow issues
        let tree = match context.get_tree(profile.language.clone()) {
            Ok(tree) => tree,
            Err(e) => {
                eprintln!(
                    "Warning: Failed to parse {}: {}. Skipping.",
                    context.path.display(),
                    e
                );
                return Ok(MatchResult::Boolean(false));
            }
        };

        // 4. Compile the tree-sitter query.
        let query = Query::new(&profile.language, ts_query_str)
            .with_context(|| format!("Failed to compile tree-sitter query for key {key:?}"))?;
        let mut cursor = QueryCursor::new();
        let mut ranges = Vec::new();

        // 5. Execute the query and check for a match.
        let captures = cursor.matches(&query, tree.root_node(), content.as_bytes());

        for m in captures {
            for capture in m.captures {
                // We only care about nodes captured with the name `@match`.
                let capture_name = &query.capture_names()[capture.index as usize];
                if *capture_name != "match" {
                    continue;
                }

                let captured_node = capture.node;
                let captured_text = captured_node.utf8_text(content.as_bytes())?;

                // Use the correct matching strategy based on the predicate type.
                let is_match = match key {
                    // Content-based predicates check for substrings.
                    PredicateKey::Import | PredicateKey::Comment | PredicateKey::Str => {
                        captured_text.contains(value)
                    }
                    // Definition-based predicates require an exact match on the identifier, unless a wildcard is used.
                    _ => value == "." || captured_text == value,
                };

                if is_match {
                    ranges.push(captured_node.range());
                }
            }
        }

        Ok(MatchResult::Hunks(ranges))
    }
}

---

File: ./rdump/src/predicates/code_aware/profiles/go.rs
---
use super::LanguageProfile;
use crate::parser::PredicateKey;
use std::collections::HashMap;

/// Creates the profile for the Go language.
pub(super) fn create_go_profile() -> LanguageProfile {
    let language = tree_sitter_go::language();
    let mut queries = HashMap::new();

    let type_query = "(type_declaration (type_spec name: (type_identifier) @match))";
    let func_query = "[ (function_declaration name: (identifier) @match) (method_declaration name: (field_identifier) @match) ]";

    // --- Definitions ---
    let struct_query =
        "(type_declaration (type_spec name: (type_identifier) @match type: (struct_type)))";
    let interface_query =
        "(type_declaration (type_spec name: (type_identifier) @match type: (interface_type)))";

    queries.insert(PredicateKey::Def, [type_query, func_query].join("\n"));
    queries.insert(PredicateKey::Struct, struct_query.to_string());
    queries.insert(PredicateKey::Interface, interface_query.to_string());
    queries.insert(PredicateKey::Type, type_query.to_string());

    // --- Functions & Calls ---
    queries.insert(PredicateKey::Func, func_query.to_string());
    queries.insert(PredicateKey::Call, "(call_expression function: [ (identifier) @match (selector_expression field: (field_identifier) @match) ])".to_string());

    // --- Other ---
    queries.insert(
        PredicateKey::Import,
        "(import_declaration) @match".to_string(),
    );
    queries.insert(PredicateKey::Comment, "(comment) @match".to_string());
    queries.insert(
        PredicateKey::Str,
        "[ (interpreted_string_literal) @match (raw_string_literal) @match ]".to_string(),
    );

    LanguageProfile {
        name: "Go",
        extensions: vec!["go"],
        language,
        queries,
    }
}

---

File: ./rdump/src/predicates/code_aware/profiles/java.rs
---
use super::LanguageProfile;
use crate::parser::PredicateKey;
use std::collections::HashMap;

/// Creates the profile for the Java language.
pub(super) fn create_java_profile() -> LanguageProfile {
    let language = tree_sitter_java::language();
    let mut queries = HashMap::new();

    // --- Definitions ---
    let class_query = "(class_declaration name: (identifier) @match)";
    let interface_query = "(interface_declaration name: (identifier) @match)";
    let enum_query = "(enum_declaration name: (identifier) @match)";

    queries.insert(
        PredicateKey::Def,
        format!("[ {class_query} {interface_query} {enum_query} ]"),
    );
    queries.insert(PredicateKey::Class, class_query.to_string());
    queries.insert(PredicateKey::Interface, interface_query.to_string());
    queries.insert(PredicateKey::Enum, enum_query.to_string());

    // --- Functions & Calls ---
    queries.insert(PredicateKey::Func, "[ (method_declaration name: (identifier) @match) (constructor_declaration name: (identifier) @match) ]".to_string());
    queries.insert(PredicateKey::Call, "[ (method_invocation name: (identifier) @match) (object_creation_expression type: (type_identifier) @match) ]".to_string());

    // --- Other ---
    queries.insert(
        PredicateKey::Import,
        "(import_declaration) @match".to_string(),
    );
    queries.insert(
        PredicateKey::Comment,
        "[(line_comment) @match (block_comment) @match]".to_string(),
    );
    queries.insert(PredicateKey::Str, "(string_literal) @match".to_string());

    LanguageProfile {
        name: "Java",
        extensions: vec!["java"],
        language,
        queries,
    }
}

---

File: ./rdump/src/predicates/code_aware/profiles/javascript.rs
---
use super::LanguageProfile;
use crate::parser::PredicateKey;
use std::collections::HashMap;

/// Creates the profile for the JavaScript language.
pub(super) fn create_javascript_profile() -> LanguageProfile {
    let language = tree_sitter_javascript::language();
    let mut queries = HashMap::new();

    let class_query = "(class_declaration name: (identifier) @match)";
    let func_query = "[ (function_declaration name: (identifier) @match) (method_definition name: (property_identifier) @match) ]";

    queries.insert(PredicateKey::Def, [class_query, func_query].join("\n"));
    queries.insert(PredicateKey::Class, class_query.to_string());
    queries.insert(PredicateKey::Func, func_query.to_string());

    queries.insert(
        PredicateKey::Import,
        "(import_statement) @match".to_string(),
    );
    queries.insert(
       PredicateKey::Call,
       "[ (call_expression function: [ (identifier) @match (member_expression property: (property_identifier) @match) ]) (new_expression constructor: (identifier) @match) ]".to_string()
   );

    queries.insert(
        PredicateKey::Comment,
        "[(comment) @match (regex) @match]".to_string(),
    ); // JS Regexes are basically comments
    queries.insert(
        PredicateKey::Str,
        "[(string) @match (template_string) @match]".to_string(),
    );

    LanguageProfile {
        name: "JavaScript",
        extensions: vec!["js", "jsx"],
        language,
        queries,
    }
}

---

File: ./rdump/src/predicates/code_aware/profiles/mod.rs
---
use crate::parser::PredicateKey;
use once_cell::sync::Lazy;
use std::collections::HashMap;

mod go;
mod java;
mod javascript;
mod python;
mod rust;
mod typescript;

/// Defines the tree-sitter queries and metadata for a specific language.
pub struct LanguageProfile {
    pub name: &'static str,
    pub extensions: Vec<&'static str>,
    pub(super) language: tree_sitter::Language,
    pub queries: HashMap<PredicateKey, String>,
}

pub(super) static LANGUAGE_PROFILES: Lazy<HashMap<&'static str, LanguageProfile>> =
    Lazy::new(|| {
        let mut m = HashMap::new();
        m.insert("rs", rust::create_rust_profile());
        m.insert("py", python::create_python_profile());
        m.insert("go", go::create_go_profile());
        m.insert("java", java::create_java_profile());
        m.insert("ts", typescript::create_typescript_profile());
        m.insert("js", javascript::create_javascript_profile());
        m
    });

/// Returns a list of all configured language profiles.
pub fn list_language_profiles() -> Vec<&'static LanguageProfile> {
    LANGUAGE_PROFILES.values().collect()
}

---

File: ./rdump/src/predicates/code_aware/profiles/python.rs
---
use super::LanguageProfile;
use crate::parser::PredicateKey;
use std::collections::HashMap;

/// Creates the profile for the Python language.
pub(super) fn create_python_profile() -> LanguageProfile {
    let language = tree_sitter_python::language();
    let mut queries = HashMap::new();

    let class_query = "(class_definition name: (identifier) @match)";
    let func_query = "(function_definition name: (identifier) @match)";

    queries.insert(PredicateKey::Def, [class_query, func_query].join("\n"));
    queries.insert(PredicateKey::Class, class_query.to_string());
    queries.insert(PredicateKey::Func, func_query.to_string());

    // Query for `import` and `from ... import` statements.
    queries.insert(
        PredicateKey::Import,
        "
        [
            (import_statement) @match
            (import_from_statement) @match
        ]
        "
        .to_string(),
    );

    // Query for function and method call sites.
    queries.insert(
        PredicateKey::Call,
        "
       (call
           function: [
               (identifier) @match
               (attribute attribute: (identifier) @match)
           ]
       )
       "
        .to_string(),
    );

    queries.insert(PredicateKey::Comment, "(comment) @match".to_string());
    queries.insert(PredicateKey::Str, "(string) @match".to_string());

    LanguageProfile {
        name: "Python",
        extensions: vec!["py"],
        language,
        queries,
    }
}

---

File: ./rdump/src/predicates/code_aware/profiles/rust.rs
---
use super::LanguageProfile;
use crate::parser::PredicateKey;
use std::collections::HashMap;

/// Creates the profile for the Rust language.
pub(super) fn create_rust_profile() -> LanguageProfile {
    let language = tree_sitter_rust::language();
    let mut queries = HashMap::new();

    let struct_query = "(struct_item name: (_) @match)";
    let enum_query = "(enum_item name: (_) @match)";
    let trait_query = "(trait_item name: (_) @match)";
    let type_query = "(type_item name: (type_identifier) @match)";

    let def_query = [struct_query, enum_query, trait_query, type_query].join("\n");

    queries.insert(PredicateKey::Def, def_query);
    queries.insert(PredicateKey::Struct, struct_query.to_string());
    queries.insert(PredicateKey::Enum, enum_query.to_string());
    queries.insert(PredicateKey::Trait, trait_query.to_string());
    queries.insert(PredicateKey::Type, type_query.to_string());

    // Query for standalone functions and methods in traits or impls.
    queries.insert(
        PredicateKey::Func,
        "
        [
            (function_item name: (identifier) @match)
            (function_signature_item name: (identifier) @match)
        ]"
        .to_string(),
    );
    // Query for the entire `use` declaration. We will match against its text content.
    queries.insert(
        PredicateKey::Import,
        "
        (use_declaration) @match
        "
        .to_string(),
    );

    // Query for function and method call sites.
    queries.insert(
        PredicateKey::Call,
        "
       (call_expression
           function: [
               (identifier) @match
               (field_expression field: (field_identifier) @match)
           ]
       )
       (macro_invocation macro: (identifier) @match)
       "
        .to_string(),
    );

    queries.insert(
        PredicateKey::Comment,
        "[(line_comment) @match (block_comment) @match]".to_string(),
    );
    queries.insert(
        PredicateKey::Str,
        "[(string_literal) @match (raw_string_literal) @match]".to_string(),
    );

    LanguageProfile {
        name: "Rust",
        extensions: vec!["rs"],
        language,
        queries,
    }
}

---

File: ./rdump/src/predicates/code_aware/profiles/typescript.rs
---
use super::LanguageProfile;
use crate::parser::PredicateKey;
use std::collections::HashMap;

/// Creates the profile for the TypeScript language.
pub(super) fn create_typescript_profile() -> LanguageProfile {
    let language = tree_sitter_typescript::language_typescript();
    let mut queries = HashMap::new();

    let class_query = "(class_declaration name: (type_identifier) @match)";
    let interface_query = "(interface_declaration name: (type_identifier) @match)";
    let type_query = "(type_alias_declaration name: (type_identifier) @match)";
    let enum_query = "(enum_declaration name: (identifier) @match)";

    let def_query = [class_query, interface_query, type_query, enum_query].join("\n");
    queries.insert(PredicateKey::Def, def_query);

    queries.insert(PredicateKey::Class, class_query.to_string());
    queries.insert(PredicateKey::Interface, interface_query.to_string());
    queries.insert(PredicateKey::Type, type_query.to_string());
    queries.insert(PredicateKey::Enum, enum_query.to_string());

    queries.insert(PredicateKey::Func, "[ (function_declaration name: (identifier) @match) (method_definition name: (property_identifier) @match) ]".to_string());
    queries.insert(
        PredicateKey::Import,
        "(import_statement) @match".to_string(),
    );
    queries.insert(
       PredicateKey::Call,
       "[ (call_expression function: [ (identifier) @match (member_expression property: (property_identifier) @match) ]) (new_expression constructor: [ (identifier) @match (type_identifier) @match ]) ]".to_string()
   );

    queries.insert(PredicateKey::Comment, "(comment) @match".to_string());
    queries.insert(
        PredicateKey::Str,
        "[(string) @match (template_string) @match]".to_string(),
    );

    LanguageProfile {
        name: "TypeScript",
        extensions: vec!["ts", "tsx"],
        language,
        queries,
    }
}

---

File: ./rdump/src/predicates/contains.rs
---
use super::PredicateEvaluator;
use crate::evaluator::{FileContext, MatchResult};
use crate::parser::PredicateKey;
use anyhow::Result;
use tree_sitter::Range;

pub(super) struct ContainsEvaluator;

impl PredicateEvaluator for ContainsEvaluator {
    fn evaluate(
        &self,
        context: &mut FileContext,
        _key: &PredicateKey,
        value: &str,
    ) -> Result<MatchResult> {
        let content = context.get_content()?;
        let mut ranges = Vec::new();
        for (i, line) in content.lines().enumerate() {
            if line.to_lowercase().contains(&value.to_lowercase()) {
                let start_byte = content.lines().take(i).map(|l| l.len() + 1).sum();
                let end_byte = start_byte + line.len();
                let range = Range {
                    start_byte,
                    end_byte,
                    start_point: tree_sitter::Point { row: i, column: 0 },
                    end_point: tree_sitter::Point {
                        row: i,
                        column: line.len(),
                    },
                };
                ranges.push(range);
            }
        }
        Ok(MatchResult::Hunks(ranges))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::io::Write;
    use std::path::PathBuf;
    use tempfile::NamedTempFile;
    fn create_temp_file(content: &str) -> NamedTempFile {
        let mut file = NamedTempFile::new().unwrap();
        write!(file, "{}", content).unwrap();
        file
    }
    #[test]
    fn test_contains_evaluator() {
        let file = create_temp_file("Hello world\nThis is a test.");
        let mut context = FileContext::new(file.path().to_path_buf(), PathBuf::from("/"));
        let evaluator = ContainsEvaluator;
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Contains, "world")
            .unwrap()
            .is_match());
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Contains, "is a test")
            .unwrap()
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context, &PredicateKey::Contains, "goodbye")
            .unwrap()
            .is_match());
    }
}

---

File: ./rdump/src/predicates/ext.rs
---
use super::PredicateEvaluator;
use crate::evaluator::{FileContext, MatchResult};
use crate::parser::PredicateKey;
use anyhow::Result;

pub(super) struct ExtEvaluator;
impl PredicateEvaluator for ExtEvaluator {
    fn evaluate(
        &self,
        context: &mut FileContext,
        _key: &PredicateKey,
        value: &str,
    ) -> Result<MatchResult> {
        let file_ext = context
            .path
            .extension()
            .and_then(|s| s.to_str())
            .unwrap_or("");
        Ok(MatchResult::Boolean(file_ext.eq_ignore_ascii_case(value)))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::path::PathBuf;

    #[test]
    fn test_ext_evaluator() {
        let mut context_rs = FileContext::new(PathBuf::from("main.rs"), PathBuf::from("/"));
        let mut context_toml = FileContext::new(PathBuf::from("Cargo.TOML"), PathBuf::from("/"));
        let mut context_no_ext = FileContext::new(PathBuf::from("README"), PathBuf::from("/"));
        let mut context_dotfile = FileContext::new(PathBuf::from(".bashrc"), PathBuf::from("/"));

        let evaluator = ExtEvaluator;
        assert!(evaluator
            .evaluate(&mut context_rs, &PredicateKey::Ext, "rs")
            .unwrap()
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context_rs, &PredicateKey::Ext, "toml")
            .unwrap()
            .is_match());
        assert!(
            evaluator
                .evaluate(&mut context_toml, &PredicateKey::Ext, "toml")
                .unwrap()
                .is_match(),
            "Should be case-insensitive"
        );
        assert!(!evaluator
            .evaluate(&mut context_no_ext, &PredicateKey::Ext, "rs")
            .unwrap()
            .is_match());
        assert!(
            !evaluator
                .evaluate(&mut context_dotfile, &PredicateKey::Ext, "bashrc")
                .unwrap()
                .is_match(),
            "Dotfiles should have no extension"
        );
    }
}

---

File: ./rdump/src/predicates/helpers.rs
---
use anyhow::{anyhow, Result};
use chrono::{Local, NaiveDate, NaiveDateTime, NaiveTime, TimeZone};
use std::time::{Duration, SystemTime};

pub(super) fn parse_and_compare_size(file_size: u64, query: &str) -> Result<bool> {
    let query = query.trim();
    let (op, size_str) = if query.starts_with(['>', '<', '=']) {
        query.split_at(1)
    } else {
        ("=", query)
    };

    let size_str = size_str.trim().to_lowercase();
    let (num_str, unit) = size_str.split_at(
        size_str
            .find(|c: char| !c.is_digit(10) && c != '.')
            .unwrap_or(size_str.len()),
    );

    let num = num_str.parse::<f64>()?;
    let multiplier = match unit.trim() {
        "b" | "" => 1.0,
        "kb" | "k" => 1024.0,
        "mb" | "m" => 1024.0 * 1024.0,
        "gb" | "g" => 1024.0 * 1024.0 * 1024.0,
        _ => return Err(anyhow!("Invalid size unit: {}", unit)),
    };

    let target_size_bytes = (num * multiplier) as u64;

    match op {
        ">" => Ok(file_size > target_size_bytes),
        "<" => Ok(file_size < target_size_bytes),
        "=" => Ok(file_size == target_size_bytes),
        _ => Err(anyhow!("Invalid size operator: {}", op)),
    }
}

pub(super) fn parse_and_compare_time(modified_time: SystemTime, query: &str) -> Result<bool> {
    let now = SystemTime::now();
    let (op, time_str) = if query.starts_with(['>', '<', '=']) {
        query.split_at(1)
    } else {
        ("=", query)
    };
    let time_str = time_str.trim();

    let threshold_time = if let Ok(duration) = parse_relative_time(time_str) {
        now.checked_sub(duration)
            .ok_or_else(|| anyhow!("Time calculation underflow"))?
    } else if let Ok(datetime) = parse_absolute_time(time_str) {
        datetime
    } else {
        return Err(anyhow!("Invalid date format: '{}'", time_str));
    };

    match op {
        ">" => Ok(modified_time > threshold_time),
        "<" => Ok(modified_time < threshold_time),
        "=" => {
            // For date-only comparisons, check if the modified time is within the same day
            if time_str.len() == 10 {
                let modified_local = chrono::DateTime::<Local>::from(modified_time);
                let threshold_local = chrono::DateTime::<Local>::from(threshold_time);
                Ok(modified_local.date_naive() == threshold_local.date_naive())
            } else {
                Ok(modified_time == threshold_time)
            }
        }
        _ => Err(anyhow!("Invalid time operator: {}", op)),
    }
}

fn parse_relative_time(time_str: &str) -> Result<Duration> {
    let (num_str, unit) = time_str.split_at(
        time_str
            .find(|c: char| !c.is_digit(10))
            .unwrap_or(time_str.len()),
    );
    let num = num_str.parse::<u64>()?;
    let multiplier = match unit.trim() {
        "s" => 1,
        "m" => 60,
        "h" => 3600,
        "d" => 86400,
        "w" => 86400 * 7,
        "y" => 86400 * 365,
        _ => return Err(anyhow!("Invalid time unit")),
    };
    Ok(Duration::from_secs(num * multiplier))
}

fn parse_absolute_time(time_str: &str) -> Result<SystemTime> {
    let datetime = if let Ok(dt) = NaiveDateTime::parse_from_str(time_str, "%Y-%m-%d %H:%M:%S") {
        dt
    } else if let Ok(date) = NaiveDate::parse_from_str(time_str, "%Y-%m-%d") {
        date.and_time(NaiveTime::from_hms_opt(0, 0, 0).unwrap())
    } else {
        return Err(anyhow!("Invalid absolute date format"));
    };

    Ok(Local
        .from_local_datetime(&datetime)
        .single()
        .ok_or_else(|| anyhow!("Failed to convert to local time"))?
        .into())
}

---

File: ./rdump/src/predicates/in_path.rs
---
use anyhow::Result;
use globset::Glob;
use std::path::PathBuf;

use super::PredicateEvaluator;
use crate::evaluator::{FileContext, MatchResult};
use crate::parser::PredicateKey;

pub(super) struct InPathEvaluator;

impl PredicateEvaluator for InPathEvaluator {
    fn evaluate(
        &self,
        context: &mut FileContext,
        _key: &PredicateKey,
        value: &str,
    ) -> Result<MatchResult> {
        // Check for glob metacharacters to switch between logic paths.
        if value.contains('*') || value.contains('?') || value.contains('[') || value.contains('{')
        {
            // --- Wildcard Logic ---
            let glob = Glob::new(value)?.compile_matcher();

            if let Some(parent) = context.path.parent() {
                // Strip the root from the parent path to make the match relative.
                let relative_parent = parent.strip_prefix(&context.root).unwrap_or(parent);
                Ok(MatchResult::Boolean(glob.is_match(relative_parent)))
            } else {
                Ok(MatchResult::Boolean(false))
            }
        } else {
            // --- Existing Exact-Path Logic (for non-wildcard patterns) ---
            let target_dir = PathBuf::from(value);
            let absolute_target_dir = if target_dir.is_absolute() {
                target_dir
            } else {
                context.root.join(target_dir)
            };

            // If the target directory doesn't exist, it can't contain any files.
            if !absolute_target_dir.exists() {
                return Ok(MatchResult::Boolean(false));
            }

            // Canonicalize to resolve `.` or `..` for a reliable comparison.
            // On failure (e.g., broken symlink), we consider it a non-match rather than erroring out.
            let canonical_target = match dunce::canonicalize(&absolute_target_dir) {
                Ok(path) => path,
                Err(_) => return Ok(MatchResult::Boolean(false)),
            };
            let canonical_file_path = match dunce::canonicalize(&context.path) {
                Ok(path) => path,
                // This should not fail for a file that is being processed, but be robust.
                Err(_) => return Ok(MatchResult::Boolean(false)),
            };

            // `starts_with` handles the "is contained within" logic perfectly for exact paths.
            // e.g., a file in `/a/b/c` is also considered "in" `/a/b`.
            Ok(MatchResult::Boolean(
                canonical_file_path.starts_with(&canonical_target),
            ))
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs;
    use tempfile::tempdir;

    #[test]
    fn test_in_path_evaluator_exact() -> Result<()> {
        let evaluator = InPathEvaluator;

        // Create a temporary directory structure
        let root_dir = tempdir()?;
        let root_path = root_dir.path();

        let project_dir = root_path.join("project");
        let src_dir = project_dir.join("src");
        let other_project_dir = root_path.join("other_project");
        fs::create_dir_all(&src_dir)?;
        fs::create_dir_all(&other_project_dir)?;

        let main_rs_path = src_dir.join("main.rs");
        fs::write(&main_rs_path, "fn main() {}")?;

        // --- Test Cases ---

        let mut context = FileContext::new(main_rs_path.clone(), root_path.to_path_buf());

        // 1. Absolute Path: Exact parent directory
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::In, src_dir.to_str().unwrap())?
            .is_match());

        // 2. Absolute Path: Grandparent directory
        assert!(evaluator
            .evaluate(
                &mut context,
                &PredicateKey::In,
                project_dir.to_str().unwrap()
            )?
            .is_match());

        // 3. Absolute Path: Non-matching directory
        assert!(!evaluator
            .evaluate(
                &mut context,
                &PredicateKey::In,
                other_project_dir.to_str().unwrap()
            )?
            .is_match());

        // 4. Relative Path: from the root
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::In, "project/src")?
            .is_match());

        // 5. Relative Path: with dot-slash
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::In, "./project/src")?
            .is_match());

        // 6. Relative Path: non-matching
        assert!(!evaluator
            .evaluate(&mut context, &PredicateKey::In, "other_project")?
            .is_match());

        // 7. A file is considered to be "in" the directory represented by its own path
        assert!(evaluator
            .evaluate(
                &mut context,
                &PredicateKey::In,
                main_rs_path.to_str().unwrap()
            )?
            .is_match());

        // 8. Non-existent directory should not error, just return false
        assert!(!evaluator
            .evaluate(&mut context, &PredicateKey::In, "non_existent_dir")?
            .is_match());

        Ok(())
    }

    #[test]
    fn test_in_path_evaluator_wildcard() -> Result<()> {
        let evaluator = InPathEvaluator;

        // Create a temporary directory structure
        let root_dir = tempdir()?;
        let root_path = root_dir.path();

        let project_a_src = root_path.join("project_a").join("src");
        let project_b_source = root_path.join("project_b").join("source");
        let other_src = root_path.join("other").join("src");
        fs::create_dir_all(&project_a_src)?;
        fs::create_dir_all(&project_b_source)?;
        fs::create_dir_all(&other_src)?;

        let file_a = project_a_src.join("main.rs");
        fs::write(&file_a, "")?;
        let file_b = project_b_source.join("lib.rs");
        fs::write(&file_b, "")?;
        let file_c = other_src.join("component.js");
        fs::write(&file_c, "")?;

        let mut context_a = FileContext::new(file_a, root_path.to_path_buf());
        let mut context_b = FileContext::new(file_b, root_path.to_path_buf());
        let mut context_c = FileContext::new(file_c, root_path.to_path_buf());

        // --- Test Cases ---

        // 1. `**/src` should match files in any `src` directory
        assert!(evaluator
            .evaluate(&mut context_a, &PredicateKey::In, "**/src")?
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context_b, &PredicateKey::In, "**/src")?
            .is_match());
        assert!(evaluator
            .evaluate(&mut context_c, &PredicateKey::In, "**/src")?
            .is_match());

        // 2. `project_*/src` glob should match relative to the root.
        assert!(evaluator
            .evaluate(&mut context_a, &PredicateKey::In, "project_a/src")?
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context_b, &PredicateKey::In, "project_*/src")?
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context_c, &PredicateKey::In, "project_*/src")?
            .is_match());

        // 3. More specific glob `**/project_a/s?c`
        assert!(evaluator
            .evaluate(&mut context_a, &PredicateKey::In, "**/project_a/s?c")?
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context_b, &PredicateKey::In, "**/project_a/s?c")?
            .is_match());

        // 4. Glob that should not match anything
        assert!(!evaluator
            .evaluate(&mut context_a, &PredicateKey::In, "**/test")?
            .is_match());

        // 5. Glob matching a different directory `**/so*ce`
        assert!(!evaluator
            .evaluate(&mut context_a, &PredicateKey::In, "**/so*ce")?
            .is_match());
        assert!(evaluator
            .evaluate(&mut context_b, &PredicateKey::In, "**/so*ce")?
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context_c, &PredicateKey::In, "**/so*ce")?
            .is_match());

        Ok(())
    }

    #[test]
    fn test_in_path_evaluator_relative_wildcard() -> Result<()> {
        let evaluator = InPathEvaluator;

        // Create a temporary directory structure
        let root_dir = tempdir()?;
        let root_path = root_dir.path();

        let project_a_src = root_path.join("project_a").join("src");
        fs::create_dir_all(&project_a_src)?;

        let file_a = project_a_src.join("main.rs");
        fs::write(&file_a, "")?;

        // The context's root is the temporary directory we created.
        let mut context_a = FileContext::new(file_a, root_path.to_path_buf());

        // This glob is relative to the context's root.
        // It should match `.../project_a/src`
        assert!(evaluator
            .evaluate(&mut context_a, &PredicateKey::In, "project_a/*")?
            .is_match());

        // This glob should not match.
        assert!(!evaluator
            .evaluate(&mut context_a, &PredicateKey::In, "project_b/*")?
            .is_match());
            
        // This glob should also match.
        assert!(evaluator
            .evaluate(&mut context_a, &PredicateKey::In, "project_a/s?c")?
            .is_match());

        Ok(())
    }
}

---

File: ./rdump/src/predicates/matches.rs
---
use super::PredicateEvaluator;
use crate::evaluator::{FileContext, MatchResult};
use crate::parser::PredicateKey;
use anyhow::Result;
use regex::Regex;
use tree_sitter::Range;

pub(super) struct MatchesEvaluator;
impl PredicateEvaluator for MatchesEvaluator {
    fn evaluate(
        &self,
        context: &mut FileContext,
        _key: &PredicateKey,
        value: &str,
    ) -> Result<MatchResult> {
        let content = context.get_content()?;
        let re = Regex::new(value)?;

        let mut ranges = Vec::new();
        for (i, line) in content.lines().enumerate() {
            if re.is_match(line) {
                let start_byte = content.lines().take(i).map(|l| l.len() + 1).sum();
                let end_byte = start_byte + line.len();
                ranges.push(Range {
                    start_byte,
                    end_byte,
                    start_point: tree_sitter::Point { row: i, column: 0 },
                    end_point: tree_sitter::Point {
                        row: i,
                        column: line.len(),
                    },
                });
            }
        }
        Ok(MatchResult::Hunks(ranges))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::io::Write;
    use std::path::PathBuf;
    use tempfile::NamedTempFile;

    fn create_temp_file(content: &str) -> NamedTempFile {
        let mut file = NamedTempFile::new().unwrap();
        write!(file, "{}", content).unwrap();
        file
    }

    #[test]
    fn test_matches_evaluator() {
        let file = create_temp_file("version = \"0.1.0\"\nauthor = \"test\"");
        let mut context = FileContext::new(file.path().to_path_buf(), PathBuf::from("/"));
        let evaluator = MatchesEvaluator;
        // Simple regex
        assert!(evaluator
            .evaluate(
                &mut context,
                &PredicateKey::Matches,
                r#"version = "[0-9]+\.[0-9]+\.[0-9]+""#
            )
            .unwrap()
            .is_match());
        // Test regex that finds a line
        assert!(evaluator
            .evaluate(
                &mut context,
                &PredicateKey::Matches,
                r#"author = "test""#
            )
            .unwrap()
            .is_match());
        assert!(!evaluator
            .evaluate(
                &mut context,
                &PredicateKey::Matches,
                r#"^version = "1.0.0"$"#
            )
            .unwrap()
            .is_match());
    }
}

---

File: ./rdump/src/predicates/mod.rs
---
pub mod code_aware;
pub mod contains;
pub mod ext;
mod helpers;
pub mod in_path;
pub mod matches;
pub mod modified;
pub mod name;
pub mod path;
pub mod size;

use self::code_aware::CodeAwareEvaluator;
use self::contains::ContainsEvaluator;
use self::ext::ExtEvaluator;
use self::in_path::InPathEvaluator;
use self::matches::MatchesEvaluator;
use self::modified::ModifiedEvaluator;
use self::name::NameEvaluator;
use self::path::PathEvaluator;
use self::size::SizeEvaluator;
use crate::evaluator::{FileContext, MatchResult};
use crate::parser::PredicateKey;
use anyhow::Result;
use std::collections::HashMap;

// The core trait that all predicate evaluators must implement.
pub trait PredicateEvaluator {
    // The key is now passed to allow one evaluator to handle multiple predicate types.
    fn evaluate(
        &self,
        context: &mut FileContext,
        key: &PredicateKey,
        value: &str,
    ) -> Result<MatchResult>;
}

/// Creates a predicate registry with only the fast, metadata-based predicates.
/// This is used for the pre-filtering pass.
pub fn create_metadata_predicate_registry(
) -> HashMap<PredicateKey, Box<dyn PredicateEvaluator + Send + Sync>> {
    let mut registry: HashMap<PredicateKey, Box<dyn PredicateEvaluator + Send + Sync>> =
        HashMap::new();

    registry.insert(PredicateKey::Ext, Box::new(ExtEvaluator));
    registry.insert(PredicateKey::Name, Box::new(NameEvaluator));
    registry.insert(PredicateKey::Path, Box::new(PathEvaluator));
    registry.insert(PredicateKey::In, Box::new(InPathEvaluator));
    registry.insert(PredicateKey::Size, Box::new(SizeEvaluator));
    registry.insert(PredicateKey::Modified, Box::new(ModifiedEvaluator));

    registry
}

/// Creates and populates the complete predicate registry.
pub fn create_predicate_registry(
) -> HashMap<PredicateKey, Box<dyn PredicateEvaluator + Send + Sync>> {
    // Start with the metadata predicates
    let mut registry = create_metadata_predicate_registry();

    // Add content-based predicates
    registry.insert(PredicateKey::Contains, Box::new(ContainsEvaluator));
    registry.insert(PredicateKey::Matches, Box::new(MatchesEvaluator));

    // Register the single CodeAwareEvaluator for all semantic predicate keys.
    let code_evaluator = Box::new(CodeAwareEvaluator);
    registry.insert(PredicateKey::Def, code_evaluator.clone());
    registry.insert(PredicateKey::Func, code_evaluator.clone());
    registry.insert(PredicateKey::Import, code_evaluator.clone());
    registry.insert(PredicateKey::Class, code_evaluator.clone());
    registry.insert(PredicateKey::Struct, code_evaluator.clone());
    registry.insert(PredicateKey::Enum, code_evaluator.clone());
    registry.insert(PredicateKey::Interface, code_evaluator.clone());
    registry.insert(PredicateKey::Trait, code_evaluator.clone());
    registry.insert(PredicateKey::Type, code_evaluator.clone());
    registry.insert(PredicateKey::Comment, code_evaluator.clone());
    registry.insert(PredicateKey::Str, code_evaluator.clone());
    registry.insert(PredicateKey::Call, code_evaluator);

    registry
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::io::Write;

    // The `code_aware` suite remains here as it tests the interaction
    // of multiple profiles, which is a responsibility of this parent module.
    #[test]
    fn test_code_aware_evaluator_full_rust_suite() {
        let rust_code = r#"
            // TODO: refactor this module
            use std::collections::HashMap;

            type ConfigMap = HashMap<String, String>;

            pub struct AppConfig {}
            pub trait Runnable {
                fn run(&self);
            }
            fn launch_app() {
                let msg = "Launching...";
                println!("{}", msg);
            }
        "#;

        let temp_dir = tempfile::tempdir().unwrap();
        let file_path = temp_dir.path().join("complex.rs");
        let mut file = std::fs::File::create(&file_path).unwrap();
        file.write_all(rust_code.as_bytes()).unwrap();

        let evaluator = CodeAwareEvaluator;

        // --- Granular Defs ---
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Struct, "AppConfig")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Trait, "Runnable")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Type, "ConfigMap")
            .unwrap()
            .is_match());

        // --- Functions ---
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Func, "run")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Func, "launch_app")
            .unwrap()
            .is_match());

        // --- Calls ---
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(
            evaluator
                .evaluate(&mut ctx, &PredicateKey::Call, "println")
                .unwrap()
                .is_match(),
            "Should find function call"
        );
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(
            !evaluator
                .evaluate(&mut ctx, &PredicateKey::Call, "launch_app")
                .unwrap()
                .is_match(),
            "Should not find the definition as a call"
        );

        // --- Syntactic Content ---
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Comment, "TODO")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Str, "Launching...")
            .unwrap()
            .is_match());
    }

    #[test]
    fn test_code_aware_evaluator_python_suite() {
        let python_code = r#"
# FIXME: use a real database
import os

class DataProcessor:
    def __init__(self):
        self.api_key = "secret_key"
        self.connect()

    def connect(self):
        print("Connecting...")

def process_data():
    proc = DataProcessor()
    print("Processing")
        "#;

        let temp_dir = tempfile::tempdir().unwrap();
        let file_path = temp_dir.path().join("script.py");
        let mut file = std::fs::File::create(&file_path).unwrap();
        file.write_all(python_code.as_bytes()).unwrap();

        let evaluator = CodeAwareEvaluator;

        // --- Granular Defs ---
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Class, "DataProcessor")
            .unwrap()
            .is_match());

        // --- Functions ---
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Func, "process_data")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Func, "connect")
            .unwrap()
            .is_match());

        // --- Calls ---
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(
            evaluator
                .evaluate(&mut ctx, &PredicateKey::Call, "print")
                .unwrap()
                .is_match(),
            "Should find multiple calls to print"
        );
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(
            evaluator
                .evaluate(&mut ctx, &PredicateKey::Call, "DataProcessor")
                .unwrap()
                .is_match(),
            "Should find constructor call"
        );
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(
            evaluator
                .evaluate(&mut ctx, &PredicateKey::Call, "connect")
                .unwrap()
                .is_match(),
            "Should find method call"
        );

        // --- Syntactic Content ---
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Comment, "FIXME")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Str, "secret_key")
            .unwrap()
            .is_match());
    }

    #[test]
    fn test_code_aware_evaluator_javascript_suite() {
        let js_code = r#"
            import { open } from 'fs/promises';

            class Logger {
                log(message) { console.log(message); }
            }

            function a() {
                const l = new Logger();
                l.log("hello");
            }
        "#;

        let temp_dir = tempfile::tempdir().unwrap();
        let file_path = temp_dir.path().join("script.js");
        let mut file = std::fs::File::create(&file_path).unwrap();
        file.write_all(js_code.as_bytes()).unwrap();

        let evaluator = CodeAwareEvaluator;

        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Def, "Logger")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Func, "log")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Import, "fs/promises")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(
            evaluator
                .evaluate(&mut ctx, &PredicateKey::Call, "Logger")
                .unwrap()
                .is_match(),
            "Should find constructor call"
        );
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(
            evaluator
                .evaluate(&mut ctx, &PredicateKey::Call, "log")
                .unwrap()
                .is_match(),
            "Should find method call"
        );
    }

    #[test]
    fn test_code_aware_evaluator_typescript_suite() {
        let ts_code = r#"
            import React from 'react';

            interface User { id: number; }
            type ID = string | number;

            class ApiClient {
                // The URL for the API
                private url = "https://api.example.com";
                fetchUser(): User | null { return null; }
            }

            const client = new ApiClient();
            client.fetchUser();
        "#;

        let temp_dir = tempfile::tempdir().unwrap();
        let file_path = temp_dir.path().join("api.ts");
        let mut file = std::fs::File::create(&file_path).unwrap();
        file.write_all(ts_code.as_bytes()).unwrap();

        let evaluator = CodeAwareEvaluator;

        // --- Granular Defs ---
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(
            evaluator
                .evaluate(&mut ctx, &PredicateKey::Def, "ApiClient")
                .unwrap()
                .is_match(),
            "Should find class"
        );
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Func, "fetchUser")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Import, "React")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(
            evaluator
                .evaluate(&mut ctx, &PredicateKey::Call, "ApiClient")
                .unwrap()
                .is_match(),
            "Should find TS constructor call"
        );
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(
            evaluator
                .evaluate(&mut ctx, &PredicateKey::Call, "fetchUser")
                .unwrap()
                .is_match(),
            "Should find TS method call"
        );

        // --- Syntactic Content ---
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Comment, "The URL")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Str, "https://api.example.com")
            .unwrap()
            .is_match());
    }

    #[test]
    fn test_code_aware_evaluator_go_suite() {
        let go_code = r#"
           package main

           import "fmt"

           // User represents a user
           type User struct {
               ID int
           }

           func (u *User) Greet() {
               fmt.Println("Hello")
           }

           func main() {
               user := User{ID: 1}
               user.Greet()
           }
       "#;

        let temp_dir = tempfile::tempdir().unwrap();
        let file_path = temp_dir.path().join("main.go");
        let mut file = std::fs::File::create(&file_path).unwrap();
        file.write_all(go_code.as_bytes()).unwrap();

        let evaluator = CodeAwareEvaluator;

        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Struct, "User")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Func, "Greet")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Call, "Println")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Import, "fmt")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Comment, "represents a user")
            .unwrap()
            .is_match());
    }

    #[test]
    fn test_code_aware_evaluator_java_suite() {
        let java_code = r#"
           package com.example;

           import java.util.List;

           // Represents a user
           public class User {
               public User() {
                   System.out.println("User created");
               }

               public void greet() {}
           }
       "#;

        let temp_dir = tempfile::tempdir().unwrap();
        let file_path = temp_dir.path().join("User.java");
        let mut file = std::fs::File::create(&file_path).unwrap();
        file.write_all(java_code.as_bytes()).unwrap();

        let evaluator = CodeAwareEvaluator;

        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Class, "User")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Func, "greet")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Call, "println")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Import, "java.util.List")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Comment, "Represents a user")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone(), file_path.parent().unwrap().to_path_buf());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Str, "User created")
            .unwrap()
            .is_match());
    }
}

---

File: ./rdump/src/predicates/modified.rs
---
use super::{helpers, PredicateEvaluator};
use crate::evaluator::{FileContext, MatchResult};
use crate::parser::PredicateKey;
use anyhow::Result;

pub(super) struct ModifiedEvaluator;
impl PredicateEvaluator for ModifiedEvaluator {
    fn evaluate(
        &self,
        context: &mut FileContext,
        _key: &PredicateKey,
        value: &str,
    ) -> Result<MatchResult> {
        let metadata = context.path.metadata()?;
        let modified_time = metadata.modified()?;
        Ok(MatchResult::Boolean(helpers::parse_and_compare_time(
            modified_time,
            value,
        )?))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::io::Write;
    use std::path::PathBuf;
    use tempfile::NamedTempFile;

    fn create_temp_file(content: &str) -> NamedTempFile {
        let mut file = NamedTempFile::new().unwrap();
        write!(file, "{}", content).unwrap();
        file
    }

    #[test]
    fn test_modified_evaluator() {
        let file = create_temp_file("content");
        let mut context = FileContext::new(file.path().to_path_buf(), PathBuf::from("/"));

        let evaluator = ModifiedEvaluator;
        // File was just created
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Modified, ">1m")
            .unwrap()
            .is_match()); // Modified more recently than 1 min ago
        assert!(!evaluator
            .evaluate(&mut context, &PredicateKey::Modified, "<1m")
            .unwrap()
            .is_match()); // Not modified longer than 1 min ago
    }
}

---

File: ./rdump/src/predicates/name.rs
---
use super::PredicateEvaluator;
use crate::evaluator::{FileContext, MatchResult};
use crate::parser::PredicateKey;
use anyhow::Result;
use glob::{MatchOptions, Pattern};

pub(super) struct NameEvaluator;
impl PredicateEvaluator for NameEvaluator {
    fn evaluate(
        &self,
        context: &mut FileContext,
        _key: &PredicateKey,
        value: &str,
    ) -> Result<MatchResult> {
        let file_name = context
            .path
            .file_name()
            .and_then(|s| s.to_str())
            .unwrap_or("");
        let options = MatchOptions {
            case_sensitive: false,
            ..Default::default()
        };
        let pattern = Pattern::new(value)?;
        Ok(MatchResult::Boolean(
            pattern.matches_with(file_name, options),
        ))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::path::PathBuf;

    #[test]
    fn test_name_evaluator() {
        let mut context1 = FileContext::new(PathBuf::from("/home/user/Cargo.toml"), PathBuf::from("/"));
        let mut context2 = FileContext::new(PathBuf::from("/home/user/main.rs"), PathBuf::from("/"));

        let evaluator = NameEvaluator;
        assert!(evaluator
            .evaluate(&mut context1, &PredicateKey::Name, "Cargo.toml")
            .unwrap()
            .is_match());
        assert!(
            evaluator
                .evaluate(&mut context1, &PredicateKey::Name, "C*.toml")
                .unwrap()
                .is_match(),
            "Glob pattern should match"
        );
        assert!(
            evaluator
                .evaluate(&mut context2, &PredicateKey::Name, "*.rs")
                .unwrap()
                .is_match(),
            "Glob pattern should match"
        );
        assert!(!evaluator
            .evaluate(&mut context1, &PredicateKey::Name, "*.rs")
            .unwrap()
            .is_match());
    }

    #[test]
    fn test_name_evaluator_case_insensitive() {
        let mut context =
            FileContext::new(PathBuf::from("/home/user/MyFile.txt"), PathBuf::from("/"));
        let evaluator = NameEvaluator;
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Name, "myfile.txt")
            .unwrap()
            .is_match());
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Name, "MYFILE.TXT")
            .unwrap()
            .is_match());
    }
}

---

File: ./rdump/src/predicates/path.rs
---
use super::PredicateEvaluator;
use crate::evaluator::{FileContext, MatchResult};
use crate::parser::PredicateKey;
use anyhow::Result;
use regex::Regex;

pub(super) struct PathEvaluator;

impl PredicateEvaluator for PathEvaluator {
    fn evaluate(
        &self,
        context: &mut FileContext,
        _key: &PredicateKey,
        value: &str,
    ) -> Result<MatchResult> {
        let path_str = context.path.to_string_lossy();

        if value.contains('*') || value.contains('?') || value.contains('[') || value.contains('{')
        {
            // Convert glob-style pattern to a regex
            let regex_str = value
                .replace('.', "\\.")
                .replace('*', ".*")
                .replace('?', ".");
            let regex = Regex::new(&regex_str)?;
            Ok(MatchResult::Boolean(regex.is_match(&path_str)))
        } else {
            // Fallback to simple substring search for non-glob patterns
            Ok(MatchResult::Boolean(path_str.contains(value)))
        }
    }
}


#[cfg(test)]
mod tests {
    use super::*;
    use std::path::PathBuf;

    #[test]
    fn test_path_evaluator_contains() {
        let mut context = FileContext::new(
            PathBuf::from("/home/user/project/src/main.rs"),
            PathBuf::from("/"),
        );
        let evaluator = PathEvaluator;
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Path, "project/src")
            .unwrap()
            .is_match());
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Path, "/home/user")
            .unwrap()
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context, &PredicateKey::Path, "project/lib")
            .unwrap()
            .is_match());
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Path, "main.rs")
            .unwrap()
            .is_match());
    }

    #[test]
    fn test_path_evaluator_wildcard() {
        let mut context = FileContext::new(
            PathBuf::from("/home/user/project/src/main.rs"),
            PathBuf::from("/"),
        );
        let evaluator = PathEvaluator;

        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Path, "project/src/*")
            .unwrap()
            .is_match());
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Path, "project/*/main.rs")
            .unwrap()
            .is_match());
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Path, "*.rs")
            .unwrap()
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context, &PredicateKey::Path, "*.ts")
            .unwrap()
            .is_match());
    }

    #[test]
    fn test_empty_path_query() {
        let mut context = FileContext::new(
            PathBuf::from("/home/user/project/src/main.rs"),
            PathBuf::from("/"),
        );
        let evaluator = PathEvaluator;

        // Empty string should match everything with `contains`
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Path, "")
            .unwrap()
            .is_match());
    }
}

---

File: ./rdump/src/predicates/size.rs
---
use super::{helpers, PredicateEvaluator};
use crate::evaluator::{FileContext, MatchResult};
use crate::parser::PredicateKey;
use anyhow::Result;

pub(super) struct SizeEvaluator;
impl PredicateEvaluator for SizeEvaluator {
    fn evaluate(
        &self,
        context: &mut FileContext,
        _key: &PredicateKey,
        value: &str,
    ) -> Result<MatchResult> {
        let metadata = context.path.metadata()?;
        let file_size = metadata.len();
        Ok(MatchResult::Boolean(helpers::parse_and_compare_size(
            file_size, value,
        )?))
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs::File;
    use std::io::Write;
    use std::path::PathBuf;
    use tempfile::tempdir;

    #[test]
    fn test_size_evaluator_valid_comparisons() -> Result<()> {
        let dir = tempdir()?;
        let file_path = dir.path().join("file_1kb");
        let mut file = File::create(&file_path)?;
        file.write_all(&[0; 1024])?;

        let mut context = FileContext::new(file_path, PathBuf::from("/"));
        let evaluator = SizeEvaluator;

        // Exact match
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Size, "=1kb")?
            .is_match());
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Size, "=1024")?
            .is_match());

        // Greater than
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Size, ">1000")?
            .is_match());
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Size, ">0.9kb")?
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context, &PredicateKey::Size, ">2kb")?
            .is_match());

        // Less than
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Size, "<2kb")?
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context, &PredicateKey::Size, "<1kb")?
            .is_match());

        Ok(())
    }

    #[test]
    fn test_size_evaluator_empty_file() -> Result<()> {
        let dir = tempdir()?;
        let file_path = dir.path().join("empty_file");
        File::create(&file_path)?;

        let mut context = FileContext::new(file_path, PathBuf::from("/"));
        let evaluator = SizeEvaluator;

        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Size, "=0")?
            .is_match());
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Size, "<1")?
            .is_match());
        assert!(!evaluator
            .evaluate(&mut context, &PredicateKey::Size, ">0")?
            .is_match());

        Ok(())
    }

    #[test]
    fn test_size_evaluator_invalid_input() -> Result<()> {
        let dir = tempdir()?;
        let file_path = dir.path().join("any_file");
        File::create(&file_path)?;
        let mut context = FileContext::new(file_path, PathBuf::from("/"));
        let evaluator = SizeEvaluator;

        // Invalid number
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Size, ">abc")
            .is_err());

        // Invalid operator
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Size, "?123")
            .is_err());
            
        // Missing value
        assert!(evaluator
            .evaluate(&mut context, &PredicateKey::Size, ">")
            .is_err());

        Ok(())
    }
}

---

File: ./rdump/src/rql.pest
---
// rdump Query Language (RQL) Grammar
// This file defines the syntax for rdump queries using the Pest parser generator.
// The grammar is defined in a top-down manner, from the highest-level rule (query)
// to the lowest-level tokens (operators, identifiers, etc.).

// --- Top-Level Rule ---
// A query must start at the beginning of the input (SOI), contain a single
// expression, and end at the end of the input (EOI). This ensures the entire
// input string is parsed.
query = { SOI ~ expression ~ EOI }

// --- Expression and Operator Precedence ---
// An expression is a series of terms connected by logical operators.
// The grammar enforces standard logical precedence: NOT > AND > OR.
expression = { logical_or }

// `logical_or` has the lowest precedence. It's a series of `logical_and`
// terms separated by the OR operator.
logical_or = { logical_and ~ (OR ~ logical_and)* }

// `logical_and` has higher precedence than OR. It's a series of `term`s
// separated by the AND operator.
logical_and = { term ~ (AND ~ term)* }

// --- Terms and Factors ---
// A `term` is the basic building block of an expression. It can be a simple
// factor or a factor negated with NOT. The NOT operator has the highest precedence.
term = { NOT? ~ factor }

// A `factor` can be a single predicate or a grouped expression in parentheses.
// Parentheses are used to override the default operator precedence.
factor = { predicate | "(" ~ expression ~ ")" }

// --- Predicates and Values ---
// A `predicate` is the core of the query, representing a key-value filter.
// It consists of an identifier (the key), a colon, and a value.
predicate = { identifier ~ ":" ~ value }

// An `identifier` is the key for a predicate (e.g., "ext", "name", "contains").
// It must consist of one or more alphanumeric characters.
identifier = @{ ASCII_ALPHANUMERIC+ }

// A `value` can be either quoted or unquoted.
value = { quoted_value | unquoted_value }

// An `unquoted_value` is a sequence of characters that are not special operators
// or whitespace. This allows for simple values without requiring quotes.
// It can include comparison operators and time/size units (e.g., ">10kb").
unquoted_value = @{ (!(" " | "\t" | "\n" | "\r" | "(" | ")") ~ ANY)+ }

// A `quoted_value` allows for values containing spaces or special characters.
// It supports both single and double quotes, and allows escaping the respective
// quote character with a backslash.
quoted_value = { single_quoted | double_quoted }
single_quoted = @{ "'" ~ (("\\'" | !"'") ~ ANY)* ~ "'" }
double_quoted = @{ "\"" ~ (("\\\"" | !"\"") ~ ANY)* ~ "\"" }

// --- Operators and Whitespace ---
// Logical operators can be symbols or case-insensitive keywords.
AND = { "&" | ("a" | "A") ~ ("n" | "N") ~ ("d" | "D") }
OR = { "|" | ("o" | "O") ~ ("r" | "R") }
NOT = { "!" | ("n" | "N") ~ ("o" | "O") ~ ("t" | "T") }

// `WHITESPACE` is defined to be ignored between other tokens, making the
// query format more flexible.
WHITESPACE = _{ " " | "\t" | "\n" | "\r" }

---

File: ./rdump/tests/cli.rs
---
// In rdump/tests/cli.rs

use assert_cmd::prelude::*; // Adds methods on commands
use predicates::prelude::*; // Used for writing assertions
use std::fs;
use std::io::Write;
use std::process::Command; // Lets us run other programs
use tempfile::tempdir; // Create temporary directories for testing

// --- Helper Functions ---

/// A helper to set up a temporary directory with a predictable file structure for tests.
/// Returns the TempDir object (which cleans up the directory when it's dropped)
/// and the PathBuf of the root, for convenience.
fn setup_test_dir() -> (tempfile::TempDir, std::path::PathBuf) {
    let dir = tempdir().unwrap();
    let root = dir.path().to_path_buf();

    // Create a file to be found
    fs::File::create(root.join("main.rs"))
        .unwrap()
        .write_all(b"fn main() {\n    println!(\"Hello\");\n}")
        .unwrap();

    // Create a file that shouldn't be found by most queries
    fs::File::create(root.join("other.txt"))
        .unwrap()
        .write_all(b"some text")
        .unwrap();

    (dir, root)
}

// --- Test Implementation ---

#[test]
fn test_help_message() -> Result<(), Box<dyn std::error::Error>> {
    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.arg("--help");
    cmd.assert()
        .success()
        .stdout(predicate::str::contains(
            "A fast, expressive, code-aware tool",
        ))
        .stdout(predicate::str::contains("Usage: rdump <COMMAND>"))
        .stdout(predicate::str::contains("Commands:\n  search"))
        .stdout(predicate::str::contains("  preset"))
        .stdout(predicate::str::contains("Options:\n  -h, --help"))
        .stdout(predicate::str::contains("  -V, --version"));
    Ok(())
}

#[test]
fn test_version_message() -> Result<(), Box<dyn std::error::Error>> {
    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.arg("--version");
    cmd.assert()
        .success()
        .stdout(predicate::str::contains("rdump 0.1.0")); // Assumes version in Cargo.toml
    Ok(())
}

#[test]
fn test_no_args_fails() -> Result<(), Box<dyn std::error::Error>> {
    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.assert()
        .failure() // Should fail because a subcommand is required
        .stderr(predicate::str::contains("Usage: rdump <COMMAND>"));
    Ok(())
}

#[test]
fn test_search_simple_predicate_succeeds() -> Result<(), Box<dyn std::error::Error>> {
    // Setup a temporary directory with our test files
    let (_dir, root) = setup_test_dir();

    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root); // Run the command *from* our test directory
    cmd.arg("search").arg("ext:rs");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("File: ./main.rs"))
        .stdout(predicate::str::contains("fn main()"))
        .stdout(predicate::str::contains("---").count(1))
        .stdout(predicate::str::contains("other.txt").not());
    Ok(())
}

#[test]
fn test_search_no_results() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_test_dir();

    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root);
    cmd.arg("search").arg("ext:java"); // No java files exist

    cmd.assert().success().stdout(predicate::str::is_empty()); // Nothing should be printed
    Ok(())
}

#[test]
fn test_search_invalid_query_fails() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_test_dir();

    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root);
    cmd.arg("search").arg("ext:"); // Query with a missing value

    cmd.assert()
        .failure()
        .stdout(predicate::str::is_empty())
        .stderr(predicate::str::contains("expected value"));
    Ok(())
}

// Add this new helper function to rdump/tests/cli.rs

/// Sets up a more complex directory for testing discovery and formatting.
fn setup_advanced_test_dir() -> (tempfile::TempDir, std::path::PathBuf) {
    let dir = tempdir().unwrap();
    let root = dir.path().to_path_buf();

    // Top-level files
    fs::File::create(root.join("main.rs"))
        .unwrap()
        .write_all(b"fn main() {}")
        .unwrap();
    fs::File::create(root.join(".hidden_config"))
        .unwrap()
        .write_all(b"secret=true")
        .unwrap();

    // Subdirectory with a file
    fs::create_dir(root.join("src")).unwrap();
    fs::File::create(root.join("src/lib.rs"))
        .unwrap()
        .write_all(b"// a library")
        .unwrap();

    // Directory and file to be ignored
    fs::create_dir(root.join("logs")).unwrap();
    fs::File::create(root.join("logs/latest.log"))
        .unwrap()
        .write_all(b"INFO: started")
        .unwrap();

    // .gitignore file to ignore the logs
    let mut gitignore = fs::File::create(root.join(".gitignore")).unwrap();
    writeln!(gitignore, "*.log").unwrap();

    (dir, root)
}

// Add these new tests to the end of rdump/tests/cli.rs

#[test]
fn test_file_discovery_flags() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_advanced_test_dir();

    // Test --hidden flag
    let mut cmd_hidden = Command::cargo_bin("rdump")?;
    cmd_hidden.current_dir(&root);
    cmd_hidden.arg("search").arg("--hidden").arg("path:hidden");
    cmd_hidden
        .assert()
        .success()
        .stdout(predicate::str::contains(".hidden_config"));

    // Test --no-ignore flag
    let mut cmd_no_ignore = Command::cargo_bin("rdump")?;
    cmd_no_ignore.current_dir(&root);
    cmd_no_ignore
        .arg("search")
        .arg("--no-ignore")
        .arg("ext:log");
    cmd_no_ignore
        .assert()
        .success()
        .stdout(predicate::str::contains("latest.log"));

    // Test --max-depth flag
    let mut cmd_depth = Command::cargo_bin("rdump")?;
    cmd_depth.current_dir(&root);
    // This should find `main.rs` but not `src/lib.rs`
    cmd_depth
        .arg("search")
        .arg("--max-depth")
        .arg("1")
        .arg("ext:rs");
    cmd_depth
        .assert()
        .success()
        .stdout(predicate::str::contains("main.rs"))
        .stdout(predicate::str::contains("src/lib.rs").not());

    Ok(())
}

#[test]
fn test_output_formatting_flags() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_advanced_test_dir();

    // Test --format paths
    let mut cmd_paths = Command::cargo_bin("rdump")?;
    cmd_paths.current_dir(&root);
    cmd_paths
        .arg("search")
        .arg("--format")
        .arg("paths")
        .arg("ext:rs");
    // Should contain ONLY the paths, sorted. The extra newline is important.
    let expected_paths = "./main.rs\n./src/lib.rs\n";
    cmd_paths.assert().success().stdout(expected_paths);

    // Test --format json
    let mut cmd_json = Command::cargo_bin("rdump")?;
    cmd_json.current_dir(&root);
    cmd_json
        .arg("search")
        .arg("--format")
        .arg("json")
        .arg("path:main.rs");
    // Assert it contains the key parts of a valid JSON output
    cmd_json
        .assert()
        .success()
        .stdout(predicate::str::contains(r#""path": "./main.rs""#))
        .stdout(predicate::str::contains(r#""content": "fn main() {}""#));

    // Test --format cat with --line-numbers (no color, since it's a pipe)
    let mut cmd_cat = Command::cargo_bin("rdump")?;
    cmd_cat.current_dir(&root);
    cmd_cat
        .arg("search")
        .arg("--format")
        .arg("cat")
        .arg("--line-numbers")
        .arg("path:main.rs");
    cmd_cat
        .assert()
        .success()
        .stdout(predicate::str::contains("1 | fn main() {}"))
        .stdout(predicate::str::contains("\x1b[").not()); // Check for NO ANSI color codes

    // Test --color=always to force highlighting
    let mut cmd_color = Command::cargo_bin("rdump")?;
    cmd_color.current_dir(&root);
    cmd_color
        .arg("search")
        .arg("--color=always")
        .arg("path:main.rs");
    cmd_color
        .assert()
        .success()
        .stdout(predicate::str::contains("\x1b[")); // Check FOR ANSI color codes

    // Test --find shorthand flag
    let mut cmd_find = Command::cargo_bin("rdump")?;
    cmd_find.current_dir(&root);
    cmd_find.arg("search").arg("--find").arg("path:main.rs");
    // We can't know the exact permissions/date, but we can check for the structure
    cmd_find
        .assert()
        .success()
        .stdout(predicate::str::contains("main.rs")) // The path
        .stdout(predicate::str::contains("12")); // The size (fn main() {} is 12 bytes)

    Ok(())
}

/// Sets up an environment for testing presets, with a fake home and project directory.
fn setup_preset_test_env() -> (tempfile::TempDir, std::path::PathBuf, std::path::PathBuf) {
    let dir = tempdir().unwrap();
    let fake_home = dir.path().join("home");
    fs::create_dir(&fake_home).unwrap();
    let project_dir = dir.path().join("project");
    fs::create_dir(&project_dir).unwrap();

    // Create a file in the project directory to be found by searches
    fs::File::create(project_dir.join("main.rs"))
        .unwrap()
        .write_all(b"fn main() {}")
        .unwrap();
    fs::File::create(project_dir.join("main.toml"))
        .unwrap()
        .write_all(b"[package]")
        .unwrap();

    (dir, fake_home, project_dir)
}

// Add these new tests to the end of rdump/tests/cli.rs

#[test]
fn test_preset_lifecycle() -> Result<(), Box<dyn std::error::Error>> {
    // We get a clean home directory AND a clean project directory
    let (_dir, fake_home, project_dir) = setup_preset_test_env();
    let config_path = fake_home.join("rdump/config.toml");

    // 1. List when no presets exist.
    // CRITICAL FIX: Run this command from the clean project_dir.
    let mut cmd_list1 = Command::cargo_bin("rdump")?;
    cmd_list1.env("RDUMP_TEST_CONFIG_DIR", &fake_home);
    cmd_list1.current_dir(&project_dir); // <--- THIS IS THE FIX
    cmd_list1.arg("preset").arg("list");
    cmd_list1
        .assert()
        .success()
        .stdout(predicate::str::contains("No presets found."));

    // 2. Add a preset. This command is not affected by current_dir, but it's good practice.
    let mut cmd_add = Command::cargo_bin("rdump")?;
    cmd_add.env("RDUMP_TEST_CONFIG_DIR", &fake_home);
    cmd_add.current_dir(&project_dir); // Add for consistency
    cmd_add
        .arg("preset")
        .arg("add")
        .arg("rust-files")
        .arg("ext:rs");
    cmd_add.assert().success();

    // Verify the file content directly
    assert!(config_path.exists());
    let content = fs::read_to_string(&config_path)?;
    assert!(content.contains(r#"rust-files = "ext:rs""#));

    // 3. List again to see the new preset.
    let mut cmd_list2 = Command::cargo_bin("rdump")?;
    cmd_list2.env("RDUMP_TEST_CONFIG_DIR", &fake_home);
    cmd_list2.current_dir(&project_dir); // Add for consistency
    cmd_list2.arg("preset").arg("list");
    cmd_list2
        .assert()
        .success()
        .stdout(predicate::str::contains("rust-files : ext:rs"));

    // 4. Remove the preset.
    let mut cmd_remove = Command::cargo_bin("rdump")?;
    cmd_remove.env("RDUMP_TEST_CONFIG_DIR", &fake_home);
    cmd_remove.current_dir(&project_dir); // Add for consistency
    cmd_remove.arg("preset").arg("remove").arg("rust-files");
    cmd_remove.assert().success();

    // Verify the file content has changed
    let content_after_remove = fs::read_to_string(&config_path)?;
    assert!(!content_after_remove.contains("rust-files"));

    Ok(())
}

#[test]
fn test_search_and_preset_interaction() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, fake_home, project_dir) = setup_preset_test_env();

    // 1. Setup: Create presets
    let preset_content = r#"
[presets]
rust = "ext:rs"
config = "ext:toml"
"#;
    let config_dir = fake_home.join("rdump");
    fs::create_dir_all(&config_dir)?;
    fs::write(config_dir.join("config.toml"), preset_content)?;

    // 2. Test search with one preset
    let mut cmd_search1 = Command::cargo_bin("rdump")?;
    cmd_search1.env("RDUMP_TEST_CONFIG_DIR", &fake_home);
    cmd_search1.current_dir(&project_dir);
    cmd_search1.arg("search").arg("-p").arg("rust");
    cmd_search1
        .assert()
        .success()
        .stdout(predicate::str::contains("main.rs"))
        .stdout(predicate::str::contains("main.toml").not());

    // 3. Test search with a preset AND a query
    // Should evaluate to `(ext:rs) & contains:main`
    let mut cmd_search2 = Command::cargo_bin("rdump")?;
    cmd_search2.env("RDUMP_TEST_CONFIG_DIR", &fake_home);
    cmd_search2.current_dir(&project_dir);
    cmd_search2
        .arg("search")
        .arg("-p")
        .arg("rust")
        .arg("contains:main");
    cmd_search2
        .assert()
        .success()
        .stdout(predicate::str::contains("main.rs"));

    // 4. Test search with multiple presets
    // Should evaluate to `(ext:toml) & (ext:rs)` -> no results
    let mut cmd_search3 = Command::cargo_bin("rdump")?;
    cmd_search3.env("RDUMP_TEST_CONFIG_DIR", &fake_home);
    cmd_search3.current_dir(&project_dir);
    cmd_search3
        .arg("search")
        .arg("-p")
        .arg("rust")
        .arg("-p")
        .arg("config");
    cmd_search3
        .assert()
        .success()
        .stdout(predicate::str::is_empty());

    Ok(())
}

#[test]
fn test_local_config_override() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, fake_home, project_dir) = setup_preset_test_env();

    // 1. Setup: Create a global config
    let global_preset = r#"[presets]
app = "ext:rs""#;
    let config_dir = fake_home.join("rdump");
    fs::create_dir_all(&config_dir)?;
    fs::write(config_dir.join("config.toml"), global_preset)?;

    // 2. Setup: Create a local .rdump.toml that OVERRIDES the preset
    let local_preset = r#"[presets]
app = "ext:toml""#;
    fs::write(project_dir.join(".rdump.toml"), local_preset)?;

    // 3. Run the search from the project directory
    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.env("RDUMP_TEST_CONFIG_DIR", &fake_home);
    cmd.current_dir(&project_dir); // CRITICAL: Run from where the local config is
    cmd.arg("search").arg("-p").arg("app");

    // 4. Assert that it used the LOCAL definition (ext:toml) and not the global one (ext:rs)
    cmd.assert()
        .success()
        .stdout(predicate::str::contains("main.toml"))
        .stdout(predicate::str::contains("main.rs").not());

    Ok(())
}

#[test]
fn test_preset_error_handling() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, fake_home, _project_dir) = setup_preset_test_env();

    // Test removing a preset that doesn't exist
    let mut cmd_remove = Command::cargo_bin("rdump")?;
    cmd_remove.env("RDUMP_TEST_CONFIG_DIR", &fake_home);
    // Note: We have to create an empty config file first for the remove error to trigger
    let config_dir = fake_home.join("rdump");
    fs::create_dir_all(&config_dir)?;
    fs::write(config_dir.join("config.toml"), "")?;
    cmd_remove.arg("preset").arg("remove").arg("no-such-preset");

    cmd_remove
        .assert()
        .failure()
        .stderr(predicate::str::contains(
            "Preset 'no-such-preset' not found",
        ));

    Ok(())
}

#[test]
fn test_search_with_or_operator() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_test_dir();

    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root);
    cmd.arg("search").arg("ext:rs | contains:text");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("main.rs"))
        .stdout(predicate::str::contains("other.txt"));
    Ok(())
}

#[test]
fn test_output_to_file_disables_color() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_test_dir();
    let output_path = root.join("output.txt");

    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root);
    cmd.arg("search")
        .arg("ext:rs")
        .arg("--output")
        .arg(&output_path);

    // Even though the default is Auto, writing to a file should disable color.
    cmd.assert().success();

    let output_content = fs::read_to_string(&output_path)?;
    assert!(
        !output_content.contains("\x1b["),
        "Output to file should not contain ANSI color codes by default"
    );
    assert!(
        output_content.contains("fn main()"),
        "Output file should contain the matched content"
    );

    Ok(())
}

#[test]
fn test_output_to_file_forced_color() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_test_dir();
    let output_path = root.join("output_forced.txt");

    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root);
    cmd.arg("search")
        .arg("ext:rs")
        .arg("--output")
        .arg(&output_path)
        .arg("--color=always"); // Force color

    cmd.assert().success();

    let output_content = fs::read_to_string(&output_path)?;
    assert!(
        output_content.contains("\x1b["),
        "Output to file with --color=always should contain ANSI color codes"
    );

    Ok(())
}

---

File: ./rdump/tests/common.rs
---
#![allow(dead_code)] // a-llow dead code for this common helper module

use std::fs;
use std::io::Write;
use tempfile::tempdir;
use tempfile::TempDir;

/// A helper to set up a temporary directory with a multi-language sample project.
pub fn setup_test_project() -> TempDir {
    let dir = tempdir().unwrap();
    let src_dir = dir.path().join("src");
    fs::create_dir(&src_dir).unwrap();

    let main_rs_content = r#"
#[macro_use]
mod macros;
mod lib;
mod traits;

// TODO: Refactor this later
use crate::lib::{User, Role};

struct Cli {
    pattern: String,
}

pub fn main() {
    // This is the main function
    let _u = User::new();
    println!("Hello, world!");
    my_macro!();
}
"#;
    let mut main_rs = fs::File::create(src_dir.join("main.rs")).unwrap();
    main_rs.write_all(main_rs_content.as_bytes()).unwrap();

    let lib_rs_content = r#"
// This is a library file.
use serde::Serialize;

pub type UserId = u64;

pub struct User {
    id: UserId,
    name: String,
}

impl User {
    pub fn new() -> Self {
        Self { id: 0, name: "".into() }
    }
}

pub enum Role {
    Admin,
    User,
}
"#;
    let mut lib_rs = fs::File::create(src_dir.join("lib.rs")).unwrap();
    lib_rs.write_all(lib_rs_content.as_bytes()).unwrap();

    let readme_md_content = "# Test Project\nThis is a README for Role and User structs.";
    let mut readme_md = fs::File::create(dir.path().join("README.md")).unwrap();
    readme_md.write_all(readme_md_content.as_bytes()).unwrap();

    // --- Add a Python file ---
    let py_content = r#"
# FIXME: Hardcoded path
import os

class Helper:
    def __init__(self):
        self.path = "/tmp/data"
        self.do_setup()

    def do_setup(self):
        print("Setup complete")

def run_helper():
    h = Helper()
    return h.path

if __name__ == "__main__":
    run_helper()
"#;
    let mut py_file = fs::File::create(dir.path().join("helper.py")).unwrap();
    py_file.write_all(py_content.as_bytes()).unwrap();

    // --- NEW: Add JS and TS files ---
    let js_content = r#"
// HACK: for demo purposes
import { a } from './lib';

export class OldLogger {
    log(msg) { console.log("logging: " + msg); }
}

const logger = new OldLogger();
logger.log("init");
"#;
    fs::File::create(src_dir.join("logger.js"))
        .unwrap()
        .write_all(js_content.as_bytes())
        .unwrap();

    let ts_content = r#"
// REVIEW: Use a real logging library
import * as path from 'path';

export interface ILog {
    message: string;
}

export type LogLevel = "info" | "warn" | "error";

export function createLog(message: string): ILog {
    const newLog = { message };
    console.log(newLog);
    return newLog;
}
"#;
    fs::File::create(src_dir.join("log_utils.ts"))
        .unwrap()
        .write_all(ts_content.as_bytes())
        .unwrap();

    // --- NEW: Add a Go file ---
    let go_content = r#"
package main

import "fmt"

// Server represents our HTTP server.
type Server struct {
	Address string
}

func NewServer(addr string) *Server {
	return &Server{Address: addr}
}

func main() {
	server := NewServer(":8080")
	fmt.Println(server.Address)
}
"#;
    fs::File::create(src_dir.join("main.go"))
        .unwrap()
        .write_all(go_content.as_bytes())
        .unwrap();

    // --- NEW: Add a Java file ---
    let java_dir = dir.path().join("src/main/java/com/example");
    fs::create_dir_all(&java_dir).unwrap();
    let java_content = r#"
package com.example;

import java.util.ArrayList;

/**
 * Main application class.
 * HACK: This is just for a test.
 */
public class Application {
    public static void main(String[] args) {
        ArrayList<String> list = new ArrayList<>();
        System.out.println("Hello from Java!");
    }
}
"#;
    fs::File::create(java_dir.join("Application.java"))
        .unwrap()
        .write_all(java_content.as_bytes())
        .unwrap();

    let traits_rs_content = r#"
pub trait Summary {
    fn summarize(&self) -> String;
}

pub struct NewsArticle {
    pub headline: String,
    pub location: String,
    pub author: String,
    pub content: String,
}

impl Summary for NewsArticle {
    fn summarize(&self) -> String {
        format!("{}, by {} ({})", self.headline, self.author, self.location)
    }
}
"#;
    let mut traits_rs = fs::File::create(src_dir.join("traits.rs")).unwrap();
    traits_rs.write_all(traits_rs_content.as_bytes()).unwrap();

    let macros_rs_content = r#"
#[macro_export]
macro_rules! my_macro {
    () => {
        println!("This is my macro!");
    };
}
"#;
    let mut macros_rs = fs::File::create(src_dir.join("macros.rs")).unwrap();
    macros_rs.write_all(macros_rs_content.as_bytes()).unwrap();

    dir
}

---

File: ./rdump/tests/complex_queries.rs
---
use assert_cmd::prelude::*;
use predicates::prelude::*;
use std::fs;
use std::io::Write;
use std::process::Command;
use tempfile::tempdir;

fn setup_test_dir() -> (tempfile::TempDir, std::path::PathBuf) {
    let dir = tempdir().unwrap();
    let root = dir.path().to_path_buf();

    fs::File::create(root.join("a.log"))
        .unwrap()
        .write_all(b"[error] something went wrong")
        .unwrap();

    fs::File::create(root.join("b.txt"))
        .unwrap()
        .write_all(b"this is a test")
        .unwrap();

    fs::File::create(root.join("important.log"))
        .unwrap()
        .write_all(b"[warn] something might be wrong")
        .unwrap();

    fs::create_dir(root.join("old")).unwrap();
    fs::File::create(root.join("old/old_file.txt"))
        .unwrap()
        .write_all(b"this is an old error")
        .unwrap();

    fs::File::create(root.join("exact_size_123.bin"))
        .unwrap()
        .write_all(&[0; 123])
        .unwrap();

    (dir, root)
}

#[test]
fn test_deeply_nested_query() {
    let (_dir, root) = setup_test_dir();
    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(&root);
    cmd.arg("search")
        .arg(r#"((name:"*.log" or name:"*.txt") and (contains:"error" or contains:"warn")) and not (path:"old")"#);

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("a.log"))
        .stdout(predicate::str::contains("important.log"))
        .stdout(predicate::str::contains("old_file.txt").not());
}

#[test]
fn test_query_with_mixed_case_operators() {
    let (_dir, root) = setup_test_dir();
    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(&root);
    cmd.arg("search").arg(r#"name:"*.log" AND contains:"error""#);

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("a.log"));
}

#[test]
fn test_exact_size_query() {
    let (_dir, root) = setup_test_dir();
    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(&root);
    cmd.arg("search").arg(r#"size:"=123""#);

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("exact_size_123.bin"));
}

#[test]
fn test_empty_file_size_query() {
    let (_dir, root) = setup_test_dir();
    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(&root);
    cmd.arg("search").arg(r#"size:"=0""#);

    cmd.assert().success().stdout(predicate::str::is_empty());
}

---

File: ./rdump/tests/contains_predicate.rs
---


// In rdump/tests/contains_predicate.rs

use assert_cmd::prelude::*;
use predicates::prelude::*;
use std::process::Command;

mod common;
use common::setup_test_project;

#[test]
fn test_contains_simple() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("contains:\"main function\"")
        .assert()
        .success()
        .stdout(predicate::str::contains("main.rs"))
        .stdout(predicate::str::contains("main function").from_utf8());
}

#[test]
fn test_contains_case_insensitivity() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("contains:\"MAIN FUNCTION\"")
        .assert()
        .success()
        .stdout(predicate::str::contains("main.rs"))
        .stdout(predicate::str::contains("main function").from_utf8());
}

#[test]
fn test_contains_no_results() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("contains:\"this should not be found\"")
        .assert()
        .success()
        .stdout(predicate::str::is_empty());
}

#[test]
fn test_contains_with_other_predicates() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("contains:\"main function\" and ext:rs")
        .assert()
        .success()
        .stdout(predicate::str::contains("main.rs"))
        .stdout(predicate::str::contains("main.go").not());
}


---

File: ./rdump/tests/extended_cli.rs
---
// In rdump/tests/extended_cli.rs

use assert_cmd::prelude::*;
use predicates::prelude::*;
use std::fs;
use std::io::Write;
use std::process::Command;
use tempfile::tempdir;

/// Helper to create a directory with a few files for testing complex queries.
fn setup_query_test_dir() -> (tempfile::TempDir, std::path::PathBuf) {
    let dir = tempdir().unwrap();
    let root = dir.path().to_path_buf();

    // A file that will match multiple criteria (44 bytes)
    fs::File::create(root.join("main.rs"))
        .unwrap()
        .write_all(b"// main file\nfn main() {\n    println!(\"hello\");\n}")
        .unwrap();

    // A file with a different name but similar content (44 bytes)
    fs::File::create(root.join("utils.rs"))
        .unwrap()
        .write_all(b"// utility file\nfn helper() {\n    println!(\"world\");\n}")
        .unwrap();

    // A file to test case-insensitivity (8 bytes)
    fs::File::create(root.join("README.md"))
        .unwrap()
        .write_all(b"# Readme")
        .unwrap();

    (dir, root)
}

#[test]
fn test_complex_query_with_grouping() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_query_test_dir();

    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root);
    // Query: (contains:"main" or contains:"utility") and ext:rs
    cmd.arg("search")
        .arg("(contains:main | contains:utility) & ext:rs");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("main.rs"))
        .stdout(predicate::str::contains("utils.rs"))
        .stdout(predicate::str::contains("README.md").not());

    Ok(())
}

#[test]
fn test_name_predicate_case_insensitivity() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_query_test_dir();

    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root);
    // Query: name should match "readme.md" case-insensitively by default
    cmd.arg("search").arg("name:readme.md");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("README.md"));

    Ok(())
}

#[test]
fn test_matches_predicate_with_regex() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_query_test_dir();

    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root);
    // Query: matches a regex pattern for "hello" or "world"
    cmd.arg("search").arg("matches:\"(hello|world)\"");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("main.rs"))
        .stdout(predicate::str::contains("utils.rs"))
        .stdout(predicate::str::contains("README.md").not());

    Ok(())
}

#[test]
fn test_size_predicate() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_query_test_dir();

    // Test for files greater than 40 bytes
    let mut cmd_gt = Command::cargo_bin("rdump")?;
    cmd_gt.current_dir(&root);
    cmd_gt.arg("search").arg("size:>40b").arg("--format=paths");

    let output_gt = cmd_gt.output()?.stdout;
    let output_gt_str = String::from_utf8_lossy(&output_gt);
    assert_eq!(output_gt_str.lines().count(), 2, "Expected 2 files greater than 40 bytes, found: {}", output_gt_str);


    // Test for files less than 40 bytes
    let mut cmd_lt = Command::cargo_bin("rdump")?;
    cmd_lt.current_dir(&root);
    cmd_lt.arg("search").arg("size:<40b").arg("--format=paths");

    let output_lt = cmd_lt.output()?.stdout;
    let output_lt_str = String::from_utf8_lossy(&output_lt);
    assert_eq!(output_lt_str.lines().count(), 1, "Expected 1 file less than 40 bytes, found: {}", output_lt_str);

    Ok(())
}

#[test]
fn test_complex_predicate_combination() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_query_test_dir();

    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root);
    // Query: (name:main.rs or name:utils.rs) and contains:hello
    cmd.arg("search")
        .arg("(name:main.rs | name:utils.rs) & contains:hello");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("main.rs"))
        .stdout(predicate::str::contains("utils.rs").not());

    Ok(())
}

---

File: ./rdump/tests/go_search.rs
---
use assert_cmd::prelude::*;
use predicates::prelude::*;
use std::process::Command;

mod common;
use common::setup_test_project;

#[test]
fn test_struct_predicate_go() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("struct:Server & ext:go")
        .assert()
        .success()
        .stdout(predicate::str::contains("src/main.go"))
        .stdout(predicate::str::contains("type Server struct"));
}

#[test]
fn test_func_and_call_predicates_go() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("func:NewServer | call:NewServer")
        .assert()
        .success()
        .stdout(predicate::str::contains(
            "func NewServer(addr string) *Server",
        ))
        .stdout(predicate::str::contains("server := NewServer(\":8080\")"));
}

#[test]
fn test_import_and_comment_predicates_go() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("import:fmt & comment:\"HTTP server\"")
        .assert()
        .success()
        .stdout(predicate::str::contains("src/main.go"));
}

#[test]
fn test_struct_not_found_go() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("struct:NonExistent & ext:go")
        .assert()
        .success()
        .stdout(predicate::str::is_empty());
}

---

File: ./rdump/tests/hunks_format_test.rs
---
use assert_cmd::prelude::*;
use predicates::prelude::*;
use std::fs;
use std::io::Write;
use std::process::Command;
use tempfile::tempdir;

fn setup_hunks_test_dir() -> (tempfile::TempDir, std::path::PathBuf) {
    let dir = tempdir().unwrap();
    let root = dir.path().to_path_buf();

    let file_path = root.join("test.txt");
    let mut file = fs::File::create(&file_path).unwrap();
    writeln!(file, "line 1").unwrap();
    writeln!(file, "line 2").unwrap();
    writeln!(file, "line 3").unwrap();
    writeln!(file, "line 4").unwrap();
    writeln!(file, "line 5").unwrap();

    (dir, root)
}

#[test]
fn test_hunks_format() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_hunks_test_dir();

    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root);
    cmd.arg("search")
        .arg("contains:'line 3'")
        .arg("--format")
        .arg("hunks")
        .arg("-C")
        .arg("1");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("line 2"))
        .stdout(predicate::str::contains("line 3"))
        .stdout(predicate::str::contains("line 4"))
        .stdout(predicate::str::contains("line 1").not())
        .stdout(predicate::str::contains("line 5").not());

    Ok(())
}

---

File: ./rdump/tests/ignore.rs
---

// In rdump/tests/ignore.rs

use assert_cmd::prelude::*;
use predicates::prelude::*;
use std::fs;
use std::io::Write;
use std::process::Command;
use tempfile::tempdir;

#[test]
fn test_rdumpignore() -> Result<(), Box<dyn std::error::Error>> {
    let dir = tempdir()?;
    let root = dir.path();

    // Create a file that should be ignored
    fs::File::create(root.join("ignored.txt"))?
        .write_all(b"This should be ignored.")?;

    // Create a file that should not be ignored
    fs::File::create(root.join("not_ignored.txt"))?
        .write_all(b"This should not be ignored.")?;

    // Create a .rdumpignore file
    fs::File::create(root.join(".rdumpignore"))?
        .write_all(b"ignored.txt")?;

    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(root);
    cmd.arg("search").arg("contains:\"This should be ignored.\"");

    cmd.assert()
        .success()
        .stdout(predicate::str::is_empty());

    Ok(())
}

---

File: ./rdump/tests/java_search.rs
---
use assert_cmd::prelude::*;
use predicates::prelude::*;
use std::process::Command;

mod common;
use common::setup_test_project;

#[test]
fn test_class_predicate_java() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("class:Application & ext:java")
        .assert()
        .success()
        .stdout(predicate::str::contains("Application.java"))
        .stdout(predicate::str::contains("public class Application"));
}

#[test]
fn test_func_and_call_predicates_java() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("func:main & call:println")
        .assert()
        .success()
        .stdout(predicate::str::contains("Application.java"));
}

#[test]
fn test_import_and_comment_predicates_java() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("import:ArrayList & comment:HACK")
        .assert()
        .success()
        .stdout(predicate::str::contains("Application.java"));
}

#[test]
fn test_str_predicate_java() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("str:\"Hello from Java!\"")
        .assert()
        .success()
        .stdout(predicate::str::contains("Application.java"));
}

#[test]
fn test_class_not_found_java() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("class:NonExistent & ext:java")
        .assert()
        .success()
        .stdout(predicate::str::is_empty());
}

---

File: ./rdump/tests/js_ts_search.rs
---
use assert_cmd::prelude::*;
use predicates::prelude::*;
use std::process::Command;

mod common;
use common::setup_test_project;

#[test]
fn test_def_finds_javascript_class() {
    let dir = setup_test_project();

    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(dir.path());
    cmd.arg("search").arg("def:OldLogger");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("logger.js"))
        .stdout(predicate::str::contains("export class OldLogger"))
        .stdout(predicate::str::contains("log_utils.ts").not());
}

#[test]
fn test_def_finds_typescript_interface_and_type() {
    let dir = setup_test_project();
    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(dir.path())
        .arg("search")
        .arg("def:ILog | def:LogLevel");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("log_utils.ts"))
        .stdout(predicate::str::contains("interface ILog"))
        .stdout(predicate::str::contains(
            r#"type LogLevel = "info" | "warn" | "error";"#,
        ));
}

#[test]
fn test_func_finds_typescript_function() {
    let dir = setup_test_project();
    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(dir.path())
        .arg("search")
        .arg("func:createLog");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("log_utils.ts"))
        .stdout(predicate::str::contains("export function createLog"));
}

#[test]
fn test_import_finds_typescript_import() {
    let dir = setup_test_project();
    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(dir.path())
        .arg("search")
        .arg("import:path & ext:ts");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("log_utils.ts"))
        .stdout(predicate::str::contains("import * as path from 'path';"));
}

#[test]
fn test_call_predicate_javascript() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("call:log & ext:js")
        .assert()
        .success()
        .stdout(predicate::str::contains("logger.js"))
        .stdout(predicate::str::contains("logger.log(\"init\");"));
}

#[test]
fn test_call_predicate_typescript() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("call:log & ext:ts")
        .assert()
        .success()
        .stdout(predicate::str::contains("log_utils.ts"))
        .stdout(predicate::str::contains("console.log(newLog);"));
}

#[test]
fn test_comment_predicate_typescript() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("comment:REVIEW")
        .assert()
        .success()
        .stdout(predicate::str::contains("log_utils.ts"));
}

#[test]
fn test_str_predicate_javascript() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("str:logging:")
        .assert()
        .success()
        .stdout(predicate::str::contains("logger.js"));
}

#[test]
fn test_interface_and_type_predicates_typescript() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("interface:ILog & type:LogLevel")
        .assert()
        .success()
        .stdout(predicate::str::contains("log_utils.ts"));
}

#[test]
fn test_def_not_found_js_ts() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("def:NonExistent & (ext:js | ext:ts)")
        .assert()
        .success()
        .stdout(predicate::str::is_empty());
}

---

File: ./rdump/tests/matches_predicate.rs
---
use assert_cmd::prelude::*;
use predicates::prelude::*;
use std::fs;
use std::io::Write;
use std::process::Command;
use tempfile::tempdir;

fn setup_test_dir() -> (tempfile::TempDir, std::path::PathBuf) {
    let dir = tempdir().unwrap();
    let root = dir.path().to_path_buf();

    fs::File::create(root.join("file1.txt"))
        .unwrap()
        .write_all(b"hello world\n(hello world)\nHELLO WORLD")
        .unwrap();

    fs::File::create(root.join("file2.txt"))
        .unwrap()
        .write_all(b"this is a test\nfoo bar baz")
        .unwrap();

    fs::File::create(root.join("unicode.txt"))
        .unwrap()
        .write_all("こんにちは世界\n你好世界".as_bytes())
        .unwrap();

    (dir, root)
}

#[test]
fn test_matches_with_special_characters() {
    let (_dir, root) = setup_test_dir();
    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(&root);
    cmd.arg("search")
        .arg(r#"matches:'\(hello world\)'"#);

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("file1.txt"));
}

#[test]
fn test_matches_multiple_lines() {
    let (_dir, root) = setup_test_dir();
    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(&root);
    cmd.arg("search")
        .arg(r#"matches:'hello world'"#);

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("hello world\n(hello world)"));
}

#[test]
fn test_matches_no_match() {
    let (_dir, root) = setup_test_dir();
    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(&root);
    cmd.arg("search")
        .arg(r#"matches:'goodbye world'"#);

    cmd.assert().success().stdout(predicate::str::is_empty());
}

#[test]
fn test_matches_case_insensitive() {
    let (_dir, root) = setup_test_dir();
    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(&root);
    cmd.arg("search")
        .arg(r#"matches:'(?i)hello world'"#);

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("file1.txt"))
        .stdout(predicate::str::contains("hello world\n(hello world)\nHELLO WORLD"));
}

#[test]
fn test_matches_unicode() {
    let (_dir, root) = setup_test_dir();
    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(&root);
    cmd.arg("search")
        .arg(r#"matches:'こんにちは世界'"#);

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("unicode.txt"));
}

#[test]
fn test_invalid_regex() {
    let (_dir, root) = setup_test_dir();
    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(&root);
    cmd.arg("search").arg(r#"matches:'('"#);

    cmd.assert()
        .failure()
        .stderr(predicate::str::contains("regex parse error"));
}

---

File: ./rdump/tests/modified_predicate.rs
---

use assert_cmd::prelude::*;
use predicates::prelude::*;
use std::fs::File;
use std::process::Command;
use std::thread;
use std::time::Duration;
use tempfile::tempdir;

fn setup_test_dir() -> (tempfile::TempDir, std::path::PathBuf) {
    let dir = tempdir().unwrap();
    let root = dir.path().to_path_buf();

    // Create files with different modification times
    thread::sleep(Duration::from_secs(2));
    File::create(root.join("old.txt")).unwrap();
    thread::sleep(Duration::from_secs(2));
    File::create(root.join("recent.txt")).unwrap();

    (dir, root)
}

#[test]
fn test_modified_after() {
    let (_dir, root) = setup_test_dir();
    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(&root);
    cmd.arg("search").arg("modified:>1s");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("recent.txt"))
        .stdout(predicate::str::contains("old.txt").not());
}

#[test]
fn test_modified_before() {
    let (_dir, root) = setup_test_dir();
    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(&root);
    cmd.arg("search").arg("modified:<1s");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("old.txt"))
        .stdout(predicate::str::contains("recent.txt").not());
}

#[test]
fn test_modified_exact_date() {
    let (_dir, root) = setup_test_dir();
    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(&root);
    let now = chrono::Local::now().format("%Y-%m-%d").to_string();
    cmd.arg("search").arg(format!("modified:{}", now));

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("recent.txt"))
        .stdout(predicate::str::contains("old.txt"));
}

#[test]
fn test_invalid_date_format() {
    let (_dir, root) = setup_test_dir();
    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(&root);
    cmd.arg("search").arg("modified:invalid-date");

    cmd.assert()
        .failure()
        .stderr(predicate::str::contains("Invalid date format"));
}

---

File: ./rdump/tests/python_search.rs
---
use assert_cmd::prelude::*;
use predicates::prelude::*;
use std::process::Command;

mod common;
use common::setup_test_project;

#[test]
fn test_def_finds_python_class() {
    let dir = setup_test_project();

    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(dir.path());
    cmd.arg("search").arg("def:Helper & ext:py");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("helper.py"))
        .stdout(predicate::str::contains("class Helper"))
        .stdout(predicate::str::contains("src/main.rs").not());
}

#[test]
fn test_func_finds_python_function() {
    let dir = setup_test_project();

    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(dir.path());
    cmd.arg("search").arg("func:run_helper");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("helper.py"))
        .stdout(predicate::str::contains("def run_helper()"))
        .stdout(predicate::str::contains("src/main.rs").not());
}

#[test]
fn test_import_finds_python_import() {
    let dir = setup_test_project();

    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(dir.path());
    cmd.arg("search").arg("import:os & ext:py");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("helper.py"))
        .stdout(predicate::str::contains("import os"))
        .stdout(predicate::str::contains("src/lib.rs").not());
}

#[test]
fn test_comment_and_class_predicates_python() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("comment:FIXME & class:Helper")
        .assert()
        .success()
        .stdout(predicate::str::contains("helper.py"));
}

#[test]
fn test_str_predicate_python() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("str:/tmp/data")
        .assert()
        .success()
        .stdout(predicate::str::contains("helper.py"));
}

#[test]
fn test_call_predicate_python() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("call:run_helper | call:do_setup")
        .assert()
        .success()
        .stdout(predicate::str::contains("self.do_setup()"))
        .stdout(predicate::str::contains("run_helper()"));
}

#[test]
fn test_def_not_found_python() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("def:NonExistent & ext:py")
        .assert()
        .success()
        .stdout(predicate::str::is_empty());
}

---

File: ./rdump/tests/rust_search.rs
---
use assert_cmd::prelude::*;
use predicates::prelude::*;
use std::process::Command;

mod common;
use common::setup_test_project;

#[test]
fn test_def_finds_struct_in_correct_file() {
    let dir = setup_test_project();

    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(dir.path());
    cmd.arg("search").arg("def:Cli"); // Query for the Cli struct

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("src/main.rs"))
        .stdout(predicate::str::contains("struct Cli"))
        .stdout(predicate::str::contains("src/lib.rs").not());
}

#[test]
fn test_def_finds_enum_in_correct_file() {
    let dir = setup_test_project();

    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(dir.path());
    cmd.arg("search").arg("def:Role"); // Query for the Role enum

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("src/lib.rs"))
        .stdout(predicate::str::contains("pub enum Role"))
        .stdout(predicate::str::contains("src/main.rs").not());
}

#[test]
fn test_def_with_ext_predicate_and_paths_format() {
    let dir = setup_test_project();
    let root = dir.path();

    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(root);
    cmd.arg("search").arg("def:User & ext:rs");
    cmd.arg("--format=paths");

    // Normalize path for cross-platform compatibility
    let expected_path_str = format!("src{}lib.rs", std::path::MAIN_SEPARATOR);

    cmd.assert()
        .success()
        .stdout(predicate::str::contains(expected_path_str));
}

#[test]
fn test_def_returns_no_matches_for_non_existent_item() {
    let dir = setup_test_project();

    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(dir.path());
    cmd.arg("search").arg("def:NonExistent");

    // Should succeed with no output
    cmd.assert().success().stdout(predicate::str::is_empty());
}

#[test]
fn test_def_does_not_match_in_non_rust_files() {
    let dir = setup_test_project();

    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(dir.path());
    // The README.md contains the words "Role" and "User"
    cmd.arg("search").arg("def:Role | def:User");

    // It should ONLY find src/lib.rs, not README.md
    cmd.assert()
        .success()
        .stdout(predicate::str::contains("src/lib.rs"))
        .stdout(predicate::str::contains("README.md").not());
}

#[test]
fn test_func_finds_standalone_function() {
    let dir = setup_test_project();

    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(dir.path());
    cmd.arg("search").arg("func:main");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("src/main.rs"))
        .stdout(predicate::str::contains("src/lib.rs").not());
}

#[test]
fn test_func_finds_impl_method() {
    let dir = setup_test_project();

    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(dir.path());
    cmd.arg("search").arg("func:new");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("src/lib.rs"))
        .stdout(predicate::str::contains("src/main.rs").not());
}

#[test]
fn test_import_finds_use_statement() {
    let dir = setup_test_project();

    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(dir.path());
    cmd.arg("search")
        .arg("--format=markdown")
        .arg("import:serde");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("src/lib.rs"))
        .stdout(predicate::str::contains("```rs")) // Check for markdown code fence
        .stdout(predicate::str::contains("src/main.rs").not());
}

#[test]
fn test_logical_or_across_files() {
    let dir = setup_test_project();

    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(dir.path());
    cmd.arg("search").arg("func:main | import:serde");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("src/main.rs"))
        .stdout(predicate::str::contains("src/lib.rs"));
}

#[test]
fn test_comment_predicate_rust() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("comment:TODO")
        .assert()
        .success()
        .stdout(predicate::str::contains("src/main.rs"))
        .stdout(predicate::str::contains("src/lib.rs").not());
}

#[test]
fn test_str_predicate_rust() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("str:\"Hello, world!\"")
        .assert()
        .success()
        .stdout(predicate::str::contains("src/main.rs"));
}

#[test]
fn test_type_and_struct_predicates_rust() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("type:UserId & struct:User")
        .assert()
        .success()
        .stdout(predicate::str::contains("src/lib.rs"))
        .stdout(predicate::str::contains("src/main.rs").not());
}

#[test]
fn test_call_predicate_rust() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("call:println & ext:rs")
        .assert()
        .success()
        .stdout(predicate::str::contains("src/main.rs")) // The call is in main.rs
        .stdout(predicate::str::contains("src/lib.rs").not()); // The definition is in lib.rs
}

#[test]
fn test_logical_operators_with_hunks() {
    let dir = setup_test_project();
    // Query: find the file that defines the `Cli` struct AND ALSO contains a `TODO` comment.
    // This should only match main.rs
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("--format=hunks")
        .arg("struct:Cli & comment:TODO")
        .assert()
        .success()
        .stdout(predicate::str::contains("src/main.rs"))
        .stdout(predicate::str::contains("src/lib.rs").not());
}

#[test]
fn test_negation_with_hunks() {
    let dir = setup_test_project();
    // Query: find files with `User` struct but NOT containing `TODO`
    // This should only match lib.rs
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("--format=hunks")
        .arg("struct:User & !comment:TODO")
        .assert()
        .success()
        .stdout(predicate::str::contains("src/lib.rs"))
        .stdout(predicate::str::contains("User"))
        .stdout(predicate::str::contains("src/main.rs").not());
}

#[test]
fn test_and_of_semantic_predicates() {
    let dir = setup_test_project();
    // Query: find files with a `struct` AND a `func`
    // This should only match lib.rs (User struct, new function)
    // and main.rs (Cli struct, main function)
    let mut cmd = Command::cargo_bin("rdump").unwrap();
    cmd.current_dir(dir.path());
    cmd.arg("search");
    cmd.arg("--format=paths");
    cmd.arg("struct:. & func:. & ext:rs");

    let output = cmd.output().unwrap();
    let stdout = String::from_utf8(output.stdout).unwrap();
    let lines: Vec<&str> = stdout.lines().collect();
    assert_eq!(
        lines.len(),
        3,
        "Expected exactly 3 files, but found {}: {:?}",
        lines.len(),
        lines
    );
}

#[test]
fn test_func_not_found() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("func:non_existent_function")
        .assert()
        .success()
        .stdout(predicate::str::is_empty());
}

---

File: ./rdump/tests/rust_search_macros.rs
---

use assert_cmd::prelude::*;
use predicates::prelude::*;
use std::process::Command;

mod common;
use common::setup_test_project;

#[test]
fn test_macro_def_predicate() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("macro:my_macro")
        .assert()
        .success()
        .stdout(predicate::str::contains("src/macros.rs"))
        .stdout(predicate::str::contains("macro_rules! my_macro"));
}

#[test]
fn test_macro_call_predicate() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("call:my_macro")
        .assert()
        .success()
        .stdout(predicate::str::contains("src/main.rs"))
        .stdout(predicate::str::contains("my_macro!"));
}

---

File: ./rdump/tests/rust_search_traits.rs
---

use assert_cmd::prelude::*;
use predicates::prelude::*;
use std::process::Command;

mod common;
use common::setup_test_project;

#[test]
fn test_trait_predicate() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("trait:Summary")
        .assert()
        .success()
        .stdout(predicate::str::contains("src/traits.rs"))
        .stdout(predicate::str::contains("pub trait Summary"));
}

#[test]
fn test_impl_predicate() {
    let dir = setup_test_project();
    Command::cargo_bin("rdump")
        .unwrap()
        .current_dir(dir.path())
        .arg("search")
        .arg("impl:NewsArticle")
        .assert()
        .success()
        .stdout(predicate::str::contains("src/traits.rs"))
        .stdout(predicate::str::contains("impl Summary for NewsArticle"));
}

---

File: ./rdump/tsconfig.json
---
{
  "compilerOptions": {
    "module": "commonjs",
    "target": "es2017",
    "esModuleInterop": true,
    "strict": true,
    "noImplicitAny": true,
    "moduleResolution": "node",
    "sourceMap": true,
    "outDir": "dist",
    "baseUrl": ".",
    "paths": {
      "*": [
        "node_modules/*"
      ]
    }
  },
  "include": [
    "**/*.ts"
  ],
  "exclude": [
    "node_modules"
  ]
}

---

File: ./tests/cli.rs
---
// In rdump/tests/cli.rs

use assert_cmd::prelude::*; // Adds methods on commands
use predicates::prelude::*; // Used for writing assertions
use std::fs;
use std::io::Write;
use std::process::Command; // Lets us run other programs
use tempfile::tempdir; // Create temporary directories for testing

// --- Helper Functions ---

/// A helper to set up a temporary directory with a predictable file structure for tests.
/// Returns the TempDir object (which cleans up the directory when it's dropped)
/// and the PathBuf of the root, for convenience.
fn setup_test_dir() -> (tempfile::TempDir, std::path::PathBuf) {
    let dir = tempdir().unwrap();
    let root = dir.path().to_path_buf();

    // Create a file to be found
    fs::File::create(root.join("main.rs"))
        .unwrap()
        .write_all(b"fn main() {\n    println!(\"Hello\");\n}")
        .unwrap();

    // Create a file that shouldn't be found by most queries
    fs::File::create(root.join("other.txt"))
        .unwrap()
        .write_all(b"some text")
        .unwrap();

    (dir, root)
}

// --- Test Implementation ---

#[test]
fn test_help_message() -> Result<(), Box<dyn std::error::Error>> {
    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.arg("--help");
    cmd.assert()
        .success()
        .stdout(predicate::str::contains(
            "A fast, expressive, code-aware tool",
        ))
        .stdout(predicate::str::contains("Usage: rdump <COMMAND>"))
        .stdout(predicate::str::contains("Commands:\n  search"))
        .stdout(predicate::str::contains("  preset"))
        .stdout(predicate::str::contains("Options:\n  -h, --help"))
        .stdout(predicate::str::contains("  -V, --version"));
    Ok(())
}

#[test]
fn test_version_message() -> Result<(), Box<dyn std::error::Error>> {
    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.arg("--version");
    cmd.assert()
        .success()
        .stdout(predicate::str::contains("rdump 0.1.0")); // Assumes version in Cargo.toml
    Ok(())
}

#[test]
fn test_no_args_fails() -> Result<(), Box<dyn std::error::Error>> {
    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.assert()
        .failure() // Should fail because a subcommand is required
        .stderr(predicate::str::contains("Usage: rdump <COMMAND>"));
    Ok(())
}

#[test]
fn test_search_simple_predicate_succeeds() -> Result<(), Box<dyn std::error::Error>> {
    // Setup a temporary directory with our test files
    let (_dir, root) = setup_test_dir();

    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root); // Run the command *from* our test directory
    cmd.arg("search").arg("ext:rs");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("File: ./main.rs"))
        .stdout(predicate::str::contains("```rs")) // Check for markdown code fence
        .stdout(predicate::str::contains("---").count(1))
        .stdout(predicate::str::contains("other.txt").not());
    Ok(())
}

#[test]
fn test_search_no_results() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_test_dir();

    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root);
    cmd.arg("search").arg("ext:java"); // No java files exist

    cmd.assert().success().stdout(predicate::str::is_empty()); // Nothing should be printed
    Ok(())
}

#[test]
fn test_search_invalid_query_fails() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_test_dir();

    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root);
    cmd.arg("search").arg("ext:"); // Query with a missing value

    cmd.assert()
        .failure()
        .stdout(predicate::str::is_empty())
        .stderr(predicate::str::contains("expected value"));
    Ok(())
}

// Add this new helper function to rdump/tests/cli.rs

/// Sets up a more complex directory for testing discovery and formatting.
fn setup_advanced_test_dir() -> (tempfile::TempDir, std::path::PathBuf) {
    let dir = tempdir().unwrap();
    let root = dir.path().to_path_buf();

    // Top-level files
    fs::File::create(root.join("main.rs"))
        .unwrap()
        .write_all(b"fn main() {}")
        .unwrap();
    fs::File::create(root.join(".hidden_config"))
        .unwrap()
        .write_all(b"secret=true")
        .unwrap();

    // Subdirectory with a file
    fs::create_dir(root.join("src")).unwrap();
    fs::File::create(root.join("src/lib.rs"))
        .unwrap()
        .write_all(b"// a library")
        .unwrap();

    // Directory and file to be ignored
    fs::create_dir(root.join("logs")).unwrap();
    fs::File::create(root.join("logs/latest.log"))
        .unwrap()
        .write_all(b"INFO: started")
        .unwrap();

    // .gitignore file to ignore the logs
    let mut gitignore = fs::File::create(root.join(".gitignore")).unwrap();
    writeln!(gitignore, "*.log").unwrap();

    (dir, root)
}

// Add these new tests to the end of rdump/tests/cli.rs

#[test]
fn test_file_discovery_flags() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_advanced_test_dir();

    // Test --hidden flag
    let mut cmd_hidden = Command::cargo_bin("rdump")?;
    cmd_hidden.current_dir(&root);
    cmd_hidden.arg("search").arg("--hidden").arg("path:hidden");
    cmd_hidden
        .assert()
        .success()
        .stdout(predicate::str::contains(".hidden_config"));

    // Test --no-ignore flag
    let mut cmd_no_ignore = Command::cargo_bin("rdump")?;
    cmd_no_ignore.current_dir(&root);
    cmd_no_ignore
        .arg("search")
        .arg("--no-ignore")
        .arg("ext:log");
    cmd_no_ignore
        .assert()
        .success()
        .stdout(predicate::str::contains("latest.log"));

    // Test --max-depth flag
    let mut cmd_depth = Command::cargo_bin("rdump")?;
    cmd_depth.current_dir(&root);
    // This should find `main.rs` but not `src/lib.rs`
    cmd_depth
        .arg("search")
        .arg("--max-depth")
        .arg("1")
        .arg("ext:rs");
    cmd_depth
        .assert()
        .success()
        .stdout(predicate::str::contains("main.rs"))
        .stdout(predicate::str::contains("src/lib.rs").not());

    Ok(())
}

#[test]
fn test_output_formatting_flags() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_advanced_test_dir();

    // Test --format paths
    let mut cmd_paths = Command::cargo_bin("rdump")?;
    cmd_paths.current_dir(&root);
    cmd_paths
        .arg("search")
        .arg("--format")
        .arg("paths")
        .arg("ext:rs");
    // Should contain ONLY the paths, sorted. The extra newline is important.
    let output = String::from_utf8(cmd_paths.get_output().stdout.clone()).unwrap();
    let mut paths: Vec<&str> = output.trim().split('\n').collect();
    paths.sort();
    assert_eq!(paths, vec!["./main.rs", "./src/lib.rs"]);

    // Test --format json
    let mut cmd_json = Command::cargo_bin("rdump")?;
    cmd_json.current_dir(&root);
    cmd_json
        .arg("search")
        .arg("--format")
        .arg("json")
        .arg("path:main.rs");
    // Assert it contains the key parts of a valid JSON output
    cmd_json
        .assert()
        .success()
        .stdout(predicate::str::contains(r#""path": "./main.rs""#))
        .stdout(predicate::str::contains(r#""content": "fn main() {}""#));

    // Test --format cat with --line-numbers (no color, since it's a pipe)
    let mut cmd_cat = Command::cargo_bin("rdump")?;
    cmd_cat.current_dir(&root);
    cmd_cat
        .arg("search")
        .arg("--format")
        .arg("cat")
        .arg("--line-numbers")
        .arg("path:main.rs");
    cmd_cat
        .assert()
        .success()
        .stdout(predicate::str::contains("1 | fn main() {}"))
        .stdout(predicate::str::contains("\x1b[").not()); // Check for NO ANSI color codes

    // Test --color=always to force highlighting
    let mut cmd_color = Command::cargo_bin("rdump")?;
    cmd_color.current_dir(&root);
    cmd_color
        .arg("search")
        .arg("--color=always")
        .arg("path:main.rs");
    cmd_color
        .assert()
        .success()
        .stdout(predicate::str::contains("\x1b[")); // Check FOR ANSI color codes

    // Test --find shorthand flag
    let mut cmd_find = Command::cargo_bin("rdump")?;
    cmd_find.current_dir(&root);
    cmd_find.arg("search").arg("--find").arg("path:main.rs");
    // We can't know the exact permissions/date, but we can check for the structure
    cmd_find
        .assert()
        .success()
        .stdout(predicate::str::contains("main.rs")) // The path
        .stdout(predicate::str::contains("12")); // The size (fn main() {} is 12 bytes)

    Ok(())
}

/// Sets up an environment for testing presets, with a fake home and project directory.
fn setup_preset_test_env() -> (tempfile::TempDir, std::path::PathBuf, std::path::PathBuf) {
    let dir = tempdir().unwrap();
    let fake_home = dir.path().join("home");
    fs::create_dir(&fake_home).unwrap();
    let project_dir = dir.path().join("project");
    fs::create_dir(&project_dir).unwrap();

    // Create a file in the project directory to be found by searches
    fs::File::create(project_dir.join("main.rs"))
        .unwrap()
        .write_all(b"fn main() {}")
        .unwrap();
    fs::File::create(project_dir.join("main.toml"))
        .unwrap()
        .write_all(b"[package]")
        .unwrap();

    (dir, fake_home, project_dir)
}

// Add these new tests to the end of rdump/tests/cli.rs

#[test]
fn test_preset_lifecycle() -> Result<(), Box<dyn std::error::Error>> {
    // We get a clean home directory AND a clean project directory
    let (_dir, fake_home, project_dir) = setup_preset_test_env();
    let config_path = fake_home.join("rdump/config.toml");

    // 1. List when no presets exist.
    // CRITICAL FIX: Run this command from the clean project_dir.
    let mut cmd_list1 = Command::cargo_bin("rdump")?;
    cmd_list1.env("RDUMP_TEST_CONFIG_DIR", &fake_home);
    cmd_list1.current_dir(&project_dir); // <--- THIS IS THE FIX
    cmd_list1.arg("preset").arg("list");
    cmd_list1
        .assert()
        .success()
        .stdout(predicate::str::contains("No presets found."));

    // 2. Add a preset. This command is not affected by current_dir, but it's good practice.
    let mut cmd_add = Command::cargo_bin("rdump")?;
    cmd_add.env("RDUMP_TEST_CONFIG_DIR", &fake_home);
    cmd_add.current_dir(&project_dir); // Add for consistency
    cmd_add
        .arg("preset")
        .arg("add")
        .arg("rust-files")
        .arg("ext:rs");
    cmd_add.assert().success();

    // Verify the file content directly
    assert!(config_path.exists());
    let content = fs::read_to_string(&config_path)?;
    assert!(content.contains(r#"rust-files = "ext:rs""#));

    // 3. List again to see the new preset.
    let mut cmd_list2 = Command::cargo_bin("rdump")?;
    cmd_list2.env("RDUMP_TEST_CONFIG_DIR", &fake_home);
    cmd_list2.current_dir(&project_dir); // Add for consistency
    cmd_list2.arg("preset").arg("list");
    cmd_list2
        .assert()
        .success()
        .stdout(predicate::str::contains("rust-files : ext:rs"));

    // 4. Remove the preset.
    let mut cmd_remove = Command::cargo_bin("rdump")?;
    cmd_remove.env("RDUMP_TEST_CONFIG_DIR", &fake_home);
    cmd_remove.current_dir(&project_dir); // Add for consistency
    cmd_remove.arg("preset").arg("remove").arg("rust-files");
    cmd_remove.assert().success();

    // Verify the file content has changed
    let content_after_remove = fs::read_to_string(&config_path)?;
    assert!(!content_after_remove.contains("rust-files"));

    Ok(())
}

#[test]
fn test_search_and_preset_interaction() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, fake_home, project_dir) = setup_preset_test_env();

    // 1. Setup: Create presets
    let preset_content = r#"
[presets]
rust = "ext:rs"
config = "ext:toml"
"#;
    let config_dir = fake_home.join("rdump");
    fs::create_dir_all(&config_dir)?;
    fs::write(config_dir.join("config.toml"), preset_content)?;

    // 2. Test search with one preset
    let mut cmd_search1 = Command::cargo_bin("rdump")?;
    cmd_search1.env("RDUMP_TEST_CONFIG_DIR", &fake_home);
    cmd_search1.current_dir(&project_dir);
    cmd_search1.arg("search").arg("-p").arg("rust");
    cmd_search1
        .assert()
        .success()
        .stdout(predicate::str::contains("main.rs"))
        .stdout(predicate::str::contains("main.toml").not());

    // 3. Test search with a preset AND a query
    // Should evaluate to `(ext:rs) & contains:main`
    let mut cmd_search2 = Command::cargo_bin("rdump")?;
    cmd_search2.env("RDUMP_TEST_CONFIG_DIR", &fake_home);
    cmd_search2.current_dir(&project_dir);
    cmd_search2
        .arg("search")
        .arg("-p")
        .arg("rust")
        .arg("contains:main");
    cmd_search2
        .assert()
        .success()
        .stdout(predicate::str::contains("main.rs"));

    // 4. Test search with multiple presets
    // Should evaluate to `(ext:toml) & (ext:rs)` -> no results
    let mut cmd_search3 = Command::cargo_bin("rdump")?;
    cmd_search3.env("RDUMP_TEST_CONFIG_DIR", &fake_home);
    cmd_search3.current_dir(&project_dir);
    cmd_search3
        .arg("search")
        .arg("-p")
        .arg("rust")
        .arg("-p")
        .arg("config");
    cmd_search3
        .assert()
        .success()
        .stdout(predicate::str::is_empty());

    Ok(())
}

#[test]
fn test_local_config_override() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, fake_home, project_dir) = setup_preset_test_env();

    // 1. Setup: Create a global config
    let global_preset = r#"[presets]
app = "ext:rs""#;
    let config_dir = fake_home.join("rdump");
    fs::create_dir_all(&config_dir)?;
    fs::write(config_dir.join("config.toml"), global_preset)?;

    // 2. Setup: Create a local .rdump.toml that OVERRIDES the preset
    let local_preset = r#"[presets]
app = "ext:toml""#;
    fs::write(project_dir.join(".rdump.toml"), local_preset)?;

    // 3. Run the search from the project directory
    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.env("RDUMP_TEST_CONFIG_DIR", &fake_home);
    cmd.current_dir(&project_dir); // CRITICAL: Run from where the local config is
    cmd.arg("search").arg("-p").arg("app");

    // 4. Assert that it used the LOCAL definition (ext:toml) and not the global one (ext:rs)
    cmd.assert()
        .success()
        .stdout(predicate::str::contains("main.toml"))
        .stdout(predicate::str::contains("main.rs").not());

    Ok(())
}

#[test]
fn test_preset_error_handling() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, fake_home, _project_dir) = setup_preset_test_env();

    // Test removing a preset that doesn't exist
    let mut cmd_remove = Command::cargo_bin("rdump")?;
    cmd_remove.env("RDUMP_TEST_CONFIG_DIR", &fake_home);
    // Note: We have to create an empty config file first for the remove error to trigger
    let config_dir = fake_home.join("rdump");
    fs::create_dir_all(&config_dir)?;
    fs::write(config_dir.join("config.toml"), "")?;
    cmd_remove.arg("preset").arg("remove").arg("no-such-preset");

    cmd_remove
        .assert()
        .failure()
        .stderr(predicate::str::contains(
            "Preset 'no-such-preset' not found",
        ));

    Ok(())
}

#[test]
fn test_no_ignore_finds_ignored_files() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_advanced_test_dir();
    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root);
    cmd.arg("search").arg("--no-ignore").arg("ext:log");
    cmd.assert()
        .success()
        .stdout(predicate::str::contains("latest.log"));
    Ok(())
}

#[test]
fn test_no_headers_suppresses_headers() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_test_dir();
    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root);
    cmd.arg("search").arg("ext:rs").arg("--no-headers");
    cmd.assert()
        .success()
        .stdout(predicate::str::contains("File:").not());
    Ok(())
}

#[test]
fn test_line_numbers_with_hunks() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_test_dir();
    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root);
    cmd.arg("search")
        .arg("contains:Hello")
        .arg("--line-numbers");
    cmd.assert()
        .success()
        .stdout(predicate::str::contains("2 |     println!(\"Hello\");"));
    Ok(())
}

#[test]
fn test_path_predicate_cli() -> Result<(), Box<dyn std::error::Error>> {
    let mut cmd = Command::cargo_bin("rdump")?;
    // Test glob matching
    cmd.arg("search")
        .arg("path:**/sub/dir/*")
        .arg("--format")
        .arg("paths");
    cmd.assert()
        .success()
        .stdout(predicate::str::contains("insane_test_bed/sub/dir/some_file.txt"));

    // Test contains matching
    let mut cmd2 = Command::cargo_bin("rdump")?;
    cmd2.arg("search")
        .arg("path:sub/dir")
        .arg("--format")
        .arg("paths");
    cmd2.assert()
        .success()
        .stdout(predicate::str::contains("insane_test_bed/sub/dir/some_file.txt"));
    Ok(())
}

#[test]
fn test_path_predicate_deep_glob_cli() -> Result<(), Box<dyn std::error::Error>> {
    // Setup a temporary directory with a deep structure
    let dir = tempdir()?;
    let root = dir.path();
    let deep_path = root.join("level1/level2/hooks/my-feature");
    fs::create_dir_all(&deep_path)?;
    fs::File::create(deep_path.join("use-boolean.js"))?;

    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(root); // Run from the temp dir root
    cmd.arg("search")
        .arg("path:hooks/*/use-boolean.js") // The intuitive glob
        .arg("--format")
        .arg("paths");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("use-boolean.js"));

    Ok(())
}

#[test]
fn test_cat_format_no_color_by_default() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_test_dir();
    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root);
    cmd.arg("search")
        .arg("ext:rs")
        .arg("--format")
        .arg("cat");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("fn main()"))
        .stdout(predicate::str::contains("\x1b[").not()); // Ensure no ANSI codes
    Ok(())
}

#[test]
fn test_cat_format_can_force_color() -> Result<(), Box<dyn std::error::Error>> {
    let (_dir, root) = setup_test_dir();
    let mut cmd = Command::cargo_bin("rdump")?;
    cmd.current_dir(&root);
    cmd.arg("search")
        .arg("ext:rs")
        .arg("--format")
        .arg("cat")
        .arg("--color=always");

    cmd.assert()
        .success()
        .stdout(predicate::str::contains("fn main()"))
        .stdout(predicate::str::contains("\x1b[")); // Ensure ANSI codes ARE present
    Ok(())
}
