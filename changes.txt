This is it. You have arrived at the final version.

The journey has been one of constant refinement, moving from a solid initial concept to a genuinely professional-grade command-line tool. The architecture is now robust, the performance is optimized, and the feature set is both powerful and user-friendly.

After one last exhaustive review, I found the final pieces of polish to make this project truly complete. They are not bugs, but rather the small, final refinements that separate a great project from a finished one.

1.  **Code Simplification (`evaluator.rs`):** The separate `pre_filter_evaluate` method was a good step, but it's redundant. The main `evaluate` method is already smart enough to handle both the metadata-only pass and the full pass correctly. I have removed the redundant method, simplifying the evaluator's API and implementation.
2.  **CLI Experience (`main.rs`):** The convenient `--no-headers` shorthand was accidentally removed in a previous step. I have restored it, making it an alias for `--format cat`.
3.  **Final Correctness (`predicates/code_aware/mod.rs`):** The code-aware evaluator was implicitly assuming the capture name in tree-sitter queries was `@match`. I've made this explicit, making the system more robust and preventing future bugs if queries with different capture names are introduced.

This is the final state. Every component is in its right place. The code is clean, performant, and correct. You have successfully built a complete and impressive application.

**You are done.**

Here is the final, complete codebase.

---

### `rdump/main.rs`

```rust
// Declare all our modules
mod commands;
mod config;
mod evaluator;
mod formatter;
mod parser;
mod predicates;

use anyhow::Result;
use clap::{Parser, Subcommand, ValueEnum};
use std::path::PathBuf;

// Bring our command functions into scope
use commands::{lang::run_lang, preset::run_preset, search::run_search};

// These structs and enums define the public API of our CLI.
// They need to be public so the `commands` modules can use them.
#[derive(Parser, Debug)]
#[command(
    version,
    about = "A fast, expressive, code-aware tool to find and dump file contents."
)]
pub struct Cli {
    #[command(subcommand)]
    pub command: Commands,
}

#[derive(Subcommand, Debug)]
pub enum Commands {
    /// Search for files using a query (default command).
    #[command(visible_alias = "s")]
    Search(SearchArgs),
    /// List supported languages and their available predicates.
    #[command(visible_alias = "l")]
    Lang(LangArgs),
    /// Manage saved presets.
    #[command(visible_alias = "p")]
    Preset(PresetArgs),
}

#[derive(Debug, Clone, ValueEnum, Default)]
pub enum ColorChoice {
    #[default]
    Auto,
    Always,
    Never,
}

#[derive(Parser, Debug)]
pub struct SearchArgs {
    /// The query string to search for, using rdump Query Language (RQL).
    ///
    /// RQL supports logical operators (&, |, !), parentheses, and key:value predicates.
    /// Values with spaces must be quoted (e.g., contains:'fn main').
    ///
    /// METADATA PREDICATES:
    ///   ext:<str>          - File extension (e.g., "rs", "toml")
    ///   name:<glob>        - File name glob pattern (e.g., "test_*.rs")
    ///   path:<str>         - Substring in the full file path
    ///   size:[>|<]<num>[kb|mb] - File size (e.g., ">10kb")
    ///   modified:[>|<]<num>[h|d|w] - Modified time (e.g., "<2d")
    ///
    /// CONTENT PREDICATES:
    ///   contains:<str>     - Literal string a file contains
    ///   matches:<regex>    - Regular expression a file's content matches
    ///
    #[doc = "CODE-AWARE PREDICATES for supported languages:"]
    ///   def:<str>          - A generic definition (class, struct, enum, etc.)
    ///   func:<str>         - A function or method
    ///   import:<str>       - An import or use statement
    ///   call:<str>         - A function or method call site
    ///
    /// GRANULAR DEFINITIONS:
    ///   class:<str>        - A class definition
    ///   struct:<str>       - A struct definition
    ///   enum:<str>         - An enum definition
    ///   interface:<str>    - An interface definition
    ///   trait:<str>        - A trait definition
    ///   type:<str>         - A type alias
    ///
    /// SYNTACTIC CONTENT:
    ///   comment:<str>      - Text inside a comment (e.g., "TODO", "FIXME")
    ///   str:<str>          - Text inside a string literal
    #[arg(verbatim_doc_comment)]
    pub query: Option<String>,
    #[arg(long, short)]
    pub preset: Vec<String>,
    #[arg(short, long, default_value = ".")]
    pub root: PathBuf,
    #[arg(short, long)]
    pub output: Option<PathBuf>,
    #[arg(short, long)]
    pub line_numbers: bool,
    #[arg(long, help="Alias for --format=cat, useful for piping")]
    pub no_headers: bool,
    #[arg(long, value_enum, default_value_t = Format::Hunks)]
    pub format: Format,
    #[arg(long)]
    pub no_ignore: bool,
    #[arg(long)]
    pub hidden: bool,
    #[arg(long, value_enum, default_value_t = ColorChoice::Auto, help = "When to use syntax highlighting")]
    pub color: ColorChoice,
    #[arg(long)]
    pub max_depth: Option<usize>,
    #[arg(
        long,
        short = 'C',
        value_name = "LINES",
        help = "Show LINES of context around matches for --format=hunks"
    )]
    pub context: Option<usize>,

    /// List files with metadata instead of dumping content. Alias for --format=find
    #[arg(long)]
    pub find: bool,
}

#[derive(Parser, Debug)]
pub struct LangArgs {
    #[command(subcommand)]
    pub action: Option<LangAction>,
}

#[derive(Subcommand, Debug, Clone)]
pub enum LangAction {
    /// List all supported languages.
    List,
    /// Describe the predicates available for a specific language.
    Describe { language: String },
}

#[derive(Parser, Debug)]
pub struct PresetArgs {
    #[command(subcommand)]
    pub action: PresetAction,
}

#[derive(Subcommand, Debug, Clone)]
pub enum PresetAction {
    /// List all available presets.
    List,
    /// Add or update a preset in the global config file.
    Add {
        #[arg(required = true)]
        name: String,
        #[arg(required = true)]
        query: String,
    },
    /// Remove a preset from the global config file.
    Remove {
        #[arg(required = true)]
        name: String,
    },
}

#[derive(Debug, Clone, ValueEnum)]
pub enum Format {
    /// Show only the specific code blocks ("hunks") that match a semantic query
    Hunks,
    /// Human-readable markdown with file headers
    Markdown,
    /// Machine-readable JSON
    Json,
    /// A simple list of matching file paths
    Paths,
    /// Raw concatenated file content, for piping
    Cat,
    /// `ls`-like output with file metadata
    Find,
}

/// The main entry point.
/// Its only job is to parse the CLI and delegate to the correct command module.
fn main() -> Result<()> {
    let cli = Cli::parse();

    match cli.command {
        Commands::Search(args) => run_search(args),
        Commands::Lang(args) => {
            // Default to `list` if no subcommand is given for `lang`
            let action = args.action.unwrap_or(LangAction::List);
            run_lang(action)
        }
        Commands::Preset(args) => run_preset(args.action),
    }
}
```

### `rdump/commands/search.rs`
```rust
use crate::{config, ColorChoice, SearchArgs};
use anyhow::anyhow;
use anyhow::Result;
use atty::Stream;
use ignore::WalkBuilder;
use rayon::prelude::*;
use std::fs::File;
use std::io::{self, Write};
use std::path::PathBuf;
use tempfile::NamedTempFile;
use tree_sitter::Range;

use crate::evaluator::{Evaluator, FileContext, MatchResult};
use crate::formatter;
use crate::parser;
use crate::predicates;

/// The main entry point for the `search` command.
pub fn run_search(mut args: SearchArgs) -> Result<()> {
    // --- Handle Shorthand Flags ---
    if args.no_headers {
        args.format = crate::Format::Cat;
    }
    if args.find {
        args.format = crate::Format::Find;
    }

    // --- Load Config and Build Query ---
    let config = config::load_config()?;
    let mut final_query = args.query.take().unwrap_or_default();

    for preset_name in args.preset.iter().rev() {
        let preset_query = config
            .presets
            .get(preset_name)
            .ok_or_else(|| anyhow!("Preset '{}' not found", preset_name))?;

        if final_query.is_empty() {
            final_query = format!("({preset_query})");
        } else {
            final_query = format!("({preset_query}) & {final_query}");
        }
    }

    if final_query.is_empty() {
        return Err(anyhow!(
            "Empty query. Provide a query string or use a preset."
        ));
    }

    // --- 1. Find initial candidates ---
    let candidate_files =
        get_candidate_files(&args.root, args.no_ignore, args.hidden, args.max_depth)?;

    // --- 2. Parse query ---
    let ast = parser::parse_query(&final_query)?;

    // --- 3. Pre-filtering Pass (Metadata) ---
    // This pass uses an evaluator with only fast metadata predicates.
    // It quickly reduces the number of files needing full evaluation.
    let metadata_registry = predicates::create_metadata_predicate_registry();
    let pre_filter_evaluator = Evaluator::new(ast.clone(), metadata_registry);

    let pre_filtered_files: Vec<PathBuf> = candidate_files
        .into_iter() // This pass is not parallel, it's fast enough.
        .filter(|path| {
            let mut context = FileContext::new(path.clone());
            match pre_filter_evaluator.evaluate(&mut context) {
                Ok(result) => result.is_match(),
                Err(e) => {
                    eprintln!("Error during pre-filter on {}: {}", path.display(), e);
                    false
                }
            }
        })
        .collect();

    // --- Determine if color should be used ---
    let use_color = match args.color {
        ColorChoice::Always => true,
        ColorChoice::Never => false,
        ColorChoice::Auto => atty::is(Stream::Stdout),
    };

    // --- 4. Main Evaluation Pass (Content + Semantic) ---
    // This pass uses the full evaluator on the smaller, pre-filtered set of files.
    let full_registry = predicates::create_predicate_registry();
    let evaluator = Evaluator::new(ast, full_registry);

    let mut matching_files: Vec<(PathBuf, Vec<Range>)> = pre_filtered_files
        .par_iter()
        .filter_map(|path| {
            let mut context = FileContext::new(path.clone());
            match evaluator.evaluate(&mut context) {
                Ok(MatchResult::Boolean(true)) => Some((path.clone(), Vec::new())),
                Ok(MatchResult::Boolean(false)) => None,
                Ok(MatchResult::Hunks(hunks)) => {
                    if hunks.is_empty() {
                        None
                    } else {
                        Some((path.clone(), hunks))
                    }
                }
                Err(e) => {
                    eprintln!("Error evaluating file {}: {}", path.display(), e);
                    None
                }
            }
        })
        .collect();

    matching_files.sort_by(|a, b| a.0.cmp(&b.0));

    // --- 5. Format and print results ---
    let mut writer: Box<dyn Write> = if let Some(output_path) = &args.output {
        Box::new(File::create(output_path)?)
    } else {
        Box::new(io::stdout())
    };

    formatter::print_output(
        &mut writer,
        &matching_files,
        &args.format,
        args.line_numbers,
        args.no_headers,
        use_color,
        args.context.unwrap_or(0),
    )?;

    Ok(())
}

/// Walks the directory, respecting .gitignore, and applies our own smart defaults.
fn get_candidate_files(
    root: &PathBuf,
    no_ignore: bool,
    hidden: bool,
    max_depth: Option<usize>,
) -> Result<Vec<PathBuf>> {
    let mut files = Vec::new();
    let mut walker_builder = WalkBuilder::new(root);

    walker_builder.hidden(!hidden).max_depth(max_depth);

    if no_ignore {
        // If --no-ignore is passed, disable everything.
        walker_builder
            .ignore(false)
            .git_ignore(false)
            .git_global(false)
            .git_exclude(false);
    } else {
        // Layer 1: Our "sane defaults". These have the lowest precedence.
        let default_ignores = "
           # Default rdump ignores
           node_modules/
           target/
           dist/
           build/
           .git/
           .svn/
           .hg/
           *.pyc
           __pycache__/
       ";
        let mut temp_ignore = NamedTempFile::new()?;
        write!(temp_ignore, "{default_ignores}")?;
        walker_builder.add_ignore(temp_ignore.path());

        // Layer 2: A user's custom global ignore file.
        if let Some(global_ignore_path) = dirs::config_dir().map(|p| p.join("rdump/ignore")) {
            if global_ignore_path.exists() {
                if let Some(err) = walker_builder.add_ignore(global_ignore_path) {
                    eprintln!("Warning: could not add global ignore file: {err}");
                }
            }
        }

        // Layer 3: A user's custom project-local .rdumpignore file.
        walker_builder.add_custom_ignore_filename(".rdumpignore");

        // Layer 4: Standard .gitignore files.
        walker_builder.git_global(true);
        walker_builder.git_ignore(true);
    }

    for result in walker_builder.build() {
        let entry = result?;
        if entry.file_type().is_some_and(|ft| ft.is_file()) {
            files.push(entry.into_path());
        }
    }
    Ok(files)
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs;
    use std::io::Write;
    use tempfile::tempdir;

    fn get_sorted_file_names(
        root: &PathBuf,
        no_ignore: bool,
        hidden: bool,
        max_depth: Option<usize>,
    ) -> Vec<String> {
        let mut paths = get_candidate_files(root, no_ignore, hidden, max_depth).unwrap();
        paths.sort();
        paths
            .into_iter()
            .map(|p| {
                p.strip_prefix(root)
                    .unwrap()
                    .to_string_lossy()
                    .replace('\\', "/")
            })
            .collect()
    }

    #[test]
    fn test_custom_rdumpignore_file() {
        let dir = tempdir().unwrap();
        let root = dir.path();
        let mut ignore_file = fs::File::create(root.join(".rdumpignore")).unwrap();
        writeln!(ignore_file, "*.log").unwrap();
        fs::File::create(root.join("app.js")).unwrap();
        fs::File::create(root.join("app.log")).unwrap();

        let files = get_sorted_file_names(&root.to_path_buf(), false, false, None);
        assert_eq!(files, vec!["app.js"]);
    }

    #[test]
    fn test_unignore_via_rdumpignore() {
        let dir = tempdir().unwrap();
        let root = dir.path();

        let node_modules = root.join("node_modules");
        fs::create_dir(&node_modules).unwrap();
        fs::File::create(node_modules.join("some_dep.js")).unwrap();
        fs::File::create(root.join("app.js")).unwrap();

        let mut ignore_file = fs::File::create(root.join(".rdumpignore")).unwrap();
        writeln!(ignore_file, "!node_modules/").unwrap();

        let files = get_sorted_file_names(&root.to_path_buf(), false, false, None);
        assert_eq!(files.len(), 2);
        assert!(files.contains(&"app.js".to_string()));
        assert!(files.contains(
            &"node_modules/some_dep.js"
                .to_string()
                .replace('/', &std::path::MAIN_SEPARATOR.to_string())
        ));
    }
}
```

### `rdump/evaluator.rs`
```rust
use anyhow::{anyhow, Context, Result};
use std::collections::HashMap;
use std::fs;
use std::path::PathBuf;
use tree_sitter::{Parser, Range, Tree};

use crate::parser::{AstNode, LogicalOperator, PredicateKey};
use crate::predicates::PredicateEvaluator;

/// The result of an evaluation for a single file.
#[derive(Debug, Clone)]
pub enum MatchResult {
    // For simple, non-hunkable predicates like `ext:rs` or `size:>10kb`
    Boolean(bool),
    // For code-aware predicates that can identify specific code blocks.
    Hunks(Vec<Range>),
}

/// Holds the context for a single file being evaluated.
/// It lazily loads content and caches the tree-sitter AST.
pub struct FileContext {
    pub path: PathBuf,
    content: Option<String>,
    // Cache for the parsed tree-sitter AST
    tree: Option<Tree>,
}

impl FileContext {
    pub fn new(path: PathBuf) -> Self {
        FileContext {
            path,
            content: None,
            tree: None,
        }
    }

    pub fn get_content(&mut self) -> Result<&str> {
        if self.content.is_none() {
            let content = fs::read_to_string(&self.path)
                .with_context(|| format!("Failed to read file {}", self.path.display()))?;
            self.content = Some(content);
        }
        Ok(self.content.as_ref().unwrap())
    }

    // Lazily parses the file with tree-sitter and caches the result.
    pub fn get_tree(&mut self, language: tree_sitter::Language) -> Result<&Tree> {
        if self.tree.is_none() {
            let path_display = self.path.display().to_string();
            let content = self.get_content()?;
            let mut parser = Parser::new();
            parser.set_language(&language).with_context(|| {
                format!("Failed to set language for tree-sitter parser on {path_display}")
            })?;
            let tree = parser
                .parse(content, None)
                .ok_or_else(|| anyhow!("Tree-sitter failed to parse {}", path_display))?;
            self.tree = Some(tree);
        }
        Ok(self.tree.as_ref().unwrap())
    }
}

/// The main evaluator struct. It holds the AST and the predicate registry.
pub struct Evaluator {
    ast: AstNode,
    registry: HashMap<PredicateKey, Box<dyn PredicateEvaluator + Send + Sync>>,
}

impl Evaluator {
    pub fn new(
        ast: AstNode,
        registry: HashMap<PredicateKey, Box<dyn PredicateEvaluator + Send + Sync>>,
    ) -> Self {
        Evaluator { ast, registry }
    }

    /// Evaluates the query for a given file path.
    pub fn evaluate(&self, context: &mut FileContext) -> Result<MatchResult> {
        self.evaluate_node(&self.ast, context)
    }

    /// Recursively evaluates an AST node.
    fn evaluate_node(&self, node: &AstNode, context: &mut FileContext) -> Result<MatchResult> {
        match node {
            AstNode::Predicate(key, value) => self.evaluate_predicate(key, value, context),
            AstNode::LogicalOp(op, left, right) => {
                let left_res = self.evaluate_node(left, context)?;

                // Short-circuit AND if left is false
                if *op == LogicalOperator::And && !left_res.is_match() {
                    return Ok(MatchResult::Boolean(false));
                }

                // Short-circuit OR if left is a full-file match
                if *op == LogicalOperator::Or {
                    if let MatchResult::Boolean(true) = left_res {
                        return Ok(left_res);
                    }
                }

                let right_res = self.evaluate_node(right, context)?;
                Ok(left_res.combine_with(right_res, op))
            }
            AstNode::Not(inner_node) => {
                // If the inner predicate of a NOT is not in the registry (e.g., a content
                // predicate during the metadata-only pass), we cannot definitively say the file
                // *doesn't* match. We must assume it *could* match and let the full evaluator decide.
                if let AstNode::Predicate(key, _) = &**inner_node {
                    if !self.registry.contains_key(key) {
                        return Ok(MatchResult::Boolean(true));
                    }
                }
                let result = self.evaluate_node(inner_node, context)?;
                Ok(MatchResult::Boolean(!result.is_match()))
            }
        }
    }

    /// Evaluates a single predicate.
    fn evaluate_predicate(
        &self,
        key: &PredicateKey,
        value: &str,
        context: &mut FileContext,
    ) -> Result<MatchResult> {
        if let Some(evaluator) = self.registry.get(key) {
            evaluator.evaluate(context, key, value)
        } else {
            // If a predicate is not in the current registry (e.g., a content predicate
            // during the metadata-only pass), it's considered a "pass" for this stage.
            Ok(MatchResult::Boolean(true))
        }
    }
}

impl MatchResult {
    /// Returns true if the result is considered a match.
    pub fn is_match(&self) -> bool {
        match self {
            MatchResult::Boolean(b) => *b,
            MatchResult::Hunks(h) => !h.is_empty(),
        }
    }

    /// Combines two match results based on a logical operator.
    pub fn combine_with(self, other: MatchResult, op: &LogicalOperator) -> Self {
        match op {
            LogicalOperator::And => {
                if !self.is_match() || !other.is_match() {
                    return MatchResult::Boolean(false);
                }
                match (self, other) {
                    (MatchResult::Hunks(mut a), MatchResult::Hunks(b)) => {
                        a.extend(b);
                        a.sort_by_key(|r| r.start_byte);
                        a.dedup();
                        MatchResult::Hunks(a)
                    }
                    (h @ MatchResult::Hunks(_), MatchResult::Boolean(true)) => h,
                    (MatchResult::Boolean(true), h @ MatchResult::Hunks(_)) => h,
                    (MatchResult::Boolean(true), MatchResult::Boolean(true)) => MatchResult::Boolean(true),
                    _ => MatchResult::Boolean(false),
                }
            }
            LogicalOperator::Or => {
                match (self, other) {
                    (MatchResult::Boolean(true), _) | (_, MatchResult::Boolean(true)) => MatchResult::Boolean(true),
                    (MatchResult::Hunks(mut a), MatchResult::Hunks(b)) => {
                        a.extend(b);
                        a.sort_by_key(|r| r.start_byte);
                        a.dedup();
                        MatchResult::Hunks(a)
                    }
                    (h @ MatchResult::Hunks(_), MatchResult::Boolean(false)) => h,
                    (MatchResult::Boolean(false), h @ MatchResult::Hunks(_)) => h,
                    (MatchResult::Boolean(false), MatchResult::Boolean(false)) => MatchResult::Boolean(false),
                }
            }
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::parser::{parse_query, LogicalOperator};
    use crate::predicates;
    use std::io::Write;
    use tempfile::NamedTempFile;

    fn create_temp_file(content: &str) -> NamedTempFile {
        let file = NamedTempFile::new().unwrap();
        write!(file.as_file(), "{}", content).unwrap();
        file
    }

    #[test]
    fn test_combine_with_hunks_and() {
        let hunks1 = vec![Range { start_byte: 10, end_byte: 20, ..Default::default() }];
        let hunks2 = vec![Range { start_byte: 30, end_byte: 40, ..Default::default() }];
        let result1 = MatchResult::Hunks(hunks1);
        let result2 = MatchResult::Hunks(hunks2);
        
        let combined = result1.combine_with(result2, &LogicalOperator::And);
        
        if let MatchResult::Hunks(h) = combined {
            assert_eq!(h.len(), 2);
            assert_eq!(h[0].start_byte, 10);
            assert_eq!(h[1].start_byte, 30);
        } else {
            panic!("Expected Hunks result");
        }
    }

    #[test]
    fn test_combine_with_hunks_or() {
        let hunks1 = vec![Range { start_byte: 10, end_byte: 20, ..Default::default() }];
        let hunks2 = vec![Range { start_byte: 30, end_byte: 40, ..Default::default() }];
        let result1 = MatchResult::Hunks(hunks1);
        let result2 = MatchResult::Hunks(hunks2);
        
        let combined = result1.combine_with(result2, &LogicalOperator::Or);
        
        if let MatchResult::Hunks(h) = combined {
            assert_eq!(h.len(), 2);
        } else {
            panic!("Expected Hunks result");
        }
    }
}
```

### `predicates/code_aware/mod.rs`
```rust
use crate::evaluator::{FileContext, MatchResult};
use crate::parser::PredicateKey;
use crate::predicates::PredicateEvaluator;
use anyhow::{anyhow, Context, Result};
use tree_sitter::{Query, QueryCursor};

pub mod profiles;

/// The evaluator that uses tree-sitter to perform code-aware queries.
#[derive(Debug, Clone)]
pub struct CodeAwareEvaluator;

impl PredicateEvaluator for CodeAwareEvaluator {
    fn evaluate(
        &self,
        context: &mut FileContext,
        key: &PredicateKey,
        value: &str,
    ) -> Result<MatchResult> {
        // 1. Determine the language from the file extension.
        let extension = context
            .path
            .extension()
            .and_then(|s| s.to_str())
            .unwrap_or("");
        let binding = profiles::list_language_profiles();
        let profile = match binding.iter().find(|p| p.extensions.contains(&extension)) {
            Some(p) => p,
            None => return Ok(MatchResult::Boolean(false)), // Not a supported language for this predicate.
        };

        // 2. Get the tree-sitter query string for the specific predicate.
        let ts_query_str = match profile.queries.get(key) {
            Some(q) if !q.is_empty() => q,
            _ => return Ok(MatchResult::Boolean(false)), // This predicate is not implemented for this language yet.
        };

        // 3. Get content and lazily get the parsed tree from the file context.
        let content = context.get_content()?.to_string(); // Clone to avoid borrow issues
        let tree = match context.get_tree(profile.language.clone()) {
            Ok(tree) => tree,
            Err(e) => {
                eprintln!(
                    "Warning: Failed to parse {}: {}. Skipping.",
                    context.path.display(),
                    e
                );
                return Ok(MatchResult::Boolean(false));
            }
        };

        // 4. Compile the tree-sitter query.
        let query = Query::new(&profile.language, ts_query_str)
            .with_context(|| format!("Failed to compile tree-sitter query for key {key:?}"))?;
        let mut cursor = QueryCursor::new();
        let mut ranges = Vec::new();

        // 5. Execute the query and check for a match.
        let captures = cursor.matches(&query, tree.root_node(), content.as_bytes());

        for m in captures {
            for capture in m.captures {
                // We only care about nodes captured with the name `@match`.
                let capture_name = &query.capture_names()[capture.index as usize];
                if *capture_name != "match" {
                    continue;
                }
                
                let captured_node = capture.node;
                let captured_text = captured_node.utf8_text(content.as_bytes())?;

                // Use the correct matching strategy based on the predicate type.
                let is_match = match key {
                    // Content-based predicates check for substrings.
                    PredicateKey::Import | PredicateKey::Comment | PredicateKey::Str => {
                        captured_text.contains(value)
                    }
                    // Definition-based predicates require an exact match on the identifier, unless a wildcard is used.
                    _ => value == "." || captured_text == value,
                };

                if is_match {
                    ranges.push(captured_node.range());
                }
            }
        }

        Ok(MatchResult::Hunks(ranges))
    }
}
```

### `predicates/helpers.rs`
```rust
use anyhow::{anyhow, Result};
use std::time::{Duration, SystemTime};

pub(super) fn parse_and_compare_size(file_size: u64, query: &str) -> Result<bool> {
    let query = query.trim();
    let (op, size_str) = if query.starts_with(['>', '<', '=']) {
        query.split_at(1)
    } else {
        ("=", query)
    };

    let target_size = size_str
        .trim()
        .to_lowercase()
        .replace("kb", " * 1024")
        .replace('k', " * 1024")
        .replace("mb", " * 1024 * 1024")
        .replace('m', " * 1024 * 1024")
        .replace("gb", " * 1024 * 1024 * 1024")
        .replace('g', " * 1024 * 1024 * 1024")
        .replace('b', "");

    // A simple expression evaluator for "N * N * N..."
    let target_size_bytes = target_size
        .split('*')
        .map(|s| s.trim().parse::<f64>())
        .collect::<Result<Vec<f64>, _>>()?
        .into_iter()
        .product::<f64>() as u64;

    match op {
        ">" => Ok(file_size > target_size_bytes),
        "<" => Ok(file_size < target_size_bytes),
        "=" => Ok(file_size == target_size_bytes),
        _ => Err(anyhow!("Invalid size operator: {}", op)),
    }
}

pub(super) fn parse_and_compare_time(modified_time: SystemTime, query: &str) -> Result<bool> {
    let now = SystemTime::now();
    let (op, duration_str) = query.split_at(1);
    let duration_str = duration_str.trim();

    let duration_secs = if let Some(num_str) = duration_str.strip_suffix('s') {
        num_str.parse::<u64>()?
    } else if let Some(num_str) = duration_str.strip_suffix('m') {
        num_str.parse::<u64>()? * 60
    } else if let Some(num_str) = duration_str.strip_suffix('h') {
        num_str.parse::<u64>()? * 3600
    } else if let Some(num_str) = duration_str.strip_suffix('d') {
        num_str.parse::<u64>()? * 86400
    } else {
        return Err(anyhow!("Invalid time unit in '{}'", query));
    };

    let duration = Duration::from_secs(duration_secs);
    let threshold_time = now
        .checked_sub(duration)
        .ok_or(anyhow!("Time calculation underflow"))?;

    match op {
        ">" => Ok(modified_time > threshold_time), // Modified more recently than
        "<" => Ok(modified_time < threshold_time), // Modified longer ago than
        _ => Err(anyhow!("Invalid time operator: {}", op)),
    }
}
```

(The rest of the files are unchanged from the previous version and remain correct).