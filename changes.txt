You're asking all the right questions. The previous changes addressed correctness and modern idioms. Now, let's focus on the next major leaps forward: a significant performance optimization and a critical new feature for usability.

Yes, there are still major improvements to be made. Here is my feedback and the corresponding code changes.

### 1. Architectural & Performance: Two-Phase Evaluation

This is the single most impactful performance optimization you can make.

**The Problem:** The current process evaluates the *entire* query for *every single* candidate file. For a query like `ext:rs & contains:'MyStruct'`, it needlessly reads the content of every non-`.rs` file, even though they are guaranteed to fail the `ext:rs` check.

**The Solution:** We can split the evaluation into two phases:

1.  **Pre-filter (Metadata):** A very fast, non-parallel first pass that runs *only* the metadata-based predicates (`ext`, `name`, `path`, `size`, `modified`). This pass doesn't read file contents and quickly culls the vast majority of non-matching files.
2.  **Full Evaluation (Content):** The expensive, parallel second pass that reads file content and runs content/semantic predicates, but *only* on the much smaller set of files that passed the pre-filter.

This requires a few architectural changes: the `Evaluator` will now be created with a specific `PredicateRegistry`, and the search command will orchestrate the two-phase process.

Here are the complete code changes to implement this.

---

### `rdump/parser.rs`

The `AstNode` needs to be cloneable because it will be used by both the pre-filtering evaluator and the main evaluator.

```rust
use anyhow::{anyhow, Result};
use pest::iterators::Pair;
use pest::Parser;
use pest_derive::Parser;

#[derive(Parser)]
#[grammar = "rql.pest"]
pub struct RqlParser;

#[derive(Debug, PartialEq, Eq, Hash, Clone)]
pub enum PredicateKey {
    Ext,
    Name,
    Path,
    Contains,
    Matches,
    Size,
    Modified,
    // --- SEMANTIC PREDICATES ---
    // Generic
    Def,
    Func,
    Import,
    // Granular Definitions
    Class,
    Struct,
    Enum,
    Interface,
    Trait,
    Type,
    // Syntactic Content
    Comment,
    Str,
   // Usage
   Call,
    // A key for testing or unknown predicates
    Other(String),
}

impl AsRef<str> for PredicateKey {
   fn as_ref(&self) -> &str {
       match self {
           PredicateKey::Ext => "ext",
           PredicateKey::Name => "name",
           PredicateKey::Path => "path",
           PredicateKey::Contains => "contains",
           PredicateKey::Matches => "matches",
           PredicateKey::Size => "size",
           PredicateKey::Modified => "modified",
           PredicateKey::Def => "def",
           PredicateKey::Func => "func",
           PredicateKey::Import => "import",
           PredicateKey::Class => "class",
           PredicateKey::Struct => "struct",
           PredicateKey::Enum => "enum",
           PredicateKey::Interface => "interface",
           PredicateKey::Trait => "trait",
           PredicateKey::Type => "type",
           PredicateKey::Comment => "comment",
           PredicateKey::Str => "str",
           PredicateKey::Call => "call",
           PredicateKey::Other(s) => s.as_str(),
       }
   }
}

impl From<&str> for PredicateKey {
    fn from(s: &str) -> Self {
        match s {
            "ext" => Self::Ext,
            "name" => Self::Name,
            "path" => Self::Path,
            "contains" => Self::Contains,
            "matches" => Self::Matches,
            "size" => Self::Size,
            "modified" => Self::Modified,
            // --- SEMANTIC ---
            "def" => Self::Def,
            "func" => Self::Func,
            "import" => Self::Import,
            "class" => Self::Class,
            "struct" => Self::Struct,
            "enum" => Self::Enum,
            "interface" => Self::Interface,
            "trait" => Self::Trait,
            "type" => Self::Type,
            "comment" => Self::Comment,
            "str" => Self::Str,
           "call" => Self::Call,
            // Any other key is captured here.
            other => Self::Other(other.to_string()),
        }
    }
}

#[derive(Debug, PartialEq, Clone)]
pub enum AstNode {
    Predicate(PredicateKey, String),
    LogicalOp(LogicalOperator, Box<AstNode>, Box<AstNode>),
    Not(Box<AstNode>),
}

#[derive(Debug, PartialEq, Clone)]
pub enum LogicalOperator {
    And,
    Or,
}

pub fn parse_query(query: &str) -> Result<AstNode> {
   // Check for empty or whitespace-only queries BEFORE parsing.
   if query.trim().is_empty() {
       return Err(anyhow!("Query cannot be empty."));
   }

   match RqlParser::parse(Rule::query, query) {
       Ok(pairs) => build_ast_from_pairs(pairs.peek().unwrap()),
       Err(e) => {
           // Re-format the pest error to be more user-friendly.
           Err(anyhow!("Invalid query syntax:\n{}", e))
       }
   }
}

fn build_ast_from_pairs(pair: Pair<Rule>) -> Result<AstNode> {
    match pair.as_rule() {
        Rule::query => build_ast_from_pairs(pair.into_inner().next().unwrap()),
        Rule::expression | Rule::logical_or | Rule::logical_and => build_ast_from_logical_op(pair),
        Rule::term => {
            let mut inner = pair.into_inner();
            let first = inner.next().unwrap();
            if first.as_rule() == Rule::NOT {
                let factor = inner.next().unwrap();
                let ast = build_ast_from_pairs(factor)?;
                Ok(AstNode::Not(Box::new(ast)))
            } else {
                build_ast_from_pairs(first)
            }
        }
        Rule::factor => build_ast_from_pairs(pair.into_inner().next().unwrap()),
        Rule::predicate => {
            let mut predicate_parts = pair.into_inner();
            let key_pair = predicate_parts.next().unwrap();
            let value_pair = predicate_parts.next().unwrap();
            let key = PredicateKey::from(key_pair.as_str());
            let value = unescape_value(value_pair.as_str());
            Ok(AstNode::Predicate(key, value))
        }
        _ => Err(anyhow!("Unknown rule: {:?}", pair.as_rule())),
    }
}

fn build_ast_from_logical_op(pair: Pair<Rule>) -> Result<AstNode> {
    let mut inner_pairs = pair.into_inner();
    let mut ast = build_ast_from_pairs(inner_pairs.next().unwrap())?;

    while let Some(op_pair) = inner_pairs.next() {
        let op = match op_pair.as_str() {
            "&" => LogicalOperator::And,
            "|" => LogicalOperator::Or,
            _ => unreachable!(),
        };
        let right_pair = inner_pairs.next().unwrap();
        let right_ast = build_ast_from_pairs(right_pair)?;
        ast = AstNode::LogicalOp(op, Box::new(ast), Box::new(right_ast));
    }
    Ok(ast)
}

fn unescape_value(value: &str) -> String {
    if value.starts_with('"') && value.ends_with('"') {
        return value[1..value.len() - 1].replace("\"", "\"");
    }
    if value.starts_with('\'') && value.ends_with('\'') {
        return value[1..value.len() - 1].replace("\\'", "\'");
    }
    value.to_string()
}

#[cfg(test)]
mod tests {
    use super::*;

    // Helper to create a predicate node for cleaner tests.
    fn predicate(key: PredicateKey, value: &str) -> Box<AstNode> {
        Box::new(AstNode::Predicate(key, value.to_string()))
    }

    #[test]
    fn test_parse_simple_predicate() {
        let ast = parse_query("ext:rs").unwrap();
        assert_eq!(ast, *predicate(PredicateKey::Ext, "rs"));
    }

    #[test]
    fn test_parse_predicate_with_quoted_value() {
        let ast = parse_query("name:\"foo bar\"").unwrap();
        assert_eq!(ast, *predicate(PredicateKey::Name, "foo bar"));
    }

    #[test]
    fn test_parse_logical_and() {
        let ast = parse_query("ext:rs & name:\"foo\"").unwrap();
        assert_eq!(
            ast,
            AstNode::LogicalOp(
                LogicalOperator::And,
                predicate(PredicateKey::Ext, "rs"),
                predicate(PredicateKey::Name, "foo")
            )
        );
    }

    #[test]
    fn test_parse_logical_or() {
        let ast = parse_query("ext:rs | ext:toml").unwrap();
        assert_eq!(
            ast,
            AstNode::LogicalOp(
                LogicalOperator::Or,
                predicate(PredicateKey::Ext, "rs"),
                predicate(PredicateKey::Ext, "toml")
            )
        );
    }

    #[test]
    fn test_parse_negation() {
        let ast = parse_query("!ext:rs").unwrap();
        assert_eq!(ast, AstNode::Not(predicate(PredicateKey::Ext, "rs")));
    }

    #[test]
    fn test_parse_complex_query() {
        let ast = parse_query("ext:rs & (name:\"foo\" | name:\"bar\") & !path:tests").unwrap();
        let inner_or = AstNode::LogicalOp(
            LogicalOperator::Or,
            predicate(PredicateKey::Name, "foo"),
            predicate(PredicateKey::Name, "bar"),
        );
        let and_with_or = AstNode::LogicalOp(
            LogicalOperator::And,
            predicate(PredicateKey::Ext, "rs"),
            Box::new(inner_or),
        );
        let final_ast = AstNode::LogicalOp(
            LogicalOperator::And,
            Box::new(and_with_or),
            Box::new(AstNode::Not(predicate(PredicateKey::Path, "tests"))),
        );
        assert_eq!(ast, final_ast);
    }

    #[test]
    fn test_unescape_value() {
        assert_eq!(unescape_value(r#""hello "world"""#), "hello \"world\"");
        assert_eq!(unescape_value(r#"'hello 'world''"#), "hello 'world'");
        assert_eq!(unescape_value("no_quotes"), "no_quotes");
    }

    #[test]
    fn test_parse_predicate_with_special_chars_in_value() {
        let ast = parse_query(r#"name:"foo&bar""#).unwrap();
        assert_eq!(ast, *predicate(PredicateKey::Name, "foo&bar"));
    }

    #[test]
    fn test_parse_semantic_predicates() {
        let ast_def = parse_query("def:User").unwrap();
        assert_eq!(ast_def, *predicate(PredicateKey::Def, "User"));

        let ast_func = parse_query("func:get_user").unwrap();
        assert_eq!(ast_func, *predicate(PredicateKey::Func, "get_user"));

        let ast_import = parse_query("import:serde").unwrap();
        assert_eq!(ast_import, *predicate(PredicateKey::Import, "serde"));
    }

   #[test]
   fn test_parse_granular_and_syntactic_predicates() {
       assert_eq!(parse_query("class:Foo").unwrap(), *predicate(PredicateKey::Class, "Foo"));
       assert_eq!(parse_query("struct:Bar").unwrap(), *predicate(PredicateKey::Struct, "Bar"));
       assert_eq!(parse_query("comment:TODO").unwrap(), *predicate(PredicateKey::Comment, "TODO"));
       assert_eq!(parse_query("str:'api_key'").unwrap(), *predicate(PredicateKey::Str, "api_key"));
       assert_eq!(parse_query("call:my_func").unwrap(), *predicate(PredicateKey::Call, "my_func"));
   }

   #[test]
   fn test_error_on_trailing_operator() {
       let result = parse_query("ext:rs &");
       let err = result.unwrap_err();
       assert!(err.to_string().contains("Invalid query syntax:"));
       assert!(err.to_string().contains("expected")); // Pest's pointer is still useful
   }

   #[test]
   fn test_error_on_missing_value() {
       let result = parse_query("ext:");
       let err = result.unwrap_err();
       assert!(err.to_string().contains("Invalid query syntax:"));
   }

   #[test]
   fn test_error_on_unclosed_parenthesis() {
       let result = parse_query("(ext:rs | path:src");
       let err = result.unwrap_err();
       assert!(err.to_string().contains("Invalid query syntax:"));
   }

   #[test]
   fn test_error_on_empty_query() {
       let result = parse_query("");
       assert_eq!(result.unwrap_err().to_string(), "Query cannot be empty.");
   }

   #[test]
   fn test_error_on_whitespace_query() {
       let result = parse_query("   ");
       assert_eq!(result.unwrap_err().to_string(), "Query cannot be empty.");
   }
}
```

### `rdump/predicates/mod.rs`

We'll add a new function to create a registry with *only* the fast, metadata-based evaluators.

```rust
pub mod code_aware;
pub mod contains;
pub mod ext;
mod helpers;
pub mod matches;
pub mod modified;
pub mod name;
pub mod path;
pub mod size;

use self::code_aware::CodeAwareEvaluator;
use self::contains::ContainsEvaluator;
use self::ext::ExtEvaluator;
use self::matches::MatchesEvaluator;
use self::modified::ModifiedEvaluator;
use self::name::NameEvaluator;
use self::path::PathEvaluator;
use self::size::SizeEvaluator;
use crate::evaluator::{FileContext, MatchResult};
use crate::parser::PredicateKey;
use anyhow::Result;
use std::collections::HashMap;

// The core trait that all predicate evaluators must implement.
pub trait PredicateEvaluator {
    // The key is now passed to allow one evaluator to handle multiple predicate types.
    fn evaluate(&self, context: &mut FileContext, key: &PredicateKey, value: &str) -> Result<MatchResult>;
}

/// Creates a predicate registry with only the fast, metadata-based predicates.
/// This is used for the pre-filtering pass.
pub fn create_metadata_predicate_registry() -> HashMap<PredicateKey, Box<dyn PredicateEvaluator + Send + Sync>> {
    let mut registry: HashMap<PredicateKey, Box<dyn PredicateEvaluator + Send + Sync>> =
        HashMap::new();

    registry.insert(PredicateKey::Ext, Box::new(ExtEvaluator));
    registry.insert(PredicateKey::Name, Box::new(NameEvaluator));
    registry.insert(PredicateKey::Path, Box::new(PathEvaluator));
    registry.insert(PredicateKey::Size, Box::new(SizeEvaluator));
    registry.insert(PredicateKey::Modified, Box::new(ModifiedEvaluator));

    registry
}

/// Creates and populates the complete predicate registry.
pub fn create_predicate_registry() -> HashMap<PredicateKey, Box<dyn PredicateEvaluator + Send + Sync>> {
    // Start with the metadata predicates
    let mut registry = create_metadata_predicate_registry();

    // Add content-based predicates
    registry.insert(PredicateKey::Contains, Box::new(ContainsEvaluator));
    registry.insert(PredicateKey::Matches, Box::new(MatchesEvaluator));

    // Register the single CodeAwareEvaluator for all semantic predicate keys.
    let code_evaluator = Box::new(CodeAwareEvaluator);
    registry.insert(PredicateKey::Def, code_evaluator.clone());
    registry.insert(PredicateKey::Func, code_evaluator.clone());
    registry.insert(PredicateKey::Import, code_evaluator.clone());
    registry.insert(PredicateKey::Class, code_evaluator.clone());
    registry.insert(PredicateKey::Struct, code_evaluator.clone());
    registry.insert(PredicateKey::Enum, code_evaluator.clone());
    registry.insert(PredicateKey::Interface, code_evaluator.clone());
    registry.insert(PredicateKey::Trait, code_evaluator.clone());
    registry.insert(PredicateKey::Type, code_evaluator.clone());
    registry.insert(PredicateKey::Comment, code_evaluator.clone());
    registry.insert(PredicateKey::Str, code_evaluator.clone());
    registry.insert(PredicateKey::Call, code_evaluator);

    registry
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::io::Write;

    // The `code_aware` suite remains here as it tests the interaction
    // of multiple profiles, which is a responsibility of this parent module.
    #[test]
    fn test_code_aware_evaluator_full_rust_suite() {
        let rust_code = r#"
            // TODO: refactor this module
            use std::collections::HashMap;

            type ConfigMap = HashMap<String, String>;

            pub struct AppConfig {}
            pub trait Runnable {
                fn run(&self);
            }
            fn launch_app() {
                let msg = "Launching...";
                println!("{}", msg);
            }
        "#;

        let temp_dir = tempfile::tempdir().unwrap();
        let file_path = temp_dir.path().join("complex.rs");
        let mut file = std::fs::File::create(&file_path).unwrap();
        file.write_all(rust_code.as_bytes()).unwrap();

        let evaluator = CodeAwareEvaluator;

        // --- Granular Defs ---
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Struct, "AppConfig")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Trait, "Runnable")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Type, "ConfigMap")
            .unwrap()
            .is_match());

        // --- Functions ---
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Func, "run")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Func, "launch_app")
            .unwrap()
            .is_match());

        // --- Calls ---
        let mut ctx = FileContext::new(file_path.clone());
        assert!(
            evaluator
                .evaluate(&mut ctx, &PredicateKey::Call, "println")
                .unwrap()
                .is_match(),
            "Should find function call"
        );
        let mut ctx = FileContext::new(file_path.clone());
        assert!(
            !evaluator
                .evaluate(&mut ctx, &PredicateKey::Call, "launch_app")
                .unwrap()
                .is_match(),
            "Should not find the definition as a call"
        );

        // --- Syntactic Content ---
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Comment, "TODO")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Str, "Launching...")
            .unwrap()
            .is_match());
    }

    #[test]
    fn test_code_aware_evaluator_python_suite() {
        let python_code = r#"
# FIXME: use a real database
import os

class DataProcessor:
    def __init__(self):
        self.api_key = "secret_key"
        self.connect()

    def connect(self):
        print("Connecting...")

def process_data():
    proc = DataProcessor()
    print("Processing")
        "#;

        let temp_dir = tempfile::tempdir().unwrap();
        let file_path = temp_dir.path().join("script.py");
        let mut file = std::fs::File::create(&file_path).unwrap();
        file.write_all(python_code.as_bytes()).unwrap();

        let evaluator = CodeAwareEvaluator;

        // --- Granular Defs ---
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Class, "DataProcessor")
            .unwrap()
            .is_match());

        // --- Functions ---
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Func, "process_data")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Func, "connect")
            .unwrap()
            .is_match());

        // --- Calls ---
        let mut ctx = FileContext::new(file_path.clone());
        assert!(
            evaluator
                .evaluate(&mut ctx, &PredicateKey::Call, "print")
                .unwrap()
                .is_match(),
            "Should find multiple calls to print"
        );
        let mut ctx = FileContext::new(file_path.clone());
        assert!(
            evaluator
                .evaluate(&mut ctx, &PredicateKey::Call, "DataProcessor")
                .unwrap()
                .is_match(),
            "Should find constructor call"
        );
        let mut ctx = FileContext::new(file_path.clone());
        assert!(
            evaluator
                .evaluate(&mut ctx, &PredicateKey::Call, "connect")
                .unwrap()
                .is_match(),
            "Should find method call"
        );

        // --- Syntactic Content ---
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Comment, "FIXME")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Str, "secret_key")
            .unwrap()
            .is_match());
    }

    #[test]
    fn test_code_aware_evaluator_javascript_suite() {
        let js_code = r#"
            import { open } from 'fs/promises';

            class Logger {
                log(message) { console.log(message); }
            }

            function a() {
                const l = new Logger();
                l.log("hello");
            }
        "#;

        let temp_dir = tempfile::tempdir().unwrap();
        let file_path = temp_dir.path().join("script.js");
        let mut file = std::fs::File::create(&file_path).unwrap();
        file.write_all(js_code.as_bytes()).unwrap();

        let evaluator = CodeAwareEvaluator;

        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Def, "Logger")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Func, "log")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Import, "fs/promises")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(
            evaluator
                .evaluate(&mut ctx, &PredicateKey::Call, "Logger")
                .unwrap()
                .is_match(),
            "Should find constructor call"
        );
        let mut ctx = FileContext::new(file_path.clone());
        assert!(
            evaluator
                .evaluate(&mut ctx, &PredicateKey::Call, "log")
                .unwrap()
                .is_match(),
            "Should find method call"
        );
    }

    #[test]
    fn test_code_aware_evaluator_typescript_suite() {
        let ts_code = r#"
            import React from 'react';

            interface User { id: number; }
            type ID = string | number;

            class ApiClient {
                // The URL for the API
                private url = "https://api.example.com";
                fetchUser(): User | null { return null; }
            }

            const client = new ApiClient();
            client.fetchUser();
        "#;

        let temp_dir = tempfile::tempdir().unwrap();
        let file_path = temp_dir.path().join("api.ts");
        let mut file = std::fs::File::create(&file_path).unwrap();
        file.write_all(ts_code.as_bytes()).unwrap();

        let evaluator = CodeAwareEvaluator;

        // --- Granular Defs ---
        let mut ctx = FileContext::new(file_path.clone());
        assert!(
            evaluator
                .evaluate(&mut ctx, &PredicateKey::Def, "ApiClient")
                .unwrap()
                .is_match(),
            "Should find class"
        );
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Func, "fetchUser")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Import, "React")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(
            evaluator
                .evaluate(&mut ctx, &PredicateKey::Call, "ApiClient")
                .unwrap()
                .is_match(),
            "Should find TS constructor call"
        );
        let mut ctx = FileContext::new(file_path.clone());
        assert!(
            evaluator
                .evaluate(&mut ctx, &PredicateKey::Call, "fetchUser")
                .unwrap()
                .is_match(),
            "Should find TS method call"
        );

        // --- Syntactic Content ---
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Comment, "The URL")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Str, "https://api.example.com")
            .unwrap()
            .is_match());
    }

    #[test]
    fn test_code_aware_evaluator_go_suite() {
        let go_code = r#"
           package main

           import "fmt"

           // User represents a user
           type User struct {
               ID int
           }

           func (u *User) Greet() {
               fmt.Println("Hello")
           }

           func main() {
               user := User{ID: 1}
               user.Greet()
           }
       "#;

        let temp_dir = tempfile::tempdir().unwrap();
        let file_path = temp_dir.path().join("main.go");
        let mut file = std::fs::File::create(&file_path).unwrap();
        file.write_all(go_code.as_bytes()).unwrap();

        let evaluator = CodeAwareEvaluator;

        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Struct, "User")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Func, "Greet")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Call, "Println")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Import, "fmt")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Comment, "represents a user")
            .unwrap()
            .is_match());
    }

    #[test]
    fn test_code_aware_evaluator_java_suite() {
        let java_code = r#"
           package com.example;

           import java.util.List;

           // Represents a user
           public class User {
               public User() {
                   System.out.println("User created");
               }

               public void greet() {}
           }
       "#;

        let temp_dir = tempfile::tempdir().unwrap();
        let file_path = temp_dir.path().join("User.java");
        let mut file = std::fs::File::create(&file_path).unwrap();
        file.write_all(java_code.as_bytes()).unwrap();

        let evaluator = CodeAwareEvaluator;

        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Class, "User")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Func, "greet")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Call, "println")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Import, "java.util.List")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Comment, "Represents a user")
            .unwrap()
            .is_match());
        let mut ctx = FileContext::new(file_path.clone());
        assert!(evaluator
            .evaluate(&mut ctx, &PredicateKey::Str, "User created")
            .unwrap()
            .is_match());
    }
}
```

### `rdump/evaluator.rs`

The `Evaluator` must now accept a predicate registry in its constructor. The tests are also updated to reflect this.

```rust
use anyhow::{anyhow, Context, Result};
use std::collections::HashMap;
use std::fs;
use std::path::PathBuf;
use tree_sitter::{Parser as TreeSitterParser, Range, Tree};

use crate::parser::{AstNode, PredicateKey};
use crate::predicates::PredicateEvaluator;

/// The result of an evaluation for a single file.
#[derive(Debug, Clone)]
pub enum MatchResult {
    // For simple, non-hunkable predicates like `ext:rs` or `size:>10kb`
    Boolean(bool),
    // For code-aware predicates that can identify specific code blocks.
    Hunks(Vec<Range>),
}

/// Holds the context for a single file being evaluated.
/// It lazily loads content and caches the tree-sitter AST.
pub struct FileContext {
    pub path: PathBuf,
    content: Option<String>,
    // Cache for the parsed tree-sitter AST
    tree: Option<Tree>,
}

impl FileContext {
    pub fn new(path: PathBuf) -> Self {
        FileContext {
            path,
            content: None,
            tree: None,
        }
    }

    pub fn get_content(&mut self) -> Result<&str> {
        if self.content.is_none() {
            let content = fs::read_to_string(&self.path)
                .with_context(|| format!("Failed to read file {}", self.path.display()))?;
            self.content = Some(content);
        }
        Ok(self.content.as_ref().unwrap())
    }

    // Lazily parses the file with tree-sitter and caches the result.
    pub fn get_tree(&mut self, language: tree_sitter::Language) -> Result<&Tree> {
        if self.tree.is_none() {
            let path_display = self.path.display().to_string();
            let content = self.get_content()?;
            let mut parser = TreeSitterParser::new();
            parser.set_language(&language).with_context(|| {
                format!(
                    "Failed to set language for tree-sitter parser on {}",
                    path_display
                )
            })?;
            let tree = parser
                .parse(content, None)
                .ok_or_else(|| anyhow!("Tree-sitter failed to parse {}", path_display))?;
            self.tree = Some(tree);
        }
        Ok(self.tree.as_ref().unwrap())
    }
}

/// The main evaluator struct. It holds the AST and the predicate registry.
pub struct Evaluator {
    ast: AstNode,
    registry: HashMap<PredicateKey, Box<dyn PredicateEvaluator + Send + Sync>>,
}

impl Evaluator {
    pub fn new(
        ast: AstNode,
        registry: HashMap<PredicateKey, Box<dyn PredicateEvaluator + Send + Sync>>,
    ) -> Self {
        Evaluator { ast, registry }
    }

    /// Evaluates the query for a given file path.
    pub fn evaluate(&self, context: &mut FileContext) -> Result<MatchResult> {
        self.evaluate_node(&self.ast, context)
    }

    /// Recursively evaluates an AST node.
    fn evaluate_node(&self, node: &AstNode, context: &mut FileContext) -> Result<MatchResult> {
        match node {
            AstNode::Predicate(key, value) => self.evaluate_predicate(key, value, context),
            AstNode::LogicalOp(op, left, right) => {
                match op {
                    crate::parser::LogicalOperator::And => {
                        let left_res = self.evaluate_node(left, context)?;
                        if !left_res.is_match() {
                            return Ok(MatchResult::Boolean(false));
                        }
                        let right_res = self.evaluate_node(right, context)?;
                        if !right_res.is_match() {
                            return Ok(MatchResult::Boolean(false));
                        }
                        Ok(left_res.combine_with(right_res))
                    }
                    crate::parser::LogicalOperator::Or => {
                        let left_res = self.evaluate_node(left, context)?;
                        // Short-circuit if we have a non-hunkable, definitive match.
                        // This prevents expensive evaluation of the right side.
                        if let MatchResult::Boolean(true) = left_res {
                            return Ok(left_res);
                        }

                        let right_res = self.evaluate_node(right, context)?;

                        // Combine the results logically.
                        if left_res.is_match() && right_res.is_match() {
                            Ok(left_res.combine_with(right_res))
                        } else if left_res.is_match() {
                            Ok(left_res) // right side didn't match
                        } else {
                            Ok(right_res) // left side didn't match, so result is right
                        }
                    }
                }
            }
            AstNode::Not(node) => {
                let result = self.evaluate_node(node, context)?;
                Ok(MatchResult::Boolean(!result.is_match()))
            }
        }
    }

    /// Evaluates a single predicate.
    fn evaluate_predicate(
        &self,
        key: &PredicateKey,
        value: &str,
        context: &mut FileContext,
    ) -> Result<MatchResult> {
        if let Some(evaluator) = self.registry.get(key) {
            evaluator.evaluate(context, key, value)
        } else {
            // If a predicate is not in the current registry (e.g., a content predicate
            // during the metadata-only pass), it's considered a non-match for this pass.
            Ok(MatchResult::Boolean(false))
        }
    }
}

impl MatchResult {
    /// Returns true if the result is considered a match.
    pub fn is_match(&self) -> bool {
        match self {
            MatchResult::Boolean(b) => *b,
            MatchResult::Hunks(h) => !h.is_empty(),
        }
    }

    /// Combines two successful match results.
    pub fn combine_with(self, other: MatchResult) -> Self {
        match (self, other) {
            (MatchResult::Hunks(mut a), MatchResult::Hunks(b)) => {
                a.extend(b);
                a.sort_by_key(|r| r.start_byte);
                a.dedup();
                MatchResult::Hunks(a)
            }
            (MatchResult::Hunks(a), MatchResult::Boolean(_)) => MatchResult::Hunks(a),
            (MatchResult::Boolean(_), MatchResult::Hunks(b)) => MatchResult::Hunks(b),
            (MatchResult::Boolean(_), MatchResult::Boolean(_)) => MatchResult::Boolean(true),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::parser::parse_query;
    use crate::predicates;
    use std::io::Write;
    use tempfile::NamedTempFile;

    fn create_temp_file(content: &str) -> NamedTempFile {
        let file = NamedTempFile::new().unwrap();
        write!(file.as_file(), "{}", content).unwrap();
        file
    }

    #[test]
    fn test_evaluate_simple_predicate() {
        let file = create_temp_file("hello world");
        let mut context = FileContext::new(file.path().to_path_buf());
        let ast = parse_query("contains:world").unwrap();
        let evaluator = Evaluator::new(ast, predicates::create_predicate_registry());
        assert!(evaluator.evaluate(&mut context).unwrap().is_match());
    }

    #[test]
    fn test_evaluate_logical_and() {
        let file = create_temp_file("hello world");
        let mut context = FileContext::new(file.path().to_path_buf());
        let ast = parse_query("contains:hello & contains:world").unwrap();
        let evaluator = Evaluator::new(ast, predicates::create_predicate_registry());
        assert!(evaluator.evaluate(&mut context).unwrap().is_match());

        let ast_fail = parse_query("contains:hello & contains:goodbye").unwrap();
        let evaluator_fail = Evaluator::new(ast_fail, predicates::create_predicate_registry());
        assert!(!evaluator_fail
            .evaluate(&mut context)
            .unwrap()
            .is_match());
    }

    #[test]
    fn test_evaluate_logical_or() {
        let file = create_temp_file("hello world");
        let mut context = FileContext::new(file.path().to_path_buf());
        let ast = parse_query("contains:hello | contains:goodbye").unwrap();
        let evaluator = Evaluator::new(ast, predicates::create_predicate_registry());
        assert!(evaluator.evaluate(&mut context).unwrap().is_match());

        let ast_fail = parse_query("contains:goodbye | contains:farewell").unwrap();
        let evaluator_fail = Evaluator::new(ast_fail, predicates::create_predicate_registry());
        assert!(!evaluator_fail
            .evaluate(&mut context)
            .unwrap()
            .is_match());
    }

    #[test]
    fn test_evaluate_negation() {
        let file = create_temp_file("hello world");
        let mut context = FileContext::new(file.path().to_path_buf());
        let ast = parse_query("!contains:goodbye").unwrap();
        let evaluator = Evaluator::new(ast, predicates::create_predicate_registry());
        assert!(evaluator.evaluate(&mut context).unwrap().is_match());

        let ast_fail = parse_query("!contains:hello").unwrap();
        let evaluator_fail = Evaluator::new(ast_fail, predicates::create_predicate_registry());
        assert!(!evaluator_fail
            .evaluate(&mut context)
            .unwrap()
            .is_match());
    }
}
```

### `rdump/commands/search.rs`

This is where the new two-phase logic is orchestrated.

```rust
use crate::{config, ColorChoice, SearchArgs};
use anyhow::anyhow;
use anyhow::Result;
use atty::Stream;
use ignore::WalkBuilder;
use rayon::prelude::*;
use std::fs::File;
use std::io::{self, Write};
use std::path::PathBuf;
use tempfile::NamedTempFile;
use tree_sitter::Range;

use crate::evaluator::{Evaluator, FileContext, MatchResult};
use crate::formatter;
use crate::parser;
use crate::predicates;

/// The main entry point for the `search` command.
pub fn run_search(mut args: SearchArgs) -> Result<()> {
    // --- Load Config and Build Query ---
    let config = config::load_config()?;
    let mut final_query = args.query.take().unwrap_or_default();

    for preset_name in args.preset.iter().rev() {
        let preset_query = config
            .presets
            .get(preset_name)
            .ok_or_else(|| anyhow!("Preset '{}' not found", preset_name))?;

        if final_query.is_empty() {
            final_query = format!("({})", preset_query);
        } else {
            final_query = format!("({}) & {}", preset_query, final_query);
        }
    }

    if final_query.is_empty() {
        return Err(anyhow!(
            "Empty query. Provide a query string or use a preset."
        ));
    }

    // --- 1. Find initial candidates ---
    let candidate_files =
        get_candidate_files(&args.root, args.no_ignore, args.hidden, args.max_depth)?;

    // --- 2. Parse query ---
    let ast = parser::parse_query(&final_query)?;

    // --- 3. Pre-filtering Pass (Metadata) ---
    // This pass uses a special evaluator with only fast metadata predicates.
    // It quickly reduces the number of files needing full evaluation.
    let metadata_registry = predicates::create_metadata_predicate_registry();
    let pre_filter_evaluator = Evaluator::new(ast.clone(), metadata_registry);

    let pre_filtered_files: Vec<PathBuf> = candidate_files
        .into_iter() // This pass is not parallel, it's fast enough.
        .filter(|path| {
            let mut context = FileContext::new(path.clone());
            match pre_filter_evaluator.evaluate(&mut context) {
                Ok(result) => result.is_match(),
                Err(e) => {
                    eprintln!("Error during pre-filter on {}: {}", path.display(), e);
                    false
                }
            }
        })
        .collect();

    // --- Determine if color should be used ---
    let use_color = match args.color {
        ColorChoice::Always => true,
        ColorChoice::Never => false,
        ColorChoice::Auto => atty::is(Stream::Stdout),
    };

    // --- 4. Main Evaluation Pass (Content + Semantic) ---
    // This pass uses the full evaluator on the smaller, pre-filtered set of files.
    let full_registry = predicates::create_predicate_registry();
    let evaluator = Evaluator::new(ast, full_registry);

    let mut matching_files: Vec<(PathBuf, Vec<Range>)> = pre_filtered_files
        .par_iter()
        .filter_map(|path| {
            let mut context = FileContext::new(path.clone());
            match evaluator.evaluate(&mut context) {
                Ok(MatchResult::Boolean(true)) => Some((path.clone(), Vec::new())),
                Ok(MatchResult::Boolean(false)) => None,
                Ok(MatchResult::Hunks(hunks)) => {
                    if hunks.is_empty() {
                        None
                    } else {
                        Some((path.clone(), hunks))
                    }
                }
                Err(e) => {
                    eprintln!("Error evaluating file {}: {}", path.display(), e);
                    None
                }
            }
        })
        .collect();

    matching_files.sort_by(|a, b| a.0.cmp(&b.0));

    // --- 5. Format and print results ---
    let mut writer: Box<dyn Write> = if let Some(output_path) = &args.output {
        Box::new(File::create(output_path)?)
    } else {
        Box::new(io::stdout())
    };

    formatter::print_output(
        &mut writer,
        &matching_files,
        &args.format,
        args.line_numbers,
        use_color,
    )?;

    Ok(())
}

/// Walks the directory, respecting .gitignore, and applies our own smart defaults.
fn get_candidate_files(
    root: &PathBuf,
    no_ignore: bool,
    hidden: bool,
    max_depth: Option<usize>,
) -> Result<Vec<PathBuf>> {
    let mut files = Vec::new();
    let mut walker_builder = WalkBuilder::new(root);

    walker_builder.hidden(!hidden).max_depth(max_depth);

    if !no_ignore {
        // Layer 1: Our "sane defaults". These have the lowest precedence.
        let default_ignores = "
           # Default rdump ignores
           node_modules/
           target/
           dist/
           build/
           .git/
           .svn/
           .hg/
           *.pyc
           __pycache__/
       ";
        let mut temp_ignore = NamedTempFile::new()?;
        write!(temp_ignore, "{}", default_ignores)?;
        walker_builder.add_ignore(temp_ignore.path());

        // Layer 2: A user's custom global ignore file.
        if let Some(global_ignore_path) = dirs::config_dir().map(|p| p.join("rdump/ignore")) {
            if global_ignore_path.exists() {
                if let Some(err) = walker_builder.add_ignore(global_ignore_path) {
                    eprintln!("Warning: could not add global ignore file: {}", err);
                }
            }
        }

        // Layer 3: A user's custom project-local .rdumpignore file.
        walker_builder.add_custom_ignore_filename(".rdumpignore");

        // Layer 4: Standard .gitignore files.
        walker_builder.git_global(true);
        walker_builder.git_ignore(true);
    } else {
        // If --no-ignore is passed, disable everything.
        walker_builder.ignore(false);
    }

    for result in walker_builder.build() {
        let entry = result?;
        if entry.file_type().map_or(false, |ft| ft.is_file()) {
            files.push(entry.into_path());
        }
    }
    Ok(files)
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::fs;
    use std::io::Write;
    use tempfile::tempdir;

    fn get_sorted_file_names(
        root: &PathBuf,
        no_ignore: bool,
        hidden: bool,
        max_depth: Option<usize>,
    ) -> Vec<String> {
        let mut paths = get_candidate_files(root, no_ignore, hidden, max_depth).unwrap();
        paths.sort();
        paths
            .into_iter()
            .map(|p| {
                p.strip_prefix(root)
                    .unwrap()
                    .to_string_lossy()
                    .replace('\\', "/")
            })
            .collect()
    }

    #[test]
    fn test_custom_rdumpignore_file() {
        let dir = tempdir().unwrap();
        let root = dir.path();
        let mut ignore_file = fs::File::create(root.join(".rdumpignore")).unwrap();
        writeln!(ignore_file, "*.log").unwrap();
        fs::File::create(root.join("app.js")).unwrap();
        fs::File::create(root.join("app.log")).unwrap();

        let files = get_sorted_file_names(&root.to_path_buf(), false, false, None);
        assert_eq!(files, vec!["app.js"]);
    }

    #[test]
    fn test_unignore_via_rdumpignore() {
        let dir = tempdir().unwrap();
        let root = dir.path();

        let node_modules = root.join("node_modules");
        fs::create_dir(&node_modules).unwrap();
        fs::File::create(node_modules.join("some_dep.js")).unwrap();
        fs::File::create(root.join("app.js")).unwrap();

        let mut ignore_file = fs::File::create(root.join(".rdumpignore")).unwrap();
        writeln!(ignore_file, "!node_modules/").unwrap();

        let files = get_sorted_file_names(&root.to_path_buf(), false, false, None);
        assert_eq!(files.len(), 2);
        assert!(files.contains(&"app.js".to_string()));
        assert!(files.contains(
            &"node_modules/some_dep.js"
                .to_string()
                .replace('/', &std::path::MAIN_SEPARATOR.to_string())
        ));
    }
}
```

---

### 2. Missing Critical Feature: Context Control for Hunks

The `hunks` format is powerful, but often you want to see a few lines *around* the match for context, like `grep -C 3`.

**This is a missing critical usability feature.** I won't implement it for you, as it's a perfect next step for you to take, but here is exactly how you would do it:

1.  **Add a new CLI argument** in `main.rs`:
    ```rust
    #[derive(Parser, Debug)]
    pub struct SearchArgs {
        // ... existing args
        #[arg(long, short = 'C', value_name = "LINES")]
        pub context: Option<usize>,
    }
    ```

2.  **Pass `context` to `print_output`** in `commands/search.rs`:
    ```rust
    // in run_search
    formatter::print_output(
        &mut writer,
        &matching_files,
        &args.format,
        args.line_numbers,
        use_color,
        args.context.unwrap_or(0), // Pass the context lines, defaulting to 0
    )?;
    ```

3.  **Implement the logic in `formatter.rs`:**
    *   Modify the `print_output` function signature to accept `context_lines: usize`.
    *   Inside the `Format::Hunks` match arm, you currently extract the exact lines for the hunk.
    *   Instead, you'll want to get the `start_point().row()` and `end_point().row()` of the `hunk_range`.
    *   Read the entire file's content into a `Vec<&str>` by splitting on newlines.
    *   Calculate the new start and end row: `start = row_start.saturating_sub(context_lines)` and `end = (row_end + context_lines).min(total_lines - 1)`.
    *   Slice the `Vec<&str>` from `start` to `end` and print that slice.
    *   You will also need to handle merging overlapping hunks so you don't print the same lines twice.

This feature will dramatically improve the utility of semantic searches.

You have built a truly excellent foundation. This performance optimization makes it legitimately fast for large-scale use, and adding context control will make it a genuinely powerful and practical alternative to other command-line search tools.