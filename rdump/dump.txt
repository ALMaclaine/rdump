// START rdump/Cargo.toml

[package]
name = "rdump"
version = "0.1.0"
edition = "2021"

[dependencies]
clap = { version = "4.5.4", features = ["derive"] }
anyhow = "1.0.86"
ignore = "0.4.22" # <--- NO FEATURES. THIS IS THE CORRECT LINE.
rayon = "1.10.0"
regex = "1.10.4"
serde = { version = "1.0.203", features = ["derive"] }
serde_json = "1.0.117"
pest = "2.7.10"
pest_derive = "2.7.10"
tempfile = "3.20.0"
glob = "0.3.1"
dirs = "5.0.1"
toml = "0.8.12"
chrono = { version = "0.4", features = ["serde"] }
lazy_static = "1.4.0"


// END rdump/Cargo.toml

// START rdump/src/commands/mod.rs

// This makes the functions inside search.rs and preset.rs available
// to other parts of the program that use the `commands` module.
pub mod search;
pub mod preset;


// END rdump/src/commands/mod.rs

// START rdump/src/commands/preset.rs

use anyhow::{anyhow, Result};
use std::fs;
use crate::config::{self, Config};
use crate::PresetAction; // We'll need to make PresetAction public

/// The main entry point for the `preset` command.
pub fn run_preset(action: PresetAction) -> Result<()> {
    match action {
        PresetAction::List => {
            let config = config::load_config()?;
            if config.presets.is_empty() {
                println!("No presets found.");
            } else {
                println!("Available presets:");
                let max_len = config.presets.keys().map(|k| k.len()).max().unwrap_or(0);
                for (name, query) in config.presets {
                    println!("  {:<width$} : {}", name, query, width = max_len);
                }
            }
        }
        PresetAction::Add { name, query } => {
            let path = config::global_config_path()
                .ok_or_else(|| anyhow!("Could not determine global config path"))?;

            let mut config = if path.exists() {
                let config_str = fs::read_to_string(&path)?;
                toml::from_str(&config_str)?
            } else {
                Config::default()
            };

            println!("Adding/updating preset '{}'...", name);
            config.presets.insert(name, query);
            config::save_config(&config)?;
        }
        PresetAction::Remove { name } => {
            let path = config::global_config_path()
                .ok_or_else(|| anyhow!("Could not determine global config path"))?;

            if !path.exists() {
                return Err(anyhow!("Global config file does not exist. No presets to remove."));
            }

            let mut config: Config = toml::from_str(&fs::read_to_string(&path)?)?;

            if config.presets.remove(&name).is_some() {
                println!("Removing preset '{}'...", name);
                config::save_config(&config)?;
            } else {
                return Err(anyhow!("Preset '{}' not found in global config.", name));
            }
        }
    }
    Ok(())
}


// END rdump/src/commands/preset.rs

// START rdump/src/commands/search.rs

use anyhow::Result;
use ignore::WalkBuilder;
use rayon::prelude::*;
use std::fs::File;
use std::io::{self, Write};
use std::path::PathBuf;

use crate::evaluator::Evaluator;
use crate::formatter;
use crate::parser;
use crate::{config, SearchArgs};

/// The main entry point for the `search` command.
pub fn run_search(mut args: SearchArgs) -> Result<()> {
    // --- Load Config and Build Query ---
    let config = config::load_config()?;
    let mut final_query = args.query.take().unwrap_or_default();

    for preset_name in args.preset.iter().rev() {
        let preset_query = config.presets.get(preset_name)
            .ok_or_else(|| anyhow::anyhow!("Preset '{}' not found", preset_name))?;

        if final_query.is_empty() {
            final_query = format!("({})", preset_query);
        } else {
            final_query = format!("({}) & {}", preset_query, final_query);
        }
    }

    if final_query.is_empty() {
        return Err(anyhow::anyhow!("Empty query. Provide a query string or use a preset."));
    }

    // --- 1. Find candidates ---
    let candidate_files = get_candidate_files(
        &args.root,
        args.no_ignore,
        args.hidden,
        args.max_depth,
    )?;

    // --- 2. Parse query ---
    let ast = parser::parse_query(&final_query)?;

    // --- 3. Evaluate files ---
    let evaluator = Evaluator::new(&ast);
    let mut matching_files: Vec<PathBuf> = candidate_files
        .par_iter()
        .filter_map(|path| match evaluator.evaluate(path) {
            Ok(true) => Some(path.clone()),
            Ok(false) => None,
            Err(e) => {
                eprintln!("Error evaluating file {}: {}", path.display(), e);
                None
            }
        })
        .collect();

    matching_files.sort();

    // --- 4. Format and print results ---
    let mut writer: Box<dyn Write> = if let Some(output_path) = &args.output {
        Box::new(File::create(output_path)?)
    } else {
        Box::new(io::stdout())
    };

    formatter::print_output(
        &mut writer,
        &matching_files,
        &args.format,
        args.line_numbers,
    )?;

    Ok(())
}

/// Walks the directory, respecting .gitignore, and applies our own smart defaults.
// This is now a private helper function within the search module.
fn get_candidate_files(
    root: &PathBuf,
    no_ignore: bool,
    hidden: bool,
    max_depth: Option<usize>,
) -> Result<Vec<PathBuf>> {
    let mut files = Vec::new();
    let mut walker_builder = WalkBuilder::new(root);

    walker_builder
        .ignore(!no_ignore)
        .git_ignore(!no_ignore)
        .hidden(!hidden)
        .max_depth(max_depth);

    if !no_ignore {
        let gitignore_path = root.join(".gitignore");
        if gitignore_path.exists() {
            walker_builder.add_ignore(gitignore_path);
        }
    }

    for result in walker_builder.build() {
        let entry = result?;
        if entry.file_type().map_or(false, |ft| ft.is_file()) {
            files.push(entry.into_path());
        }
    }
    Ok(files)
}

// Add to the bottom of rdump/src/commands/search.rs

#[cfg(test)]
mod tests {
    use super::*;
    use std::collections::HashSet;
    use std::fs;
    use std::io::Write;
    use tempfile::tempdir;

    fn create_test_fs() -> (tempfile::TempDir, PathBuf) {
        let dir = tempdir().unwrap();
        let root = dir.path().to_path_buf();

        // Create files and directories
        fs::File::create(root.join("file_a.txt")).unwrap();
        fs::File::create(root.join(".hidden_file")).unwrap();

        fs::create_dir(root.join("sub")).unwrap();
        fs::File::create(root.join("sub/file_b.txt")).unwrap();

        fs::create_dir_all(root.join("sub/sub2")).unwrap();
        fs::File::create(root.join("sub/sub2/file_c.log")).unwrap();

        fs::create_dir_all(root.join("target/debug")).unwrap();
        fs::File::create(root.join("target/debug/app.exe")).unwrap();

        fs::create_dir(root.join("logs")).unwrap();
        fs::File::create(root.join("logs/yesterday.log")).unwrap();

        let mut gitignore = fs::File::create(root.join(".gitignore")).unwrap();
        writeln!(gitignore, "*.log").unwrap();
        writeln!(gitignore, "logs/").unwrap();
        writeln!(gitignore, "target/").unwrap();

        (dir, root)
    }

    // Helper to run get_candidate_files and return a sorted list of file names
    fn get_sorted_file_names(
        root: &PathBuf,
        no_ignore: bool,
        hidden: bool,
        max_depth: Option<usize>,
    ) -> Vec<String> {
        let mut paths = get_candidate_files(root, no_ignore, hidden, max_depth).unwrap();
        paths.sort();
        paths
            .into_iter()
            .map(|p| p.strip_prefix(root).unwrap().to_string_lossy().replace("\\", "/"))
            .collect()
    }

    #[test]
    fn test_get_candidates_default_behavior() {
        let (_dir, root) = create_test_fs();
        let files = get_sorted_file_names(&root, false, false, None);

        // Should find file_a.txt and file_b.txt
        // Should NOT find:
        // - .hidden_file (hidden)
        // - .gitignore (hidden)
        // - files in target/ (default override)
        // - *.log files (.gitignore)
        assert_eq!(files, vec!["file_a.txt", "sub/file_b.txt"]);
    }

    #[test]
    fn test_get_candidates_with_hidden() {
        let (_dir, root) = create_test_fs();
        let files = get_sorted_file_names(&root, false, true, None);

        // Should find .gitignore, .hidden_file, file_a.txt, file_b.txt
        let expected: HashSet<String> = [
            ".gitignore".to_string(),
            ".hidden_file".to_string(),
            "file_a.txt".to_string(),
            "sub/file_b.txt".to_string(),
        ]
        .iter()
        .cloned()
        .collect();
        let found: HashSet<String> = files.into_iter().collect();

        assert_eq!(found, expected);
    }

    #[test]
    fn test_get_candidates_with_no_ignore() {
        let (_dir, root) = create_test_fs();
        let files = get_sorted_file_names(&root, true, false, None);

        // Should find everything not hidden, including gitignored files
        // and files in the default-ignored 'target' dir.
        let expected: HashSet<String> = [
            "file_a.txt".to_string(),
            "sub/file_b.txt".to_string(),
            "sub/sub2/file_c.log".to_string(),
            "target/debug/app.exe".to_string(),
            "logs/yesterday.log".to_string(),
        ]
        .iter()
        .cloned()
        .collect();
        let found: HashSet<String> = files.into_iter().collect();

        assert_eq!(found, expected);
    }

    #[test]
    fn test_get_candidates_with_max_depth() {
        let (_dir, root) = create_test_fs();
        // Depth 1 is the root directory itself.
        // Depth 2 is the root + immediate children.
        let files = get_sorted_file_names(&root, false, false, Some(2));
        // Should find file_a.txt and file_b.txt which is at depth 2 (root -> sub -> file_b)
        assert_eq!(files, vec!["file_a.txt", "sub/file_b.txt"]);
    }
}

// END rdump/src/commands/search.rs

// START rdump/src/config.rs

use anyhow::{Context, Result};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::env;
use std::fs;
use std::path::{Path, PathBuf};

// This struct represents the structure of our TOML config file.
// `#[derive(Deserialize)]` tells serde how to create this struct from TOML text.
#[derive(Deserialize, Serialize, Debug, Default)]
pub struct Config {
    // `#[serde(default)]` ensures that if the `presets` table is missing,
    // we just get an empty HashMap instead of an error.
    #[serde(default)]
    pub presets: HashMap<String, String>,
}

/// Finds and loads the configuration, merging global and local files.
pub fn load_config() -> Result<Config> {
    let mut final_config = Config::default();

    // 1. Load the global config file, if it exists.
    if let Some(global_config_path) = global_config_path() {
        if global_config_path.exists() {
            let global_config_str = fs::read_to_string(&global_config_path)
                .with_context(|| format!("Failed to read global config at {:?}", global_config_path))?;
            let global_config: Config = toml::from_str(&global_config_str)?;
            final_config.presets.extend(global_config.presets);
        }
    }

    // 2. Find and load the local config file, if it exists.
    // Local presets will overwrite global ones with the same name.
    let current_dir = env::current_dir()?;
    if let Some(local_config_path) = find_local_config(&current_dir) {
        if local_config_path.exists() {
            let local_config_str = fs::read_to_string(&local_config_path)
                .with_context(|| format!("Failed to read local config at {:?}", local_config_path))?;
            let local_config: Config = toml::from_str(&local_config_str)?;
            final_config.presets.extend(local_config.presets);
        }
    }

    Ok(final_config)
}

/// Returns the path to the global configuration file.
pub fn global_config_path() -> Option<PathBuf> {
    // START: ADDED FOR TESTING
    #[cfg(test)]
    {
        // If this env var is set during a test, use it as the base config dir.
        if let Ok(path_str) = std::env::var("RDUMP_TEST_CONFIG_DIR") {
            return Some(std::path::PathBuf::from(path_str).join("rdump/config.toml"));
        }
    }
    // END: ADDED FOR TESTING

    // Use the `dirs` crate to find the conventional config directory.
    dirs::config_dir().map(|p| p.join("rdump/config.toml"))
}

/// Searches for a local `.rdump.toml` in the given directory and its parents.
fn find_local_config(start_dir: &Path) -> Option<PathBuf> {
    for ancestor in start_dir.ancestors() {
        let config_path = ancestor.join(".rdump.toml");
        if config_path.exists() {
            return Some(config_path);
        }
    }
    None
}

/// Saves the given config to the global configuration file.
pub fn save_config(config: &Config) -> Result<()> {
    let path = global_config_path().ok_or_else(|| anyhow::anyhow!("Could not determine global config path"))?;

    // Ensure the parent directory exists.
    if let Some(parent) = path.parent() {
        fs::create_dir_all(parent)
            .with_context(|| format!("Failed to create config directory at {:?}", parent))?;
    }

    let toml_string = toml::to_string_pretty(config)?;
    fs::write(&path, toml_string)
        .with_context(|| format!("Failed to write global config to {:?}", path))?;

    println!("Successfully saved config to {:?}", path);
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use lazy_static::lazy_static;
    use std::io::Write;
    use std::sync::Mutex;
    use tempfile::tempdir;

    lazy_static! {
        // A mutex to ensure that tests that manipulate the environment
        // (env vars, current dir) do not run in parallel.
        static ref ENV_MUTEX: Mutex<()> = Mutex::new(());
    }

    #[test]
    fn test_find_local_config_in_parent() {
        let _lock = ENV_MUTEX.lock().unwrap();
        let root = tempdir().unwrap();
        let sub = root.path().join("sub");
        fs::create_dir(&sub).unwrap();

        let config_path = root.path().join(".rdump.toml");
        fs::File::create(&config_path).unwrap();

        // From within the subdirectory, it should find the config in the parent.
        let found_path = find_local_config(&sub).unwrap();
        assert_eq!(found_path, config_path);
    }

    #[test]
    fn test_find_local_config_not_found() {
        let _lock = ENV_MUTEX.lock().unwrap();
        let root = tempdir().unwrap();
        assert!(find_local_config(root.path()).is_none());
    }

    #[test]
    fn test_load_config_merging_and_overriding() {
        let _lock = ENV_MUTEX.lock().unwrap();
        let test_dir = tempdir().unwrap();

        // 1. Setup the fake global config
        let fake_home_dir = test_dir.path().join("home");
        let global_config_dir = fake_home_dir.join("rdump");
        fs::create_dir_all(&global_config_dir).unwrap();
        let global_config_path = global_config_dir.join("config.toml");
        let mut global_file = fs::File::create(&global_config_path).unwrap();
        writeln!(
            global_file,
            r#"
            [presets]
            rust = "ext:rs"
            docs = "ext:md"
        "#
        )
        .unwrap();

        // 2. Setup the fake local config in a project directory
        let project_dir = test_dir.path().join("project");
        fs::create_dir(&project_dir).unwrap();
        let local_config_path = project_dir.join(".rdump.toml");
        let mut local_file = fs::File::create(&local_config_path).unwrap();
        writeln!(
            local_file,
            r#"
            [presets]
            docs = "ext:md | ext:txt" # This should override the global 'docs'
            scripts = "ext:sh"       # This is a new local-only preset
        "#
        )
        .unwrap();

        // 3. Set the environment variable to point to our fake global config dir
        env::set_var("RDUMP_TEST_CONFIG_DIR", fake_home_dir.to_str().unwrap());

        // 4. Run the function to be tested, simulating running from the project dir
        let original_dir = env::current_dir().unwrap();
        env::set_current_dir(&project_dir).unwrap();
        let config = load_config().unwrap();
        env::set_current_dir(&original_dir).unwrap(); // Cleanup

        // 5. Assert the results
        assert_eq!(config.presets.len(), 3);
        assert_eq!(config.presets.get("rust").unwrap(), "ext:rs"); // From global
        assert_eq!(config.presets.get("scripts").unwrap(), "ext:sh"); // From local
        assert_eq!(
            config.presets.get("docs").unwrap(),
            "ext:md | ext:txt" // Overridden by local
        );

        // Clean up the environment variable for other tests
        env::remove_var("RDUMP_TEST_CONFIG_DIR");
    }

    #[test]
    fn test_load_config_only_global() {
        let _lock = ENV_MUTEX.lock().unwrap();
        let test_dir = tempdir().unwrap();
        let fake_home_dir = test_dir.path().join("home");
        let project_dir = test_dir.path().join("project"); // No local config here
        fs::create_dir_all(&project_dir).unwrap();

        let global_config_dir = fake_home_dir.join("rdump");
        fs::create_dir_all(&global_config_dir).unwrap();
        let mut global_file = fs::File::create(global_config_dir.join("config.toml")).unwrap();
        writeln!(
            global_file,
            r#"
            [presets]
            rust = "ext:rs"
        "#
        )
        .unwrap();

        env::set_var("RDUMP_TEST_CONFIG_DIR", fake_home_dir.to_str().unwrap());
        let original_dir = env::current_dir().unwrap();
        env::set_current_dir(&project_dir).unwrap();
        let config = load_config().unwrap();
        env::set_current_dir(&original_dir).unwrap(); // Cleanup

        assert_eq!(config.presets.len(), 1);
        assert_eq!(config.presets.get("rust").unwrap(), "ext:rs");

        env::remove_var("RDUMP_TEST_CONFIG_DIR");
    }
}


// END rdump/src/config.rs

// START rdump/src/evaluator.rs

use anyhow::{Result, Context};
use std::collections::HashMap;
use std::fs;
use std::path::{Path, PathBuf};

use crate::parser::{AstNode, PredicateKey};
use crate::predicates::{create_predicate_registry, PredicateEvaluator};

/// A context for a single file being evaluated.
#[derive(Debug)]
pub struct FileContext {
    pub path: PathBuf,
    content: Option<String>,
}

impl FileContext {
    pub fn new(path: PathBuf) -> Self {
        FileContext { path, content: None }
    }

    pub fn get_content(&mut self) -> Result<&str> {
        if self.content.is_none() {
            let content = fs::read_to_string(&self.path)
                .with_context(|| format!("Failed to read content of {}", self.path.display()))?;
            self.content = Some(content);
        }
        Ok(self.content.as_ref().unwrap())
    }
}

/// The main evaluator struct. It holds the AST and the predicate registry.
pub struct Evaluator<'a> {
    ast: &'a AstNode,
    // The registry of all available predicate "plugins".
    registry: HashMap<PredicateKey, Box<dyn PredicateEvaluator + Send + Sync>>,
}

impl<'a> Evaluator<'a> {
    /// Creates a new evaluator with a reference to the AST.
    pub fn new(ast: &'a AstNode) -> Self {
        Self {
            ast,
            registry: create_predicate_registry(),
        }
    }

    /// Evaluates a single file path against the AST.
    pub fn evaluate(&self, path: &Path) -> Result<bool> {
        let mut context = FileContext::new(path.to_path_buf());
        self.evaluate_node(self.ast, &mut context)
    }

    /// The core recursive function that walks the AST.
    fn evaluate_node(&self, node: &AstNode, context: &mut FileContext) -> Result<bool> {
        match node {
            AstNode::And(left, right) => {
                Ok(self.evaluate_node(left, context)? && self.evaluate_node(right, context)?)
            }
            AstNode::Or(left, right) => {
                Ok(self.evaluate_node(left, context)? || self.evaluate_node(right, context)?)
            }
            AstNode::Not(node) => Ok(!self.evaluate_node(node, context)?),
            AstNode::Predicate { key, value } => self.evaluate_predicate(key, value, context),
        }
    }

    /// Dispatches to the correct plugin from the registry.
    fn evaluate_predicate(
        &self,
        key: &PredicateKey,
        value: &str,
        context: &mut FileContext,
    ) -> Result<bool> {
        if let Some(evaluator) = self.registry.get(key) {
            evaluator.evaluate(context, value)
        } else {
            // Handle unknown or unimplemented predicates gracefully.
            if let PredicateKey::Other(unknown_key) = key {
                 println!("Warning: unknown predicate key '{}'", unknown_key);
            }
            Ok(false)
        }
    }
}

// --- TESTS ARE NOW MOVED ---
// All the old evaluator tests are now invalid because the logic has moved.
// We will create new, more focused tests inside the `predicates` module itself.

#[cfg(test)]
mod tests {
    use super::*;
    use crate::parser::parse_query;
    use std::io::Write;
    use tempfile::NamedTempFile;

    // Helper to create a file with specific content for testing
    fn create_test_file(content: &str) -> NamedTempFile {
        let mut file = NamedTempFile::new().unwrap();
        file.write_all(content.as_bytes()).unwrap();
        file
    }

    #[test]
    fn test_logical_operators() {
        let file = create_test_file("fn main() {}");
        // Give the temp file a `.rs` extension for the ext: predicate
        let path_rs = file.path().with_extension("rs");
        std::fs::rename(file.path(), &path_rs).unwrap();

        // true & true => true
        let ast_and_true = parse_query("ext:rs & contains:'main'").unwrap();
        let evaluator_and_true = Evaluator::new(&ast_and_true);
        assert!(evaluator_and_true.evaluate(&path_rs).unwrap());

        // true & false => false
        let ast_and_false = parse_query("ext:rs & contains:'other'").unwrap();
        let evaluator_and_false = Evaluator::new(&ast_and_false);
        assert!(!evaluator_and_false.evaluate(&path_rs).unwrap());

        // true | false => true
        let ast_or_true = parse_query("ext:rs | contains:'other'").unwrap();
        let evaluator_or_true = Evaluator::new(&ast_or_true);
        assert!(evaluator_or_true.evaluate(&path_rs).unwrap());

        // false | false => false
        let ast_or_false = parse_query("ext:md | contains:'other'").unwrap();
        let evaluator_or_false = Evaluator::new(&ast_or_false);
        assert!(!evaluator_or_false.evaluate(&path_rs).unwrap());

        // !false => true
        let ast_not_true = parse_query("!ext:md").unwrap();
        let evaluator_not_true = Evaluator::new(&ast_not_true);
        assert!(evaluator_not_true.evaluate(&path_rs).unwrap());

        // !true => false
        let ast_not_false = parse_query("!ext:rs").unwrap();
        let evaluator_not_false = Evaluator::new(&ast_not_false);
        assert!(!evaluator_not_false.evaluate(&path_rs).unwrap());
    }

    #[test]
    fn test_file_context_lazy_loading() {
        let file = create_test_file("lazy content");
        let mut context = FileContext::new(file.path().to_path_buf());

        // Content is None initially
        assert!(context.content.is_none());

        // get_content loads it
        let content = context.get_content().unwrap();
        assert_eq!(content, "lazy content");
        assert!(context.content.is_some());

        // Calling it again returns the same content without re-reading (implicitly)
        let content_again = context.get_content().unwrap();
        assert_eq!(content_again, "lazy content");
    }
}


// END rdump/src/evaluator.rs

// START rdump/src/formatter.rs

use anyhow::{Context, Result};
use chrono::{DateTime, Local}; // For formatting timestamps
#[cfg(unix)]
use std::os::unix::fs::PermissionsExt; // For Unix permissions
use std::fs;
use std::io::Write;
use std::path::PathBuf;
use serde::{Deserialize, Serialize};

// We need to pass the format enum from main.rs
use crate::Format;

#[derive(Serialize, Deserialize, Debug, PartialEq)]
struct FileOutput {
    path: String,
    content: String,
}

/// Formats and prints the final output to a generic writer based on the chosen format.
pub fn print_output(
    writer: &mut impl Write,
    matching_files: &[PathBuf],
    format: &Format,
    with_line_numbers: bool,
) -> Result<()> {
    match format {
        Format::Find => {
            for path in matching_files {
                let metadata = fs::metadata(path)?;
                let size = metadata.len();
                let modified: DateTime<Local> = DateTime::from(metadata.modified()?);

                // Get permissions (basic implementation)
                let perms = metadata.permissions();
                let mode = perms.mode();
                let perms_str = format_mode(mode);

                // Format size into human-readable string
                let size_str = format_size(size);

                // Format time
                let time_str = modified.format("%b %d %H:%M").to_string();

                writeln!(
                    writer,
                    "{:<12} {:>8} {} {}",
                    perms_str,
                    size_str,
                    time_str,
                    path.display()
                )?;
            }
        }
        Format::Paths => {
            for path in matching_files {
                writeln!(writer, "{}", path.display())?;
            }
        }
        Format::Cat => {
            for path in matching_files {
                let content = fs::read_to_string(path)
                    .with_context(|| format!("Failed to read file for final output: {}", path.display()))?;
                if with_line_numbers {
                    for (i, line) in content.lines().enumerate() {
                        writeln!(writer, "{:>5} | {}", i + 1, line)?;
                    }
                } else {
                    writeln!(writer, "{}", content)?;
                }
            }
        }
        Format::Json => {
            let mut outputs = Vec::new();
            for path in matching_files {
                let content = fs::read_to_string(path)
                    .with_context(|| format!("Failed to read file for final output: {}", path.display()))?;
                outputs.push(FileOutput {
                    path: path.to_string_lossy().to_string(),
                    content,
                });
            }
            // Use to_writer_pretty for readable JSON output
            serde_json::to_writer_pretty(writer, &outputs)?;
        }
        Format::Markdown => {
            for (i, path) in matching_files.iter().enumerate() {
                if i > 0 {
                    writeln!(writer, "\n---\n")?;
                }
                writeln!(writer, "File: {}", path.display())?;
                writeln!(writer, "---")?;
                let content = fs::read_to_string(path)
                    .with_context(|| format!("Failed to read file for final output: {}", path.display()))?;

                if with_line_numbers {
                    for (i, line) in content.lines().enumerate() {
                        writeln!(writer, "{:>5} | {}", i + 1, line)?;
                    }
                } else {
                    writeln!(writer, "{}", content)?;
                }
            }
        }
    }
    Ok(())
}

fn format_mode(mode: u32) -> String {
    #[cfg(unix)]
    {
        let user_r = if mode & 0o400 != 0 { 'r' } else { '-' };
        let user_w = if mode & 0o200 != 0 { 'w' } else { '-' };
        let user_x = if mode & 0o100 != 0 { 'x' } else { '-' };
        let group_r = if mode & 0o040 != 0 { 'r' } else { '-' };
        let group_w = if mode & 0o020 != 0 { 'w' } else { '-' };
        let group_x = if mode & 0o010 != 0 { 'x' } else { '-' };
        let other_r = if mode & 0o004 != 0 { 'r' } else { '-' };
        let other_w = if mode & 0o002 != 0 { 'w' } else { '-' };
        let other_x = if mode & 0o001 != 0 { 'x' } else { '-' };
        format!("-{}{}{}{}{}{}{}{}{}", user_r, user_w, user_x, group_r, group_w, group_x, other_r, other_w, other_x)
    }
    #[cfg(not(unix))]
    {
        // Basic fallback for non-Unix platforms
        if mode & 0o200 != 0 { "-rw-------" } else { "-r--------" }.to_string()
    }
}

fn format_size(bytes: u64) -> String {
    const KB: u64 = 1024;
    const MB: u64 = KB * 1024;
    const GB: u64 = MB * 1024;

    if bytes >= GB {
        format!("{:.1}G", bytes as f64 / GB as f64)
    } else if bytes >= MB {
        format!("{:.1}M", bytes as f64 / MB as f64)
    } else if bytes >= KB {
        format!("{:.1}K", bytes as f64 / KB as f64)
    } else {
        format!("{}B", bytes)
    }
}


#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::NamedTempFile;
    use std::io::Write;

    fn create_temp_file_with_content(content: &str) -> NamedTempFile {
        let mut file = tempfile::NamedTempFile::new().unwrap();
        file.write_all(content.as_bytes()).unwrap();
        file
    }

    // --- UPDATED AND NEW TESTS ---

    #[test]
    fn test_format_markdown() {
        let file = create_temp_file_with_content("line 1");
        let paths = vec![file.path().to_path_buf()];
        let mut writer = Vec::new();
        print_output(&mut writer, &paths, &Format::Markdown, false).unwrap();
        let output = String::from_utf8(writer).unwrap();
        let expected = format!("File: {}\n---\nline 1\n", file.path().display());
        assert_eq!(output, expected);
    }

    #[test]
    fn test_format_cat_with_line_numbers() {
        let file = create_temp_file_with_content("a\nb");
        let paths = vec![file.path().to_path_buf()];
        let mut writer = Vec::new();
        print_output(&mut writer, &paths, &Format::Cat, true).unwrap();
        let output = String::from_utf8(writer).unwrap();
        assert_eq!(output, "    1 | a\n    2 | b\n");
    }

    #[test]
    fn test_format_paths() {
        let file1 = create_temp_file_with_content("a");
        let file2 = create_temp_file_with_content("b");
        let paths = vec![file1.path().to_path_buf(), file2.path().to_path_buf()];
        let mut writer = Vec::new();
        print_output(&mut writer, &paths, &Format::Paths, false).unwrap();
        let output = String::from_utf8(writer).unwrap();
        let expected = format!("{}\n{}\n", file1.path().display(), file2.path().display());
        assert_eq!(output, expected);
    }

    #[test]
    fn test_format_json() {
        let file1 = create_temp_file_with_content("{\"key\": \"value\"}");
        let file2 = create_temp_file_with_content("some text");
        let paths = vec![file1.path().to_path_buf(), file2.path().to_path_buf()];
        let mut writer = Vec::new();
        print_output(&mut writer, &paths, &Format::Json, false).unwrap();

        // The output is pretty-printed, so we compare the parsed data, not the raw string.
        let output_data: Vec<FileOutput> = serde_json::from_slice(&writer).unwrap();

        assert_eq!(output_data.len(), 2);
        assert_eq!(output_data[0].path, file1.path().to_string_lossy());
        assert_eq!(output_data[0].content, "{\"key\": \"value\"}");
        assert_eq!(output_data[1].path, file2.path().to_string_lossy());
        assert_eq!(output_data[1].content, "some text");
    }

    #[test]
    fn test_format_find() {
        let file = create_temp_file_with_content("hello"); // 5 bytes
        let paths = vec![file.path().to_path_buf()];
        let mut writer = Vec::new();

        print_output(&mut writer, &paths, &Format::Find, false).unwrap();

        let output = String::from_utf8(writer).unwrap();

        // We can't test the exact permissions or timestamp, but we can test the structure.
        assert!(output.contains("5B")); // Check for size
        assert!(output.contains(file.path().to_str().unwrap())); // Check for path
        assert!(output.ends_with('\n'));
    }
}


// END rdump/src/formatter.rs

// START rdump/src/main.rs

// Declare all our modules
mod commands;
mod config;
mod evaluator;
mod formatter;
mod parser;
mod predicates; // <-- NEW

use anyhow::Result;
use clap::{Parser, Subcommand, ValueEnum};
use std::path::PathBuf;

// Bring our command functions into scope
use commands::{preset::run_preset, search::run_search};

// These structs and enums define the public API of our CLI.
// They need to be public so the `commands` modules can use them.
#[derive(Parser, Debug)]
#[command(version, about = "A fast, expressive tool to find and dump file contents.")]
pub struct Cli {
    #[command(subcommand)]
    pub command: Commands,
}

#[derive(Subcommand, Debug)]
pub enum Commands {
    /// Search for files using a query (default command).
    #[command(visible_alias = "s")]
    Search(SearchArgs),
    /// Manage saved presets.
    #[command(visible_alias = "p")]
    Preset(PresetArgs),
}

#[derive(Parser, Debug, Clone)]
pub struct SearchArgs {
    #[arg()]
    pub query: Option<String>,
    #[arg(long, short)]
    pub preset: Vec<String>,
    #[arg(short, long, default_value = ".")]
    pub root: PathBuf,
    #[arg(short, long)]
    pub output: Option<PathBuf>,
    #[arg(short, long)]
    pub line_numbers: bool,
    #[arg(long)]
    pub no_headers: bool,
    #[arg(long, value_enum, default_value_t = Format::Markdown)]
    pub format: Format,
    #[arg(long)]
    pub no_ignore: bool,
    #[arg(long)]
    pub hidden: bool,
    #[arg(long)]
    pub max_depth: Option<usize>,

    /// List files with metadata instead of dumping content.
    #[arg(long)]
    pub find: bool, // <-- NEW
}

#[derive(Parser, Debug)]
pub struct PresetArgs {
    #[command(subcommand)]
    pub action: PresetAction,
}

#[derive(Subcommand, Debug, Clone)]
pub enum PresetAction {
    /// List all available presets.
    List,
    /// Add or update a preset in the global config file.
    Add {
        #[arg(required = true)]
        name: String,
        #[arg(required = true)]
        query: String,
    },
    /// Remove a preset from the global config file.
    Remove {
        #[arg(required = true)]
        name: String,
    },
}

#[derive(Debug, Clone, ValueEnum)]
pub enum Format {
    Markdown,
    Json,
    Paths,
    Cat,
    Find, // <-- NEW
}

/// The main entry point.
/// Its only job is to parse the CLI and delegate to the correct command module.
fn main() -> Result<()> {
    let mut cli = Cli::parse();

    match &mut cli.command {
        Commands::Search(args) => {
            // --- Handle Shorthand Flags ---
            if args.no_headers {
                args.format = Format::Cat;
            }
            // NEW: Handle `--find` shorthand
            if args.find {
                args.format = Format::Find;
            }
            run_search(args.clone())
        }
        Commands::Preset(args) => run_preset(args.action.clone()),
    }
}


// END rdump/src/main.rs

// START rdump/src/parser.rs

use anyhow::{anyhow, Result};
use pest::iterators::Pair;
use pest::Parser;
use pest_derive::Parser;

#[derive(Parser)]
#[grammar = "rql.pest"]
pub struct RqlParser;

#[derive(Debug, PartialEq, Eq, Hash)]
pub enum PredicateKey {
    Ext,
    Name,
    Path,
    Contains,
    Matches,
    // --- NEW PREDICATES ---
    Size,
    Modified,
    // A key for testing or unknown predicates
    Other(String),
}

impl PredicateKey {
    fn from_str(s: &str) -> Self {
        match s {
            "ext" => Self::Ext,
            "name" => Self::Name,
            "path" => Self::Path,
            "contains" | "c" => Self::Contains,
            "matches" | "m" => Self::Matches,
            // --- NEW PREDICATES ---
            "size" => Self::Size,
            "modified" => Self::Modified,
            // Any other key is captured here.
            other => Self::Other(other.to_string()),
        }
    }
}

#[derive(Debug)]
pub enum AstNode {
    And(Box<AstNode>, Box<AstNode>),
    Or(Box<AstNode>, Box<AstNode>),
    Not(Box<AstNode>),
    Predicate { key: PredicateKey, value: String },
}

pub fn parse_query(query: &str) -> Result<AstNode> {
    // Check for empty or whitespace-only queries BEFORE parsing.
    if query.trim().is_empty() {
        return Err(anyhow!("Empty query"));
    }

    // Map the pest error to a cleaner message if parsing fails.
    let mut pairs = RqlParser::parse(Rule::query, query)
        .map_err(|e| anyhow!("Syntax error in query: {}", e))?;

    let top_level_pair = pairs.next().unwrap(); // Should not fail after the check above
    build_ast_from_pair(top_level_pair)
}

fn build_ast_from_pair(pair: Pair<Rule>) -> Result<AstNode> {
    match pair.as_rule() {
        Rule::query | Rule::expression => build_ast_from_pair(pair.into_inner().next().unwrap()),
        Rule::logical_or => {
            let mut inner = pair.into_inner();
            let mut ast = build_ast_from_pair(inner.next().unwrap())?;
            while inner.next().is_some() {
                let rhs = build_ast_from_pair(inner.next().unwrap())?;
                ast = AstNode::Or(Box::new(ast), Box::new(rhs));
            }
            Ok(ast)
        }
        Rule::logical_and => {
            let mut inner = pair.into_inner();
            let mut ast = build_ast_from_pair(inner.next().unwrap())?;
            while inner.next().is_some() {
                let rhs = build_ast_from_pair(inner.next().unwrap())?;
                ast = AstNode::And(Box::new(ast), Box::new(rhs));
            }
            Ok(ast)
        }
        Rule::factor => {
            let mut inner = pair.into_inner();
            let first_node = inner.next().unwrap();
            if first_node.as_rule() == Rule::NOT {
                let expr = build_ast_from_pair(inner.next().unwrap())?;
                Ok(AstNode::Not(Box::new(expr)))
            } else {
                build_ast_from_pair(first_node)
            }
        }
        Rule::predicate => {
            let mut inner = pair.into_inner();
            let key_str = inner.next().unwrap().as_str();
            let key = PredicateKey::from_str(key_str);

            let value_pair = inner.next().unwrap();
            let inner_value_pair = value_pair.into_inner().next().unwrap();
            let final_value = match inner_value_pair.as_rule() {
                Rule::unquoted_value => inner_value_pair.as_str().to_string(),
                Rule::quoted_value => {
                    let s = inner_value_pair.as_str();
                    s[1..s.len() - 1].to_string()
                }
                _ => unreachable!(),
            };
            Ok(AstNode::Predicate {
                key,
                value: final_value,
            })
        }
        _ => unreachable!(
            "build_ast_from_pair called on unexpected rule: {:?}",
            pair.as_rule()
        ),
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    impl PartialEq for AstNode {
        fn eq(&self, other: &Self) -> bool {
            match (self, other) {
                (AstNode::And(l1, r1), AstNode::And(l2, r2)) => l1 == l2 && r1 == r2,
                (AstNode::Or(l1, r1), AstNode::Or(l2, r2)) => l1 == l2 && r1 == r2,
                (AstNode::Not(n1), AstNode::Not(n2)) => n1 == n2,
                (
                    AstNode::Predicate { key: k1, value: v1 },
                    AstNode::Predicate { key: k2, value: v2 },
                ) => k1 == k2 && v1 == v2,
                _ => false,
            }
        }
    }

    fn predicate(key: PredicateKey, value: &str) -> Box<AstNode> {
        Box::new(AstNode::Predicate {
            key,
            value: value.to_string(),
        })
    }

    #[test]
    fn test_parse_simple_predicate() {
        let ast = parse_query("ext:rs").unwrap();
        assert_eq!(ast, *predicate(PredicateKey::Ext, "rs"));
    }

    #[test]
    fn test_predicate_with_quoted_value() {
        let ast = parse_query("contains:'fn main'").unwrap();
        assert_eq!(ast, *predicate(PredicateKey::Contains, "fn main"));
    }

    #[test]
    fn test_predicate_alias() {
        let ast = parse_query("c:\"some value\"").unwrap();
        assert_eq!(ast, *predicate(PredicateKey::Contains, "some value"));
    }

    #[test]
    fn test_unknown_predicate_key() {
        let ast = parse_query("extension:rs").unwrap();
        assert_eq!(
            ast,
            *predicate(PredicateKey::Other("extension".to_string()), "rs")
        );
    }

    #[test]
    fn test_parse_and_operator() {
        let ast = parse_query("ext:rs & contains:'fn'").unwrap();
        let expected = AstNode::And(
            predicate(PredicateKey::Ext, "rs"),
            predicate(PredicateKey::Contains, "fn"),
        );
        assert_eq!(ast, expected);
    }

    #[test]
    fn test_parse_or_operator() {
        let ast = parse_query("ext:rs | ext:toml").unwrap();
        let expected = AstNode::Or(
            predicate(PredicateKey::Ext, "rs"),
            predicate(PredicateKey::Ext, "toml"),
        );
        assert_eq!(ast, expected);
    }

    #[test]
    fn test_parse_not_operator() {
        let ast = parse_query("!ext:md").unwrap();
        let expected = AstNode::Not(predicate(PredicateKey::Ext, "md"));
        assert_eq!(ast, expected);
    }

    #[test]
    fn test_parse_precedence() {
        let ast = parse_query("ext:rs & name:main | ext:toml").unwrap();
        let expected = AstNode::Or(
            Box::new(AstNode::And(
                predicate(PredicateKey::Ext, "rs"),
                predicate(PredicateKey::Name, "main"),
            )),
            predicate(PredicateKey::Ext, "toml"),
        );
        assert_eq!(ast, expected);
    }

    #[test]
    fn test_parse_parentheses() {
        let ast = parse_query("ext:rs & (name:main | ext:toml)").unwrap();
        let expected = AstNode::And(
            predicate(PredicateKey::Ext, "rs"),
            Box::new(AstNode::Or(
                predicate(PredicateKey::Name, "main"),
                predicate(PredicateKey::Ext, "toml"),
            )),
        );
        assert_eq!(ast, expected);
    }

    #[test]
    fn test_parse_complex_nested_query() {
        let ast = parse_query("!(ext:rs | path:tests) & (contains:'foo' | c:'bar')").unwrap();
        let expected = AstNode::And(
            Box::new(AstNode::Not(Box::new(AstNode::Or(
                predicate(PredicateKey::Ext, "rs"),
                predicate(PredicateKey::Path, "tests"),
            )))),
            Box::new(AstNode::Or(
                predicate(PredicateKey::Contains, "foo"),
                predicate(PredicateKey::Contains, "bar"),
            )),
        );
        assert_eq!(ast, expected);
    }

    #[test]
    fn test_whitespace_insensitivity() {
        let ast = parse_query("  ext:rs   &   (  path:src   )  ").unwrap();
        let expected = AstNode::And(
            predicate(PredicateKey::Ext, "rs"),
            predicate(PredicateKey::Path, "src"),
        );
        assert_eq!(ast, expected);
    }

    #[test]
    fn test_no_whitespace() {
        let ast = parse_query("ext:rs&path:src").unwrap();
        let expected = AstNode::And(
            predicate(PredicateKey::Ext, "rs"),
            predicate(PredicateKey::Path, "src"),
        );
        assert_eq!(ast, expected);
    }

    #[test]
    fn test_deeply_nested_precedence() {
        let ast = parse_query("a:1 | b:2 & c:3 | d:4 & e:5").unwrap();
        let expected = AstNode::Or(
            Box::new(AstNode::Or(
                predicate(PredicateKey::Other("a".to_string()), "1"),
                Box::new(AstNode::And(
                    predicate(PredicateKey::Other("b".to_string()), "2"),
                    // THIS IS THE CORRECTED LINE:
                    predicate(PredicateKey::Contains, "3"),
                )),
            )),
            Box::new(AstNode::And(
                predicate(PredicateKey::Other("d".to_string()), "4"),
                predicate(PredicateKey::Other("e".to_string()), "5"),
            )),
        );
        assert_eq!(ast, expected);
    }

    // --- SYNTAX ERROR TESTS ---

    #[test]
    fn test_error_on_trailing_operator() {
        let result = parse_query("ext:rs &");
        assert!(result.is_err());
    }

    #[test]
    fn test_error_on_missing_value() {
        let result = parse_query("ext:");
        assert!(result.is_err());
    }

    #[test]
    fn test_error_on_unclosed_parenthesis() {
        let result = parse_query("(ext:rs | path:src");
        assert!(result.is_err());
    }

    #[test]
    fn test_error_on_empty_query() {
        let result = parse_query("");
        assert!(result.is_err());
        assert_eq!(result.unwrap_err().to_string(), "Empty query");
    }

    #[test]
    fn test_error_on_whitespace_query() {
        let result = parse_query("   ");
        assert!(result.is_err());
        assert_eq!(result.unwrap_err().to_string(), "Empty query");
    }

    #[test]
    fn test_not_precedence_with_and() {
        // `!` should have higher precedence than `&`.
        // Should parse as: (!ext:rs) & path:src
        let ast = parse_query("!ext:rs & path:src").unwrap();
        let expected = AstNode::And(
            Box::new(AstNode::Not(predicate(PredicateKey::Ext, "rs"))),
            predicate(PredicateKey::Path, "src"),
        );
        assert_eq!(ast, expected);
    }

    #[test]
    fn test_not_with_parentheses() {
        // `!` should apply to the entire parenthesized group.
        let ast = parse_query("!(ext:rs | path:src)").unwrap();
        let expected = AstNode::Not(Box::new(AstNode::Or(
            predicate(PredicateKey::Ext, "rs"),
            predicate(PredicateKey::Path, "src"),
        )));
        assert_eq!(ast, expected);
    }

    #[test]
    fn test_long_or_chain_is_left_associative() {
        // Should parse as: ((a | b) | c) | d
        let ast = parse_query("ext:a | ext:b | ext:c | ext:d").unwrap();
        let expected = AstNode::Or(
            Box::new(AstNode::Or(
                Box::new(AstNode::Or(
                    predicate(PredicateKey::Ext, "a"),
                    predicate(PredicateKey::Ext, "b"),
                )),
                predicate(PredicateKey::Ext, "c"),
            )),
            predicate(PredicateKey::Ext, "d"),
        );
        assert_eq!(ast, expected);
    }

    #[test]
    fn test_long_and_chain_is_left_associative() {
        // Should parse as: ((a & b) & c) & d
        let ast = parse_query("ext:a & ext:b & ext:c & ext:d").unwrap();
        let expected = AstNode::And(
            Box::new(AstNode::And(
                Box::new(AstNode::And(
                    predicate(PredicateKey::Ext, "a"),
                    predicate(PredicateKey::Ext, "b"),
                )),
                predicate(PredicateKey::Ext, "c"),
            )),
            predicate(PredicateKey::Ext, "d"),
        );
        assert_eq!(ast, expected);
    }

    #[test]
    fn test_redundant_parentheses() {
        let ast = parse_query("((ext:rs))").unwrap();
        assert_eq!(ast, *predicate(PredicateKey::Ext, "rs"));
    }

    #[test]
    fn test_value_containing_special_char_must_be_quoted() {
        // An unquoted value cannot contain '&'
        let result = parse_query("name:foo&bar");
        assert!(result.is_err());

        // But a quoted one can
        let ast = parse_query("name:'foo&bar'").unwrap();
        assert_eq!(ast, *predicate(PredicateKey::Name, "foo&bar"));
    }
}


// END rdump/src/parser.rs

// START rdump/src/predicates/mod.rs

use crate::evaluator::FileContext;
use crate::parser::PredicateKey;
use anyhow::{anyhow, Result};
use std::collections::HashMap;
use std::time::{Duration, SystemTime};

// The core trait that all predicate evaluators must implement.
pub trait PredicateEvaluator {
    fn evaluate(&self, context: &mut FileContext, value: &str) -> Result<bool>;
}

// --- Concrete Implementations ---

struct ExtEvaluator;
impl PredicateEvaluator for ExtEvaluator {
    fn evaluate(&self, context: &mut FileContext, value: &str) -> Result<bool> {
        let file_ext = context.path.extension().and_then(|s| s.to_str()).unwrap_or("");
        Ok(file_ext.eq_ignore_ascii_case(value))
    }
}

struct PathEvaluator;
impl PredicateEvaluator for PathEvaluator {
    fn evaluate(&self, context: &mut FileContext, value: &str) -> Result<bool> {
        let path_str = context.path.to_string_lossy();
        Ok(path_str.contains(value))
    }
}

struct NameEvaluator;
impl PredicateEvaluator for NameEvaluator {
    fn evaluate(&self, context: &mut FileContext, value: &str) -> Result<bool> {
        let file_name = context.path.file_name().and_then(|s| s.to_str()).unwrap_or("");
        let pattern = glob::Pattern::new(value)?;
        Ok(pattern.matches(file_name))
    }
}

struct ContainsEvaluator;
impl PredicateEvaluator for ContainsEvaluator {
    fn evaluate(&self, context: &mut FileContext, value: &str) -> Result<bool> {
        let content = context.get_content()?;
        Ok(content.contains(value))
    }
}

struct MatchesEvaluator;
impl PredicateEvaluator for MatchesEvaluator {
    fn evaluate(&self, context: &mut FileContext, value: &str) -> Result<bool> {
        let content = context.get_content()?;
        let re = regex::Regex::new(value)?;
        Ok(re.is_match(content))
    }
}

struct SizeEvaluator;
impl PredicateEvaluator for SizeEvaluator {
    fn evaluate(&self, context: &mut FileContext, value: &str) -> Result<bool> {
        let metadata = context.path.metadata()?;
        let file_size = metadata.len();
        parse_and_compare_size(file_size, value)
    }
}

struct ModifiedEvaluator;
impl PredicateEvaluator for ModifiedEvaluator {
    fn evaluate(&self, context: &mut FileContext, value: &str) -> Result<bool> {
        let metadata = context.path.metadata()?;
        let modified_time = metadata.modified()?;
        parse_and_compare_time(modified_time, value)
    }
}

// --- HELPER FUNCTIONS (moved from evaluator.rs) ---

fn parse_and_compare_size(file_size: u64, value: &str) -> Result<bool> {
    if value.len() < 2 {
        return Err(anyhow!("Invalid size format. Expected <op><num>[unit], e.g., '>10kb'"));
    }
    let op = value.chars().next().unwrap();
    let rest = &value[1..];
    let numeric_part_end = rest.find(|c: char| !c.is_ascii_digit() && c != '.').unwrap_or(rest.len());
    let (num_str, unit_str) = rest.split_at(numeric_part_end);
    let num: f64 = num_str.parse()?;
    let multiplier = match unit_str.trim().to_lowercase().as_str() {
        "" | "b" => 1.0,
        "k" | "kb" => 1024.0,
        "m" | "mb" => 1024.0 * 1024.0,
        "g" | "gb" => 1024.0 * 1024.0 * 1024.0,
        _ => return Err(anyhow!("Invalid size unit: '{}'", unit_str)),
    };
    let target_size = (num * multiplier) as u64;
    match op {
        '>' => Ok(file_size > target_size),
        '<' => Ok(file_size < target_size),
        _ => Err(anyhow!("Invalid size operator: '{}'", op)),
    }
}

fn parse_and_compare_time(modified_time: SystemTime, value: &str) -> Result<bool> {
    let (op, duration_str) = value.split_at(1);
    let now = SystemTime::now();
    let (num_str, unit) = duration_str.split_at(duration_str.len() - 1);
    let num: u64 = num_str.parse()?;
    let duration = match unit {
        "s" => Duration::from_secs(num),
        "m" => Duration::from_secs(num * 60),
        "h" => Duration::from_secs(num * 3600),
        "d" => Duration::from_secs(num * 3600 * 24),
        "w" => Duration::from_secs(num * 3600 * 24 * 7),
        _ => return Err(anyhow!("Invalid time unit: '{}'", unit)),
    };
    let cutoff_time = now - duration;
    match op {
        ">" => Ok(modified_time > cutoff_time),
        "<" => Ok(modified_time < cutoff_time),
        _ => Err(anyhow!("Invalid time operator: '{}'", op)),
    }
}

// The "Registry" that holds all our evaluators.
pub fn create_predicate_registry() -> HashMap<PredicateKey, Box<dyn PredicateEvaluator + Send + Sync>> {
    let mut registry: HashMap<PredicateKey, Box<dyn PredicateEvaluator + Send + Sync>> = HashMap::new();

    // The `Send + Sync` bounds are required because we use this in a multi-threaded
    // context with Rayon. All our current evaluators are safe.
    registry.insert(PredicateKey::Ext, Box::new(ExtEvaluator));
    registry.insert(PredicateKey::Path, Box::new(PathEvaluator));
    registry.insert(PredicateKey::Name, Box::new(NameEvaluator));
    registry.insert(PredicateKey::Contains, Box::new(ContainsEvaluator));
    registry.insert(PredicateKey::Matches, Box::new(MatchesEvaluator));
    registry.insert(PredicateKey::Size, Box::new(SizeEvaluator));
    registry.insert(PredicateKey::Modified, Box::new(ModifiedEvaluator));

    registry
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::evaluator::FileContext;
    use std::io::Write;
    use std::path::PathBuf;
    use tempfile::NamedTempFile;

    fn create_temp_file(content: &str) -> NamedTempFile {
        let mut file = tempfile::NamedTempFile::new().unwrap();
        file.write_all(content.as_bytes()).unwrap();
        file
    }

    #[test]
    fn test_size_evaluator() {
        let content: Vec<u8> = vec![0; 1024]; // Exactly 1 KB
        let file = create_temp_file("");
        file.as_file().write_all(&content).unwrap();
        let mut context = FileContext::new(file.path().to_path_buf());

        let evaluator = SizeEvaluator;
        assert!(evaluator.evaluate(&mut context, ">1000").unwrap());
        assert!(!evaluator.evaluate(&mut context, "<1kb").unwrap());
        assert!(evaluator.evaluate(&mut context, ">0.9kb").unwrap());
    }

    #[test]
    fn test_modified_evaluator() {
        let file = create_temp_file("content");
        let mut context = FileContext::new(file.path().to_path_buf());

        let evaluator = ModifiedEvaluator;
        // File was just created
        assert!(evaluator.evaluate(&mut context, ">1m").unwrap()); // Modified more recently than 1 min ago
        assert!(!evaluator.evaluate(&mut context, "<1m").unwrap()); // Not modified longer than 1 min ago
    }

    #[test]
    fn test_ext_evaluator() {
        let mut context_rs = FileContext::new(PathBuf::from("/tmp/test.rs"));
        let mut context_toml = FileContext::new(PathBuf::from("C:\\data\\Config.TOML"));
        let mut context_no_ext = FileContext::new(PathBuf::from("no_extension"));
        let mut context_dotfile = FileContext::new(PathBuf::from(".bashrc"));

        let evaluator = ExtEvaluator;
        assert!(evaluator.evaluate(&mut context_rs, "rs").unwrap());
        assert!(!evaluator.evaluate(&mut context_rs, "toml").unwrap());
        assert!(evaluator.evaluate(&mut context_toml, "toml").unwrap(), "Should be case-insensitive");
        assert!(!evaluator.evaluate(&mut context_no_ext, "rs").unwrap());
        assert!(!evaluator.evaluate(&mut context_dotfile, "bashrc").unwrap(), "Dotfiles should have no extension");
    }

    #[test]
    fn test_path_evaluator() {
        let mut context = FileContext::new(PathBuf::from("/home/user/project/src/main.rs"));
        let evaluator = PathEvaluator;
        assert!(evaluator.evaluate(&mut context, "project/src").unwrap());
        assert!(evaluator.evaluate(&mut context, "/home/user").unwrap());
        assert!(!evaluator.evaluate(&mut context, "project/lib").unwrap());
        assert!(evaluator.evaluate(&mut context, "main.rs").unwrap());
    }

    #[test]
    fn test_name_evaluator() {
        let mut context1 = FileContext::new(PathBuf::from("/home/user/Cargo.toml"));
        let mut context2 = FileContext::new(PathBuf::from("/home/user/main.rs"));

        let evaluator = NameEvaluator;
        assert!(evaluator.evaluate(&mut context1, "Cargo.toml").unwrap());
        assert!(evaluator.evaluate(&mut context1, "C*.toml").unwrap(), "Glob pattern should match");
        assert!(evaluator.evaluate(&mut context2, "*.rs").unwrap(), "Glob pattern should match");
        assert!(!evaluator.evaluate(&mut context1, "*.rs").unwrap());
    }

    #[test]
    fn test_contains_evaluator() {
        let file = create_temp_file("Hello world\nThis is a test.");
        let mut context = FileContext::new(file.path().to_path_buf());
        let evaluator = ContainsEvaluator;
        assert!(evaluator.evaluate(&mut context, "world").unwrap());
        assert!(evaluator.evaluate(&mut context, "is a test").unwrap());
        assert!(!evaluator.evaluate(&mut context, "goodbye").unwrap());
    }

    #[test]
    fn test_matches_evaluator() {
        let file = create_temp_file("version = \"0.1.0\"\nauthor = \"test\"");
        let mut context = FileContext::new(file.path().to_path_buf());
        let evaluator = MatchesEvaluator;
        // Simple regex
        assert!(evaluator.evaluate(&mut context, r#"version = "[0-9]+\.[0-9]+\.[0-9]+""#).unwrap());
        // Test regex that spans lines
        assert!(evaluator.evaluate(&mut context, r#"(?s)version.*author"#).unwrap());
        assert!(!evaluator.evaluate(&mut context, r#"^version = "1.0.0"$"#).unwrap());
    }
}


// END rdump/src/predicates/mod.rs

